maml.exe TrainTest test=%Data% tr=LogisticRegression{l1=1.0 l2=0.1 ot=1e-3 nt=1} eval=BinaryClassifier{threshold=0.95 useRawScore=-} norm=No dout=%Output% data=%Data% out=%Output% seed=1
Not adding a normalizer.
Warning: Skipped 16 instances with missing features/label/weight during training
Beginning optimization
num vars: 10
improvement criterion: Mean Improvement
L1 regularization selected 10 of 10 weights.
Not training a calibrator because it is not needed.
Warning: The predictor produced non-finite prediction values on 16 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3499 (239.0/(239.0+444.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      198 |       41 | 0.8285
 negative ||        3 |      441 | 0.9932
          ||======================
Precision ||   0.9851 |   0.9149 |
OVERALL 0/1 ACCURACY: 0.935578
LOG LOSS/instance:  0.111002
Test-set entropy (prior Log-Loss/instance): 0.934003
LOG-LOSS REDUCTION (RIG): 0.881154
AUC:                0.996136

OVERALL RESULTS
---------------------------------------
AUC:                0.996136 (0.0000)
Accuracy:           0.935578 (0.0000)
Positive precision: 0.985075 (0.0000)
Positive recall:    0.828452 (0.0000)
Negative precision: 0.914938 (0.0000)
Negative recall:    0.993243 (0.0000)
Log-loss:           0.111002 (0.0000)
Log-loss reduction: 0.881154 (0.0000)
F1 Score:           0.900000 (0.0000)
AUPRC:              0.991883 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'LBFGS data prep' started.
[1] 'LBFGS data prep' finished in %Time%.
[2] 'LBFGS Optimizer' started.
[2] (%Time%)	0 iterations	Loss: 0.6931471824645996
[2] (%Time%)	1 iterations	Loss: 0.6448327898979187	Improvement: 0.04831
[2] (%Time%)	2 iterations	Loss: 0.6306551694869995	Improvement: 0.021
[2] (%Time%)	3 iterations	Loss: 0.5210472345352173	Improvement: 0.08851
[2] (%Time%)	4 iterations	Loss: 0.3810925781726837	Improvement: 0.1272
[2] (%Time%)	5 iterations	Loss: 0.3549964427947998	Improvement: 0.05131
[2] (%Time%)	6 iterations	Loss: 0.34571003913879395	Improvement: 0.01978
[2] (%Time%)	7 iterations	Loss: 0.3228526711463928	Improvement: 0.02209
[2] (%Time%)	8 iterations	Loss: 0.24733668565750122	Improvement: 0.06216
[2] (%Time%)	9 iterations	Loss: 0.22847387194633484	Improvement: 0.02969
[2] (%Time%)	10 iterations	Loss: 0.16646333038806915	Improvement: 0.05393
[2] (%Time%)	11 iterations	Loss: 0.12585707008838654	Improvement: 0.04394
[2] (%Time%)	12 iterations	Loss: 0.10631134361028671	Improvement: 0.02564
[2] (%Time%)	13 iterations	Loss: 0.09210390597581863	Improvement: 0.01707
[2] (%Time%)	14 iterations	Loss: 0.08548402786254883	Improvement: 0.009232
[2] (%Time%)	15 iterations	Loss: 0.08181773126125336	Improvement: 0.005058
[2] (%Time%)	16 iterations	Loss: 0.0811641737818718	Improvement: 0.001755
[2] (%Time%)	17 iterations	Loss: 0.0807165652513504	Improvement: 0.0007743
[2] 'LBFGS Optimizer' finished in %Time%.
[3] 'Saving model' started.
[3] 'Saving model' finished in %Time%.
