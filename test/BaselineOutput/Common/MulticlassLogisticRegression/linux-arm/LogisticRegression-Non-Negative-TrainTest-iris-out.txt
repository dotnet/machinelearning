maml.exe TrainTest test=%Data% tr=MulticlassLogisticRegression{l1=0.001 l2=0.1 ot=1e-3 nt=1 nn=+} norm=No dout=%Output% data=%Data% out=%Output% seed=1 xf=Term{col=Label}
Not adding a normalizer.
Beginning optimization
num vars: 15
improvement criterion: Mean Improvement
L1 regularization selected 13 of 15 weights.
Not training a calibrator because it is not needed.

Confusion table
          ||========================
PREDICTED ||     0 |     1 |     2 | Recall
TRUTH     ||========================
        0 ||    50 |     0 |     0 | 1.0000
        1 ||     0 |    48 |     2 | 0.9600
        2 ||     0 |     1 |    49 | 0.9800
          ||========================
Precision ||1.0000 |0.9796 |0.9608 |
Accuracy(micro-avg): 0.980000
Accuracy(macro-avg): 0.980000
Log-loss:           0.095473
Log-loss reduction: 0.913096

OVERALL RESULTS
---------------------------------------
Accuracy(micro-avg): 0.980000 (0.0000)
Accuracy(macro-avg): 0.980000 (0.0000)
Log-loss:           0.095473 (0.0000)
Log-loss reduction: 0.913096 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'Building term dictionary' started.
[1] (%Time%)	150 examples	Total Terms: 3
[1] 'Building term dictionary' finished in %Time%.
[2] 'LBFGS data prep' started.
[2] 'LBFGS data prep' finished in %Time%.
[3] 'LBFGS Optimizer' started.
[3] (%Time%)	0 iterations	Loss: 1.0986123085021973
[3] (%Time%)	1 iterations	Loss: 1.0638996362686157	Improvement: 0.03471
[3] (%Time%)	2 iterations	Loss: 1.0165412425994873	Improvement: 0.04483
[3] (%Time%)	3 iterations	Loss: 0.9443140625953674	Improvement: 0.0657
[3] (%Time%)	4 iterations	Loss: 0.6682092547416687	Improvement: 0.2241
[3] (%Time%)	5 iterations	Loss: 0.5532791018486023	Improvement: 0.1421
[3] (%Time%)	6 iterations	Loss: 0.42720934748649597	Improvement: 0.1301
[3] (%Time%)	7 iterations	Loss: 0.33543163537979126	Improvement: 0.1014
[3] (%Time%)	8 iterations	Loss: 0.27138790488243103	Improvement: 0.07337
[3] (%Time%)	9 iterations	Loss: 0.21875371038913727	Improvement: 0.05782
[3] (%Time%)	10 iterations	Loss: 0.1928301453590393	Improvement: 0.0339
[3] (%Time%)	11 iterations	Loss: 0.18482188880443573	Improvement: 0.01448
[3] (%Time%)	12 iterations	Loss: 0.1825772225856781	Improvement: 0.005304
[3] (%Time%)	13 iterations	Loss: 0.18094274401664734	Improvement: 0.002552
[3] (%Time%)	14 iterations	Loss: 0.1789129674434662	Improvement: 0.00216
[3] (%Time%)	15 iterations	Loss: 0.17135457694530487	Improvement: 0.006209
[3] (%Time%)	16 iterations	Loss: 0.1576078236103058	Improvement: 0.01186
[3] (%Time%)	17 iterations	Loss: 0.15354663133621216	Improvement: 0.006011
[3] (%Time%)	18 iterations	Loss: 0.15137210488319397	Improvement: 0.003134
[3] (%Time%)	19 iterations	Loss: 0.1468994915485382	Improvement: 0.004138
[3] (%Time%)	20 iterations	Loss: 0.1437908560037613	Improvement: 0.003366
[3] (%Time%)	21 iterations	Loss: 0.14152587950229645	Improvement: 0.00254
[3] (%Time%)	22 iterations	Loss: 0.1407100260257721	Improvement: 0.001247
[3] (%Time%)	23 iterations	Loss: 0.14007723331451416	Improvement: 0.0007863
[3] 'LBFGS Optimizer' finished in %Time%.
[4] 'Saving model' started.
[4] 'Saving model' finished in %Time%.
