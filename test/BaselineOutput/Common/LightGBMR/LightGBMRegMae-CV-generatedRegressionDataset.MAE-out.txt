maml.exe CV tr=LightGBMR{nt=1 iter=50 em=MeanAbsoluteError v=+ lr=0.2 mil=10 nl=20} threads=- dout=%Output% loader=Text{col=Label:R4:11 col=Features:R4:0-10 sep=; header+} data=%Data% seed=1
Not adding a normalizer.
Auto-tuning parameters: UseCategoricalSplit = False
LightGBM objective=regression
Not training a calibrator because it is not needed.
Not adding a normalizer.
Auto-tuning parameters: UseCategoricalSplit = False
LightGBM objective=regression
Not training a calibrator because it is not needed.
L1(avg):            27.482854
L2(avg):            1,445.214986
RMS(avg):           38.015983
Loss-fn(avg):       1,445.214986
R Squared:          0.919579
L1(avg):            25.712503
L2(avg):            1,341.270608
RMS(avg):           36.623362
Loss-fn(avg):       1,341.270595
R Squared:          0.927235

OVERALL RESULTS
---------------------------------------
L1(avg):            26.597679 (0.8852)
L2(avg):            1,393.242797 (51.9722)
RMS(avg):           37.319672 (0.6963)
Loss-fn(avg):       1,393.242791 (51.9722)
R Squared:          0.923407 (0.0038)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'Loading data for LightGBM' started.
[1] 'Loading data for LightGBM' finished in %Time%.
[2] 'Training with LightGBM' started.
[2] (%Time%)	Iteration: 50	Training-mae: 2.7212587836279383
[2] 'Training with LightGBM' finished in %Time%.
[3] 'Loading data for LightGBM #2' started.
[3] 'Loading data for LightGBM #2' finished in %Time%.
[4] 'Training with LightGBM #2' started.
[4] (%Time%)	Iteration: 50	Training-mae: 2.2411620443092595
[4] 'Training with LightGBM #2' finished in %Time%.
