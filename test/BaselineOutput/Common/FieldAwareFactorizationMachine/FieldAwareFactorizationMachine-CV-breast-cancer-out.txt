maml.exe CV tr=FieldAwareFactorizationMachine{d=5 shuf- norm-} col[Feature]=DupFeatures threads=- norm=No dout=%Output% data=%Data% seed=1 xf=Copy{col=DupFeatures:Features} xf=MinMax{col=Features col=DupFeatures}
Not adding a normalizer.
Warning: Skipped 8 examples with bad label/weight/features in training set
Not training a calibrator because it is not needed.
Not adding a normalizer.
Warning: Skipped 8 examples with bad label/weight/features in training set
Not training a calibrator because it is not needed.
Warning: The predictor produced non-finite prediction values on 8 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3785 (134.0/(134.0+220.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      122 |       12 | 0.9104
 negative ||        4 |      216 | 0.9818
          ||======================
Precision ||   0.9683 |   0.9474 |
OVERALL 0/1 ACCURACY: 0.954802
LOG LOSS/instance:  0.259660
Test-set entropy (prior Log-Loss/instance): 0.956998
LOG-LOSS REDUCTION (RIG): 72.867233
AUC:                0.984973
Warning: The predictor produced non-finite prediction values on 8 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3191 (105.0/(105.0+224.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||       92 |       13 | 0.8762
 negative ||        2 |      222 | 0.9911
          ||======================
Precision ||   0.9787 |   0.9447 |
OVERALL 0/1 ACCURACY: 0.954407
LOG LOSS/instance:  0.260480
Test-set entropy (prior Log-Loss/instance): 0.903454
LOG-LOSS REDUCTION (RIG): 71.168362
AUC:                0.967049

OVERALL RESULTS
---------------------------------------
AUC:                0.976011 (0.0090)
Accuracy:           0.954605 (0.0002)
Positive precision: 0.973489 (0.0052)
Positive recall:    0.893319 (0.0171)
Negative precision: 0.946025 (0.0013)
Negative recall:    0.986445 (0.0046)
Log-loss:           0.260070 (0.0004)
Log-loss reduction: 72.017798 (0.8494)
F1 Score:           0.931542 (0.0069)
AUPRC:              0.974115 (0.0054)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'Normalize' started.
[1] (%Time%)	337 examples
[1] 'Normalize' finished in %Time%.
[2] 'Training' started.
[2] (%Time%)	1 iterations, 329 examples	Training-loss: 0.371414389819699
[2] (%Time%)	2 iterations, 329 examples	Training-loss: 0.225137821503565
[2] (%Time%)	3 iterations, 329 examples	Training-loss: 0.197323119398265
[2] (%Time%)	4 iterations, 329 examples	Training-loss: 0.183649426646222
[2] (%Time%)	5 iterations, 329 examples	Training-loss: 0.174400635825405
[2] 'Training' finished in %Time%.
[3] 'Normalize #2' started.
[3] (%Time%)	362 examples
[3] 'Normalize #2' finished in %Time%.
[4] 'Training #2' started.
[4] (%Time%)	1 iterations, 354 examples	Training-loss: 0.35872800705401
[4] (%Time%)	2 iterations, 354 examples	Training-loss: 0.239609312114266
[4] (%Time%)	3 iterations, 354 examples	Training-loss: 0.210775498912242
[4] (%Time%)	4 iterations, 354 examples	Training-loss: 0.19625903089058
[4] (%Time%)	5 iterations, 354 examples	Training-loss: 0.187121580244397
[4] 'Training #2' finished in %Time%.
