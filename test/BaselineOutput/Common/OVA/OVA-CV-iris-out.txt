maml.exe CV tr=OVA{p=AvgPer{ lr=0.8 }} threads=- norm=No dout=%Output% data=%Data% seed=1 xf=Term{col=Label}
Not adding a normalizer.
Training learner 0
Training calibrator.
Training learner 1
Training calibrator.
Training learner 2
Training calibrator.
Not training a calibrator because it is not needed.
Not adding a normalizer.
Training learner 0
Training calibrator.
Training learner 1
Training calibrator.
Training learner 2
Training calibrator.
Not training a calibrator because it is not needed.

Confusion table
          ||========================
PREDICTED ||     0 |     1 |     2 | Recall
TRUTH     ||========================
        0 ||    21 |     0 |     0 | 1.0000
        1 ||     0 |    20 |    10 | 0.6667
        2 ||     0 |     0 |    28 | 1.0000
          ||========================
Precision ||1.0000 |1.0000 |0.7368 |
Accuracy(micro-avg): 0.873418
Accuracy(macro-avg): 0.888889
Log-loss:           0.393949
Log-loss reduction: 0.637753

Confusion table
          ||========================
PREDICTED ||     0 |     1 |     2 | Recall
TRUTH     ||========================
        0 ||    29 |     0 |     0 | 1.0000
        1 ||     0 |    19 |     1 | 0.9500
        2 ||     0 |     0 |    22 | 1.0000
          ||========================
Precision ||1.0000 |1.0000 |0.9565 |
Accuracy(micro-avg): 0.985915
Accuracy(macro-avg): 0.983333
Log-loss:           0.299620
Log-loss reduction: 0.724018

OVERALL RESULTS
---------------------------------------
Accuracy(micro-avg): 0.929667 (0.0562)
Accuracy(macro-avg): 0.936111 (0.0472)
Log-loss:           0.346785 (0.0472)
Log-loss reduction: 0.680886 (0.0431)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

