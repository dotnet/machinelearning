maml.exe CV tr=OVA{p=AvgPer{ lr=0.8 }} threads=- norm=No dout=%Output% data=%Data% seed=1 xf=Term{col=Label}
Not adding a normalizer.
Training learner 0
Training calibrator.
Training learner 1
Training calibrator.
Training learner 2
Training calibrator.
Not training a calibrator because it is not needed.
Not adding a normalizer.
Training learner 0
Training calibrator.
Training learner 1
Training calibrator.
Training learner 2
Training calibrator.
Not training a calibrator because it is not needed.

Confusion table
          ||========================
PREDICTED ||     0 |     1 |     2 | Recall
TRUTH     ||========================
        0 ||    21 |     0 |     0 | 1.0000
        1 ||     0 |    28 |     2 | 0.9333
        2 ||     0 |     0 |    28 | 1.0000
          ||========================
Precision ||1.0000 |1.0000 |0.9333 |
Accuracy(micro-avg): 0.974684
Accuracy(macro-avg): 0.977778
Log-loss:           0.352944
Log-loss reduction: 0.675458

Confusion table
          ||========================
PREDICTED ||     0 |     1 |     2 | Recall
TRUTH     ||========================
        0 ||    29 |     0 |     0 | 1.0000
        1 ||     0 |    18 |     2 | 0.9000
        2 ||     0 |     0 |    22 | 1.0000
          ||========================
Precision ||1.0000 |1.0000 |0.9167 |
Accuracy(micro-avg): 0.971831
Accuracy(macro-avg): 0.966667
Log-loss:           0.273754
Log-loss reduction: 0.747843

OVERALL RESULTS
---------------------------------------
Accuracy(micro-avg): 0.973257 (0.0014)
Accuracy(macro-avg): 0.972222 (0.0056)
Log-loss:           0.313349 (0.0396)
Log-loss reduction: 0.711651 (0.0362)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

