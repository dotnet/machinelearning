maml.exe TrainTest test=%Data% tr=WeightedEnsembleMulticlass{bp=mlr{t-} nm=5 oc=MultiStacking{bp=mlr{t-}} tp=-} dout=%Output% data=%Data% out=%Output% seed=1 xf=Term{col=Label}
Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.
Training 5 learners for the batch 1
Beginning training model 1 of 5
Beginning optimization
num vars: 15
improvement criterion: Mean Improvement
L1 regularization selected 10 of 15 weights.
Trainer 1 of 5 finished in %Time%
Beginning training model 2 of 5
Beginning optimization
num vars: 15
improvement criterion: Mean Improvement
L1 regularization selected 12 of 15 weights.
Trainer 2 of 5 finished in %Time%
Beginning training model 3 of 5
Beginning optimization
num vars: 15
improvement criterion: Mean Improvement
L1 regularization selected 11 of 15 weights.
Trainer 3 of 5 finished in %Time%
Beginning training model 4 of 5
Beginning optimization
num vars: 15
improvement criterion: Mean Improvement
L1 regularization selected 11 of 15 weights.
Trainer 4 of 5 finished in %Time%
Beginning training model 5 of 5
Beginning optimization
num vars: 15
improvement criterion: Mean Improvement
L1 regularization selected 11 of 15 weights.
Trainer 5 of 5 finished in %Time%
The number of instances used for stacking trainer is 43
Warning: The trainer specified for stacking wants normalization, but we do not currently allow this.
Beginning optimization
num vars: 48
improvement criterion: Mean Improvement
L1 regularization selected 26 of 48 weights.
Not training a calibrator because it is not needed.

Confusion table
          ||========================
PREDICTED ||     0 |     1 |     2 | Recall
TRUTH     ||========================
        0 ||    50 |     0 |     0 | 1.0000
        1 ||     0 |    35 |    15 | 0.7000
        2 ||     0 |     0 |    50 | 1.0000
          ||========================
Precision ||1.0000 |1.0000 |0.7692 |
Accuracy(micro-avg): 0.900000
Accuracy(macro-avg): 0.900000
Log-loss:           0.431192
Log-loss reduction: 0.607512

OVERALL RESULTS
---------------------------------------
Accuracy(micro-avg): 0.900000 (0.0000)
Accuracy(macro-avg): 0.900000 (0.0000)
Log-loss:           0.431192 (0.0000)
Log-loss reduction: 0.607512 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

