maml.exe TrainTest test=%Data% tr=BinaryClassificationGamTrainer{dt+} dout=%Output% data=%Data% out=%Output% seed=1
Not adding a normalizer.
Making per-feature arrays
Changing data from row-wise to column-wise on disk
Warning: 16 of 699 examples will be skipped due to missing feature values
Processed 683 instances
Binning and forming Feature objects
Starting to train ...
Training calibrator.
TEST POSITIVE RATIO:	0.3448 (241.0/(241.0+458.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      232 |        9 | 0.9627
 negative ||       12 |      446 | 0.9738
          ||======================
Precision ||   0.9508 |   0.9802 |
OVERALL 0/1 ACCURACY: 0.969957
LOG LOSS/instance:  0.113509
Test-set entropy (prior Log-Loss/instance): 0.929318
LOG-LOSS REDUCTION (RIG): 0.877858
AUC:                0.994972

OVERALL RESULTS
---------------------------------------
AUC:                0.994972 (0.0000)
Accuracy:           0.969957 (0.0000)
Positive precision: 0.950820 (0.0000)
Positive recall:    0.962656 (0.0000)
Negative precision: 0.980220 (0.0000)
Negative recall:    0.973799 (0.0000)
Log-loss:           0.113509 (0.0000)
Log-loss reduction: 0.877858 (0.0000)
F1 Score:           0.956701 (0.0000)
AUPRC:              0.989577 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'FastTree disk-based bins initialization' started.
[1] 'FastTree disk-based bins initialization' finished in %Time%.
[2] 'GAM training' started.
[2] 'GAM training' finished in %Time%.
[3] 'Saving model' started.
[3] 'Saving model' finished in %Time%.
