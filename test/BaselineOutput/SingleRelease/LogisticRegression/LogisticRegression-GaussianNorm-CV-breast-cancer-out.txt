maml.exe CV tr=LogisticRegression{l1=1.0 l2=0.1 ot=1e-3 nt=1} threads=- dout=%Output% data=%Data% seed=1 xf=MeanVarNormalizer{col=Features}
Not adding a normalizer.
Warning: Skipped 8 instances with missing features/label/weight during training
Beginning optimization
num vars: 10
improvement criterion: Mean Improvement
L1 regularization selected 10 of 10 weights.
Not training a calibrator because it is not needed.
Not adding a normalizer.
Warning: Skipped 8 instances with missing features/label/weight during training
Beginning optimization
num vars: 10
improvement criterion: Mean Improvement
L1 regularization selected 9 of 10 weights.
Not training a calibrator because it is not needed.
Warning: The predictor produced non-finite prediction values on 8 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3785 (134.0/(134.0+220.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      129 |        5 | 0.9627
 negative ||        7 |      213 | 0.9682
          ||======================
Precision ||   0.9485 |   0.9771 |
OVERALL 0/1 ACCURACY: 0.966102
LOG LOSS/instance:  0.133256
Test-set entropy (prior Log-Loss/instance): 0.956998
LOG-LOSS REDUCTION (RIG): 86.075599
AUC:                0.994267
Warning: The predictor produced non-finite prediction values on 8 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3191 (105.0/(105.0+224.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||       96 |        9 | 0.9143
 negative ||        3 |      221 | 0.9866
          ||======================
Precision ||   0.9697 |   0.9609 |
OVERALL 0/1 ACCURACY: 0.963526
LOG LOSS/instance:  0.117263
Test-set entropy (prior Log-Loss/instance): 0.903454
LOG-LOSS REDUCTION (RIG): 87.020603
AUC:                0.997449

OVERALL RESULTS
---------------------------------------
AUC:                0.995858 (0.0016)
Accuracy:           0.964814 (0.0013)
Positive precision: 0.959113 (0.0106)
Positive recall:    0.938486 (0.0242)
Negative precision: 0.968967 (0.0081)
Negative recall:    0.977394 (0.0092)
Log-loss:           0.125260 (0.0080)
Log-loss reduction: 86.548101 (0.4725)
F1 Score:           0.948366 (0.0072)
AUPRC:              0.991982 (0.0025)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'Normalize' started.
[1] (%Time%)	337 examples
[1] 'Normalize' finished in %Time%.
[2] 'LBFGS data prep' started.
[2] 'LBFGS data prep' finished in %Time%.
[3] 'LBFGS Optimizer' started.
[3] (%Time%)	0 iterations	Loss: 0.6931471824646
[3] (%Time%)	1 iterations	Loss: 0.609836280345917	Improvement: 0.08331
[3] (%Time%)	2 iterations	Loss: 0.453598886728287	Improvement: 0.1417
[3] (%Time%)	3 iterations	Loss: 0.208579242229462	Improvement: 0.2204
[3] (%Time%)	4 iterations	Loss: 0.163409158587456	Improvement: 0.08846
[3] (%Time%)	5 iterations	Loss: 0.137612596154213	Improvement: 0.04142
[3] (%Time%)	6 iterations	Loss: 0.127675250172615	Improvement: 0.0178
[3] (%Time%)	7 iterations	Loss: 0.122048445045948	Improvement: 0.00867
[3] (%Time%)	8 iterations	Loss: 0.106239177286625	Improvement: 0.01402
[3] (%Time%)	9 iterations	Loss: 0.102952629327774	Improvement: 0.005971
[3] (%Time%)	10 iterations	Loss: 0.101699784398079	Improvement: 0.002432
[3] (%Time%)	11 iterations	Loss: 0.101042486727238	Improvement: 0.001101
[3] (%Time%)	12 iterations	Loss: 0.0998587012290955	Improvement: 0.001163
[3] (%Time%)	13 iterations	Loss: 0.0984053239226341	Improvement: 0.001381
[3] (%Time%)	14 iterations	Loss: 0.098227322101593	Improvement: 0.0004787
[3] 'LBFGS Optimizer' finished in %Time%.
[4] 'Normalize #2' started.
[4] (%Time%)	362 examples
[4] 'Normalize #2' finished in %Time%.
[5] 'LBFGS data prep #2' started.
[5] 'LBFGS data prep #2' finished in %Time%.
[6] 'LBFGS Optimizer #2' started.
[6] (%Time%)	0 iterations	Loss: 0.6931471824646
[6] (%Time%)	1 iterations	Loss: 0.6230149269104	Improvement: 0.07013
[6] (%Time%)	2 iterations	Loss: 0.562253773212433	Improvement: 0.06264
[6] (%Time%)	3 iterations	Loss: 0.330864667892456	Improvement: 0.1912
[6] (%Time%)	4 iterations	Loss: 0.184568345546722	Improvement: 0.1574
[6] (%Time%)	5 iterations	Loss: 0.153082638978958	Improvement: 0.06287
[6] (%Time%)	6 iterations	Loss: 0.136507406830788	Improvement: 0.02814
[6] (%Time%)	7 iterations	Loss: 0.129153579473495	Improvement: 0.01255
[6] (%Time%)	8 iterations	Loss: 0.121087253093719	Improvement: 0.009187
[6] (%Time%)	9 iterations	Loss: 0.116981714963913	Improvement: 0.005376
[6] (%Time%)	10 iterations	Loss: 0.112540066242218	Improvement: 0.004675
[6] (%Time%)	11 iterations	Loss: 0.111771121621132	Improvement: 0.001746
[6] (%Time%)	12 iterations	Loss: 0.111464805901051	Improvement: 0.0006661
[6] 'LBFGS Optimizer #2' finished in %Time%.
