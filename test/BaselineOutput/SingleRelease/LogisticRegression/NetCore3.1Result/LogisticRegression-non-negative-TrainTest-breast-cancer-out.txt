maml.exe TrainTest test=%Data% tr=LogisticRegression{l1=1.0 l2=0.1 ot=1e-4 nt=1 nn=+} norm=No dout=%Output% data=%Data% out=%Output% seed=1
Not adding a normalizer.
Warning: Skipped 16 instances with missing features/label/weight during training
Beginning optimization
num vars: 10
improvement criterion: Mean Improvement
L1 regularization selected 10 of 10 weights.
Not training a calibrator because it is not needed.
Warning: The predictor produced non-finite prediction values on 16 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3499 (239.0/(239.0+444.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      228 |       11 | 0.9540
 negative ||       10 |      434 | 0.9775
          ||======================
Precision ||   0.9580 |   0.9753 |
OVERALL 0/1 ACCURACY: 0.969253
LOG LOSS/instance:  0.109007
Test-set entropy (prior Log-Loss/instance): 0.934003
LOG-LOSS REDUCTION (RIG): 0.883291
AUC:                0.996287

OVERALL RESULTS
---------------------------------------
AUC:                0.996287 (0.0000)
Accuracy:           0.969253 (0.0000)
Positive precision: 0.957983 (0.0000)
Positive recall:    0.953975 (0.0000)
Negative precision: 0.975281 (0.0000)
Negative recall:    0.977477 (0.0000)
Log-loss:           0.109007 (0.0000)
Log-loss reduction: 0.883291 (0.0000)
F1 Score:           0.955975 (0.0000)
AUPRC:              0.992293 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'LBFGS data prep' started.
[1] 'LBFGS data prep' finished in %Time%.
[2] 'LBFGS Optimizer' started.
[2] (%Time%)	0 iterations	Loss: 0.6931471824645996
[2] (%Time%)	1 iterations	Loss: 0.6448327898979187	Improvement: 0.04831
[2] (%Time%)	2 iterations	Loss: 0.6306551098823547	Improvement: 0.02101
[2] (%Time%)	3 iterations	Loss: 0.6191107034683228	Improvement: 0.0138
[2] (%Time%)	4 iterations	Loss: 0.6139997243881226	Improvement: 0.007257
[2] (%Time%)	5 iterations	Loss: 0.6017452478408813	Improvement: 0.01101
[2] (%Time%)	6 iterations	Loss: 0.5552629232406616	Improvement: 0.03762
[2] (%Time%)	7 iterations	Loss: 0.40808025002479553	Improvement: 0.1198
[2] (%Time%)	8 iterations	Loss: 0.22476567327976227	Improvement: 0.1674
[2] (%Time%)	9 iterations	Loss: 0.17795756459236145	Improvement: 0.07696
[2] (%Time%)	10 iterations	Loss: 0.13737377524375916	Improvement: 0.04968
[2] (%Time%)	11 iterations	Loss: 0.11691863089799881	Improvement: 0.02776
[2] (%Time%)	12 iterations	Loss: 0.10186515003442764	Improvement: 0.01823
[2] (%Time%)	13 iterations	Loss: 0.09181062132120132	Improvement: 0.0121
[2] (%Time%)	14 iterations	Loss: 0.08791223913431168	Improvement: 0.005948
[2] (%Time%)	15 iterations	Loss: 0.08431486040353775	Improvement: 0.004185
[2] (%Time%)	16 iterations	Loss: 0.08275849372148514	Improvement: 0.002214
[2] (%Time%)	17 iterations	Loss: 0.08134783804416656	Improvement: 0.001611
[2] (%Time%)	18 iterations	Loss: 0.08036927133798599	Improvement: 0.001137
[2] (%Time%)	19 iterations	Loss: 0.07970956712961197	Improvement: 0.000779
[2] (%Time%)	20 iterations	Loss: 0.07952727377414703	Improvement: 0.0003315
[2] (%Time%)	21 iterations	Loss: 0.07951106876134872	Improvement: 9.502E-05
[2] 'LBFGS Optimizer' finished in %Time%.
[3] 'Saving model' started.
[3] 'Saving model' finished in %Time%.
