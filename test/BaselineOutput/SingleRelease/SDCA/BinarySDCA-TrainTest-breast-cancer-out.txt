maml.exe TrainTest test=%Data% tr=SDCA{maxIterations=5 checkFreq=9 nt=1} dout=%Output% data=%Data% out=%Output% seed=1
Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.
Using 1 thread to train.
Warning: Skipped 16 instances with missing features/label during training
Auto-tuning parameters: L2 = 0.01464129.
Auto-tuning parameters: L1Threshold (L1/L2) = 0.
Using model from last iteration.
Not training a calibrator because it is not needed.
Warning: The predictor produced non-finite prediction values on 16 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3499 (239.0/(239.0+444.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      222 |       17 | 0.9289
 negative ||        9 |      435 | 0.9797
          ||======================
Precision ||   0.9610 |   0.9624 |
OVERALL 0/1 ACCURACY: 0.961933
LOG LOSS/instance:  0.294964
Test-set entropy (prior Log-Loss/instance): 0.934003
LOG-LOSS REDUCTION (RIG): 68.419387
AUC:                0.995458

OVERALL RESULTS
---------------------------------------
AUC:                0.995458 (0.0000)
Accuracy:           0.961933 (0.0000)
Positive precision: 0.961039 (0.0000)
Positive recall:    0.928870 (0.0000)
Negative precision: 0.962389 (0.0000)
Negative recall:    0.979730 (0.0000)
Log-loss:           0.294964 (0.0000)
Log-loss reduction: 68.419387 (0.0000)
F1 Score:           0.944681 (0.0000)
AUPRC:              0.990716 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

