maml.exe TrainTest test=F:\data\MNIST\Train-28x28.txt tr=MulticlassLogisticRegression{l1=0.1 ot=0.0001 m=50 initwts=0.5} loader=TextLoader{col=Label:R4:0 col=Features:R4:1-784} data=F:\data\MNIST\Test-28x28.txt
Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.
Beginning optimization
   num vars: 7850
   term criterion: Mean Improvement

Iter n: new_value (term_crit)
-------------------------------------------------
Iter 0: 3.0467e0 (**********) 
Iter 1: 2.3126e0 (7.341e-1) 
Iter 2: 1.9263e0 (4.559e-1) 
Iter 3: 1.0942e0 (7.425e-1) 
Iter 4: 9.3911e-1 (3.002e-1) 
Iter 5: 6.7632e-1 (2.721e-1) 
Iter 6: 6.1328e-1 (1.153e-1) 
Iter 7: 5.6051e-1 (6.840e-2) 
Iter 8: 4.9942e-1 (6.292e-2) 
Iter 9: 4.5021e-1 (5.263e-2) 
Iter 10: 4.3244e-1 (2.649e-2) 
Iter 11: 4.0529e-1 (2.699e-2) 
Iter 12: 3.7786e-1 (2.731e-2) 
Iter 13: 3.5483e-1 (2.411e-2) 
Iter 14: 3.4148e-1 (1.604e-2) 
Iter 15: 3.3315e-1 (1.026e-2) 
Iter 16: 3.2174e-1 (1.112e-2) 
Iter 17: 3.1594e-1 (7.132e-3) 
Iter 18: 2.9268e-1 (1.923e-2) 
Iter 19: 2.8425e-1 (1.113e-2) 
Iter 20: 2.7569e-1 (9.197e-3) 
Iter 21: 2.6950e-1 (6.945e-3) 
Iter 22: 2.6142e-1 (7.797e-3) 
Iter 23: 2.5391e-1 (7.581e-3) 
Iter 24: 2.4866e-1 (5.832e-3) 
Iter 25: 2.4389e-1 (5.037e-3) 
Iter 26: 2.3889e-1 (5.010e-3) 
Iter 27: 2.3575e-1 (3.606e-3) 
Iter 28: 2.3034e-1 (4.959e-3) 
Iter 29: 2.2705e-1 (3.706e-3) 
Iter 30: 2.2183e-1 (4.840e-3) 
Iter 31: 2.1539e-1 (6.039e-3) 
Iter 32: 2.1053e-1 (5.154e-3) 
Iter 33: 2.0733e-1 (3.695e-3) 
Iter 34: 2.0465e-1 (2.932e-3) 
Iter 35: 2.0122e-1 (3.306e-3) 
Iter 36: 1.9755e-1 (3.578e-3) 
Iter 37: 1.9542e-1 (2.490e-3) 
Iter 38: 1.9264e-1 (2.709e-3) 
Iter 39: 1.9075e-1 (2.097e-3) 
Iter 40: 1.8856e-1 (2.166e-3) 
Iter 41: 1.8637e-1 (2.182e-3) 
Iter 42: 1.8486e-1 (1.682e-3) 
Iter 43: 1.8327e-1 (1.611e-3) 
Iter 44: 1.8152e-1 (1.714e-3) 
Iter 45: 1.8033e-1 (1.324e-3) 
Iter 46: 1.7920e-1 (1.173e-3) 
Iter 47: 1.7791e-1 (1.264e-3) 
Iter 48: 1.7672e-1 (1.208e-3) 
Iter 49: 1.7579e-1 (9.970e-4) 
Iter 50: 1.7500e-1 (8.485e-4) 
Iter 51: 1.7418e-1 (8.254e-4) 
Iter 52: 1.7347e-1 (7.388e-4) 
Iter 53: 1.7299e-1 (5.468e-4) 
Iter 54: 1.7263e-1 (4.038e-4) 
Iter 55: 1.7227e-1 (3.671e-4) 
Iter 56: 1.7190e-1 (3.723e-4) 
Iter 57: 1.7162e-1 (3.038e-4) 
Iter 58: 1.7161e-1 (8.483e-5)
L1 regularization selected 5895 of 7850 weights.
Not training a calibrator because it is not needed.

 Confusion table (sampled)
          ||================================================================================
PREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 | Recall
TRUTH     ||========================================================================================
       0  ||  5615 |     1 |    40 |    25 |    30 |    63 |    56 |     7 |    63 |    23 | 0.948
       1  ||     2 |  6533 |    40 |    17 |     9 |    44 |     5 |    22 |    55 |    15 | 0.969
       2  ||    31 |    72 |  5260 |    92 |   120 |    45 |    89 |   108 |   107 |    34 | 0.883
       3  ||    22 |    40 |   199 |  5209 |     8 |   299 |    30 |    81 |   136 |   107 | 0.850
       4  ||    19 |    20 |    70 |    14 |  5324 |    10 |    50 |    42 |    59 |   234 | 0.911
       5  ||    63 |    43 |    52 |   160 |    96 |  4605 |   142 |    28 |   161 |    71 | 0.849
       6  ||    39 |    28 |    95 |     2 |    51 |    74 |  5566 |    10 |    46 |     7 | 0.941
       7  ||    43 |    30 |    52 |    26 |    62 |    27 |     6 |  5778 |    23 |   218 | 0.922
       8  ||    36 |   169 |   154 |   184 |    28 |   221 |    72 |    21 |  4851 |   115 | 0.829
       9  ||    45 |    28 |    43 |    98 |   211 |    43 |     2 |   278 |    46 |  5155 | 0.867
      ======================================================================================
Precision || 0.949 | 0.938 | 0.876 | 0.894 | 0.896 | 0.848 | 0.925 | 0.906 | 0.875 | 0.862 |

ACCURACY(micro-avg):     0.898267
ACCURACY(macro-avg):     0.896868
LOG-LOSS:                0.379819
LOG-LOSS REDUCTION:      83.494453

OVERALL RESULTS
---------------------------------------
ACCURACY(micro-avg): 0.8983 (0.0000)
ACCURACY(macro-avg): 0.8969 (0.0000)
LOG-LOSS:            0.3798 (0.0000)
LOG-LOSS REDUCTION: 83.4945 (0.0000)

---------------------------------------
2/1/2016 4:37:26 PM	 Time elapsed(s): 1.673

