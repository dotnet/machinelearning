maml.exe TrainTest test=F:\data\MNIST\Train-28x28.txt tr=MulticlassLogisticRegression{initwts=0.1} loader=TextLoader{col=Label:R4:0 col=Features:R4:1-784} data=F:\data\MNIST\Test-28x28.txt
Automatically adding a MinMax normalization transform, use 'norm=Warn' or 'norm=No' to turn this behavior off.
Beginning optimization
   num vars: 7850
   term criterion: Mean Improvement

Iter n: new_value (term_crit)
-------------------------------------------------
Iter 0: 2.3822e0 (**********) 
Iter 1: 1.7607e0 (6.216e-1) 
Iter 2: 1.1305e0 (6.285e-1) 
Iter 3: 8.2753e-1 (3.805e-1) 
Iter 4: 6.0957e-1 (2.581e-1) 
Iter 5: 5.5368e-1 (1.063e-1) 
Iter 6: 5.0716e-1 (6.145e-2) 
Iter 7: 4.7295e-1 (4.102e-2) 
Iter 8: 4.4419e-1 (3.182e-2) 
Iter 9: 4.3079e-1 (1.801e-2) 
Iter 10: 4.1137e-1 (1.907e-2) 
Iter 11: 3.9589e-1 (1.637e-2) 
Iter 12: 3.8117e-1 (1.514e-2) 
Iter 13: 3.6847e-1 (1.331e-2) 
Iter 14: 3.5857e-1 (1.075e-2) 
Iter 15: 3.5147e-1 (8.014e-3) 
Iter 16: 3.4236e-1 (8.834e-3) 
Iter 17: 3.3250e-1 (9.606e-3) 
Iter 18: 3.2422e-1 (8.610e-3) 
Iter 19: 3.1859e-1 (6.376e-3) 
Iter 20: 3.1350e-1 (5.413e-3) 
Iter 21: 3.0971e-1 (4.193e-3) 
Iter 22: 3.0383e-1 (5.465e-3) 
Iter 23: 3.0067e-1 (3.732e-3) 
Iter 24: 2.9670e-1 (3.909e-3) 
Iter 25: 2.9438e-1 (2.720e-3) 
Iter 26: 2.9151e-1 (2.831e-3) 
Iter 27: 2.8966e-1 (2.094e-3) 
Iter 28: 2.8799e-1 (1.781e-3) 
Iter 29: 2.8529e-1 (2.471e-3) .
Iter 30: 2.8414e-1 (1.477e-3) 
Iter 31: 2.8206e-1 (1.932e-3) 
Iter 32: 2.8056e-1 (1.606e-3) 
Iter 33: 2.7910e-1 (1.498e-3) 
Iter 34: 2.7772e-1 (1.409e-3) 
Iter 35: 2.7670e-1 (1.116e-3) 
Iter 36: 2.7529e-1 (1.338e-3) 
Iter 37: 2.7458e-1 (8.654e-4) 
Iter 38: 2.7338e-1 (1.115e-3) 
Iter 39: 2.7182e-1 (1.450e-3) 
Iter 40: 2.7128e-1 (7.635e-4) 
Iter 41: 2.6939e-1 (1.614e-3) 
Iter 42: 2.6872e-1 (9.009e-4) 
Iter 43: 2.6802e-1 (7.528e-4) 
Iter 44: 2.6707e-1 (8.997e-4) 
Iter 45: 2.6617e-1 (8.978e-4) 
Iter 46: 2.6553e-1 (7.043e-4) 
Iter 47: 2.6490e-1 (6.528e-4) 
Iter 48: 2.6455e-1 (4.264e-4) 
Iter 49: 2.6391e-1 (5.871e-4) 
Iter 50: 2.6339e-1 (5.327e-4) 
Iter 51: 2.6308e-1 (3.660e-4) 
Iter 52: 2.6249e-1 (5.330e-4) 
Iter 53: 2.6216e-1 (3.837e-4) 
Iter 54: 2.6152e-1 (5.788e-4) 
Iter 55: 2.6130e-1 (3.090e-4) 
Iter 56: 2.6106e-1 (2.548e-4) 
Iter 57: 2.6068e-1 (3.473e-4) 
Iter 58: 2.6034e-1 (3.415e-4) 
Iter 59: 2.6002e-1 (3.252e-4) 
Iter 60: 2.5957e-1 (4.199e-4) 
Iter 61: 2.5918e-1 (3.993e-4) 
Iter 62: 2.5885e-1 (3.486e-4) 
Iter 63: 2.5864e-1 (2.440e-4) 
Iter 64: 2.5834e-1 (2.844e-4) 
Iter 65: 2.5819e-1 (1.862e-4) 
Iter 66: 2.5795e-1 (2.232e-4) 
Iter 67: 2.5771e-1 (2.378e-4) 
Iter 68: 2.5749e-1 (2.259e-4) 
Iter 69: 2.5724e-1 (2.380e-4) 
Iter 70: 2.5700e-1 (2.419e-4) 
Iter 71: 2.5682e-1 (1.975e-4) 
Iter 72: 2.5653e-1 (2.651e-4) 
Iter 73: 2.5637e-1 (1.903e-4) 
Iter 74: 2.5625e-1 (1.348e-4) 
Iter 75: 2.5616e-1 (1.021e-4) 
Iter 76: 2.5603e-1 (1.206e-4) 
Iter 77: 2.5592e-1 (1.119e-4) 
Iter 78: 2.5578e-1 (1.345e-4) 
Iter 79: 2.5569e-1 (9.794e-5) 
Iter 80: 2.5560e-1 (9.342e-5) 
Iter 81: 2.5555e-1 (5.992e-5) 
Iter 82: 2.5552e-1 (4.220e-5) 
Iter 83: 2.5545e-1 (6.285e-5) 
Iter 84: 2.5536e-1 (8.324e-5) 
Iter 85: 2.5530e-1 (6.185e-5) 
Iter 86: 2.5523e-1 (7.034e-5) 
Iter 87: 2.5515e-1 (7.836e-5) 
Iter 88: 2.5511e-1 (4.487e-5) 
Iter 89: 2.5508e-1 (3.717e-5) 
Iter 90: 2.5506e-1 (2.733e-5) 
Iter 91: 2.5499e-1 (5.972e-5) 
Iter 92: 2.5494e-1 (4.852e-5) 
Iter 93: 2.5486e-1 (7.557e-5) 
Iter 94: 2.5481e-1 (5.182e-5) 
Iter 95: 2.5478e-1 (3.944e-5) 
Iter 96: 2.5472e-1 (5.199e-5) 
Iter 97: 2.5466e-1 (6.170e-5) 
Iter 98: 2.5461e-1 (4.674e-5) 
Iter 99: 2.5454e-1 (6.430e-5) 
Iter 100: 2.5454e-1 (1.981e-5) 
Iter 101: 2.5450e-1 (3.448e-5) 
Iter 102: 2.5449e-1 (1.510e-5) .
Iter 103: 2.5445e-1 (3.444e-5) 
Iter 104: 2.5441e-1 (3.713e-5) 
Iter 105: 2.5439e-1 (2.873e-5) 
Iter 106: 2.5436e-1 (3.056e-5) 
Iter 107: 2.5430e-1 (4.633e-5) 
Iter 108: 2.5428e-1 (3.103e-5) 
Iter 109: 2.5424e-1 (3.371e-5) 
Iter 110: 2.5422e-1 (2.573e-5) 
Iter 111: 2.5419e-1 (3.187e-5) 
Iter 112: 2.5416e-1 (2.719e-5) 
Iter 113: 2.5414e-1 (2.287e-5) 
Iter 114: 2.5410e-1 (3.124e-5) 
Iter 115: 2.5408e-1 (2.782e-5) 
Iter 116: 2.5404e-1 (3.420e-5) 
Iter 117: 2.5402e-1 (2.283e-5) 
Iter 118: 2.5401e-1 (1.668e-5) 
Iter 119: 2.5399e-1 (1.675e-5) 
Iter 120: 2.5397e-1 (2.287e-5) 
Iter 121: 2.5396e-1 (1.292e-5) 
Iter 122: 2.5393e-1 (2.279e-5) 
Iter 123: 2.5392e-1 (1.354e-5) 
Iter 124: 2.5390e-1 (1.610e-5) 
Iter 125: 2.5389e-1 (1.145e-5) 
Iter 126: 2.5387e-1 (1.824e-5) 
Iter 127: 2.5386e-1 (1.323e-5) 
Iter 128: 2.5385e-1 (1.118e-5) 
Iter 129: 2.5385e-1 (5.990e-6) 
Iter 130: 2.5384e-1 (9.097e-6) 
Iter 131: 2.5381e-1 (1.926e-5) 
Iter 132: 2.5380e-1 (1.628e-5) 
Iter 133: 2.5379e-1 (1.209e-5) 
Iter 134: 2.5378e-1 (1.194e-5) 
Iter 135: 2.5377e-1 (5.869e-6) 
Iter 136: 2.5377e-1 (4.708e-6) 
Iter 137: 2.5376e-1 (6.743e-6) 
Iter 138: 2.5376e-1 (5.508e-6) 
Iter 139: 2.5375e-1 (3.702e-6) 
Iter 140: 2.5375e-1 (3.138e-6) 
Iter 141: 2.5374e-1 (1.004e-5) 
Iter 142: 2.5373e-1 (8.813e-6) 
Iter 143: 2.5372e-1 (8.462e-6) 
Iter 144: 2.5371e-1 (8.240e-6) 
Iter 145: 2.5371e-1 (6.173e-6) 
Iter 146: 2.5370e-1 (5.343e-6) 
Iter 147: 2.5370e-1 (4.621e-6) 
Iter 148: 2.5370e-1 (2.161e-6) 
Iter 149: 2.5369e-1 (2.686e-6) .
Iter 150: 2.5369e-1 (2.013e-6) 
Iter 151: 2.5369e-1 (4.906e-6) 
Iter 152: 2.5368e-1 (4.177e-6) .
Iter 153: 2.5368e-1 (4.464e-6) 
Iter 154: 2.5367e-1 (4.178e-6) 
Iter 155: 2.5367e-1 (2.855e-6) 
Iter 156: 2.5367e-1 (1.876e-6) .
Iter 157: 2.5367e-1 (1.520e-6) 
Iter 158: 2.5367e-1 (2.034e-6) .
Iter 159: 2.5366e-1 (1.380e-6) 
Iter 160: 2.5366e-1 (3.743e-6) 
Iter 161: 2.5365e-1 (5.048e-6) .
Iter 162: 2.5365e-1 (3.095e-6) 
Iter 163: 2.5365e-1 (2.383e-6) .
Iter 164: 2.5365e-1 (7.299e-7) 
Iter 165: 2.5365e-1 (3.166e-7) .
Iter 166: 2.5365e-1 (7.944e-7) 
Iter 167: 2.5364e-1 (2.613e-6) 
Iter 168: 2.5364e-1 (1.257e-6) .
Iter 169: 2.5364e-1 (2.415e-6) .
Iter 170: 2.5364e-1 (2.012e-6) 
Iter 171: 2.5364e-1 (2.068e-6) 
Iter 172: 2.5364e-1 (7.181e-7) 
Iter 173: 2.5363e-1 (2.102e-6) 
Iter 174: 2.5363e-1 (1.889e-6) 
Iter 175: 2.5363e-1 (3.311e-6) 
Iter 176: 2.5363e-1 (1.208e-6) 
Iter 177: 2.5363e-1 (1.554e-6) 
Iter 178: 2.5363e-1 (1.171e-6) .
Iter 179: 2.5362e-1 (2.751e-6) .
Iter 180: 2.5362e-1 (1.828e-6) 
Iter 181: 2.5362e-1 (1.217e-6) 
Iter 182: 2.5362e-1 (9.748e-7) 
Iter 183: 2.5362e-1 (1.674e-6) 
Iter 184: 2.5362e-1 (1.558e-6) 
Iter 185: 2.5361e-1 (2.245e-6) .
Iter 186: 2.5361e-1 (7.400e-7) 
Iter 187: 2.5361e-1 (3.191e-7) .
Iter 188: 2.5361e-1 (1.915e-7) .
Iter 189: 2.5361e-1 (1.255e-6) 
Iter 190: 2.5361e-1 (1.185e-6) 
Iter 191: 2.5361e-1 (1.146e-6) .
Iter 192: 2.5361e-1 (3.758e-7) .
Iter 193: 2.5361e-1 (1.834e-7) 
Iter 194: 2.5361e-1 (1.387e-6) .
Iter 195: 2.5360e-1 (2.068e-6) .
Iter 196: 2.5360e-1 (9.193e-7) .
Iter 197: 2.5360e-1 (2.969e-7) 
Iter 198: 2.5360e-1 (1.549e-6) 
Iter 199: 2.5360e-1 (9.685e-7) .
Iter 200: 2.5360e-1 (1.784e-6) 
Iter 201: 2.5360e-1 (2.145e-6) 
Iter 202: 2.5359e-1 (2.458e-6) .
Iter 203: 2.5359e-1 (9.499e-7) 
Iter 204: 2.5359e-1 (8.186e-7) 
Iter 205: 2.5359e-1 (8.529e-7) 
Iter 206: 2.5359e-1 (6.155e-7) .
Iter 207: 2.5359e-1 (8.468e-7) 
Iter 208: 2.5359e-1 (1.687e-6) 
Iter 209: 2.5359e-1 (9.582e-7) 
Iter 210: 2.5359e-1 (6.419e-7) 
Iter 211: 2.5359e-1 (4.287e-7) .
Iter 212: 2.5359e-1 (1.091e-6) 
Iter 213: 2.5359e-1 (2.727e-7) .
Iter 214: 2.5359e-1 (6.817e-8)
L1 regularization selected 2450 of 7850 weights.
Not training a calibrator because it is not needed.

 Confusion table (sampled)
          ||================================================================================
PREDICTED ||     0 |     1 |     2 |     3 |     4 |     5 |     6 |     7 |     8 |     9 | Recall
TRUTH     ||========================================================================================
       0  ||  5632 |     1 |    33 |    27 |    27 |    60 |    50 |     6 |    67 |    20 | 0.951
       1  ||     2 |  6538 |    33 |    20 |     7 |    51 |     2 |    24 |    51 |    14 | 0.970
       2  ||    28 |    73 |  5257 |    90 |   119 |    37 |    88 |   112 |   119 |    35 | 0.882
       3  ||    17 |    44 |   185 |  5247 |     6 |   290 |    36 |    80 |   125 |   101 | 0.856
       4  ||    15 |    25 |    61 |    12 |  5336 |     7 |    52 |    32 |    51 |   251 | 0.913
       5  ||    57 |    62 |    55 |   165 |    83 |  4629 |   132 |    23 |   143 |    72 | 0.854
       6  ||    35 |    32 |    77 |     3 |    46 |    75 |  5590 |     8 |    43 |     9 | 0.945
       7  ||    43 |    37 |    53 |    20 |    65 |    21 |     9 |  5778 |    19 |   220 | 0.922
       8  ||    36 |   195 |   124 |   154 |    24 |   206 |    72 |    25 |  4903 |   112 | 0.838
       9  ||    50 |    33 |    34 |    94 |   175 |    44 |     3 |   249 |    50 |  5217 | 0.877
      ======================================================================================
Precision || 0.952 | 0.929 | 0.889 | 0.900 | 0.906 | 0.854 | 0.926 | 0.912 | 0.880 | 0.862 |

ACCURACY(micro-avg):     0.902117
ACCURACY(macro-avg):     0.900783
LOG-LOSS:                0.346450
LOG-LOSS REDUCTION:      84.944565

OVERALL RESULTS
---------------------------------------
ACCURACY(micro-avg): 0.9021 (0.0000)
ACCURACY(macro-avg): 0.9008 (0.0000)
LOG-LOSS:            0.3464 (0.0000)
LOG-LOSS REDUCTION: 84.9446 (0.0000)

---------------------------------------
2/1/2016 4:37:04 PM	 Time elapsed(s): 2.99

