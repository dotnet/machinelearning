maml.exe TrainTest test=%Data% tr=LogisticRegression{l1=1.0 l2=0.1 ot=1e-3 nt=1} dout=%Output% data=%Data% out=%Output% seed=1 xf=BinNormalizer{col=Features numBins=5}
Not adding a normalizer.
Warning: Skipped 16 instances with missing features/label/weight during training
Beginning optimization
num vars: 10
improvement criterion: Mean Improvement
L1 regularization selected 9 of 10 weights.
Not training a calibrator because it is not needed.
Warning: The predictor produced non-finite prediction values on 16 instances during testing. Possible causes: abnormal data or the predictor is numerically unstable.
TEST POSITIVE RATIO:	0.3499 (239.0/(239.0+444.0))
Confusion table
          ||======================
PREDICTED || positive | negative | Recall
TRUTH     ||======================
 positive ||      232 |        7 | 0.9707
 negative ||       10 |      434 | 0.9775
          ||======================
Precision ||   0.9587 |   0.9841 |
OVERALL 0/1 ACCURACY: 0.975110
LOG LOSS/instance:  0.116898
Test-set entropy (prior Log-Loss/instance): 0.934003
LOG-LOSS REDUCTION (RIG): 87.484240
AUC:                0.995208

OVERALL RESULTS
---------------------------------------
AUC:                0.995208 (0.0000)
Accuracy:           0.975110 (0.0000)
Positive precision: 0.958678 (0.0000)
Positive recall:    0.970711 (0.0000)
Negative precision: 0.984127 (0.0000)
Negative recall:    0.977477 (0.0000)
Log-loss:           0.116898 (0.0000)
Log-loss reduction: 87.484240 (0.0000)
F1 Score:           0.964657 (0.0000)
AUPRC:              0.990065 (0.0000)

---------------------------------------
Physical memory usage(MB): %Number%
Virtual memory usage(MB): %Number%
%DateTime%	 Time elapsed(s): %Number%

--- Progress log ---
[1] 'Normalize' started.
[1] (%Time%)	699 examples
[1] 'Normalize' finished in %Time%.
[2] 'LBFGS data prep' started.
[2] 'LBFGS data prep' finished in %Time%.
[3] 'LBFGS Optimizer' started.
[3] (%Time%)	0 iterations	Loss: 0.6931471824646
[3] (%Time%)	1 iterations	Loss: 0.477002263069153	Improvement: 0.2161
[3] (%Time%)	2 iterations	Loss: 0.188543751835823	Improvement: 0.274
[3] (%Time%)	3 iterations	Loss: 0.141727969050407	Improvement: 0.1009
[3] (%Time%)	4 iterations	Loss: 0.124061115086079	Improvement: 0.03823
[3] (%Time%)	5 iterations	Loss: 0.113580599427223	Improvement: 0.0174
[3] (%Time%)	6 iterations	Loss: 0.107943221926689	Improvement: 0.008575
[3] (%Time%)	7 iterations	Loss: 0.105579644441605	Improvement: 0.003916
[3] (%Time%)	8 iterations	Loss: 0.105318680405617	Improvement: 0.001175
[3] (%Time%)	9 iterations	Loss: 0.105102367699146	Improvement: 0.0004559
[3] 'LBFGS Optimizer' finished in %Time%.
[4] 'Saving model' started.
[4] 'Saving model' finished in %Time%.
