//------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
//------------------------------------------------------------------------------
#pragma warning disable
using System.Collections.Generic;
using Microsoft.ML.Runtime;
using Microsoft.ML.Runtime.Data;
using Microsoft.ML.Runtime.EntryPoints;
using Newtonsoft.Json;
using System;
using System.Linq;
using Microsoft.ML.Runtime.CommandLine;

namespace Microsoft.ML
{
    namespace Runtime
    {
        public sealed partial class Experiment
        {
            public Microsoft.ML.Legacy.Data.CustomTextLoader.Output Add(Microsoft.ML.Legacy.Data.CustomTextLoader input)
            {
                var output = new Microsoft.ML.Legacy.Data.CustomTextLoader.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Data.CustomTextLoader input, Microsoft.ML.Legacy.Data.CustomTextLoader.Output output)
            {
                _jsonNodes.Add(Serialize("Data.CustomTextLoader", input, output));
            }

            public Microsoft.ML.Legacy.Data.DataViewReference.Output Add(Microsoft.ML.Legacy.Data.DataViewReference input)
            {
                var output = new Microsoft.ML.Legacy.Data.DataViewReference.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Data.DataViewReference input, Microsoft.ML.Legacy.Data.DataViewReference.Output output)
            {
                _jsonNodes.Add(Serialize("Data.DataViewReference", input, output));
            }

            public Microsoft.ML.Legacy.Data.IDataViewArrayConverter.Output Add(Microsoft.ML.Legacy.Data.IDataViewArrayConverter input)
            {
                var output = new Microsoft.ML.Legacy.Data.IDataViewArrayConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Data.IDataViewArrayConverter input, Microsoft.ML.Legacy.Data.IDataViewArrayConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Data.IDataViewArrayConverter", input, output));
            }

            public Microsoft.ML.Legacy.Data.PredictorModelArrayConverter.Output Add(Microsoft.ML.Legacy.Data.PredictorModelArrayConverter input)
            {
                var output = new Microsoft.ML.Legacy.Data.PredictorModelArrayConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Data.PredictorModelArrayConverter input, Microsoft.ML.Legacy.Data.PredictorModelArrayConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Data.PredictorModelArrayConverter", input, output));
            }

            public Microsoft.ML.Legacy.Data.TextLoader.Output Add(Microsoft.ML.Legacy.Data.TextLoader input)
            {
                var output = new Microsoft.ML.Legacy.Data.TextLoader.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Data.TextLoader input, Microsoft.ML.Legacy.Data.TextLoader.Output output)
            {
                _jsonNodes.Add(Serialize("Data.TextLoader", input, output));
            }

            public Microsoft.ML.Legacy.Data.TransformModelArrayConverter.Output Add(Microsoft.ML.Legacy.Data.TransformModelArrayConverter input)
            {
                var output = new Microsoft.ML.Legacy.Data.TransformModelArrayConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Data.TransformModelArrayConverter input, Microsoft.ML.Legacy.Data.TransformModelArrayConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Data.TransformModelArrayConverter", input, output));
            }

            public Microsoft.ML.Legacy.Models.AnomalyDetectionEvaluator.Output Add(Microsoft.ML.Legacy.Models.AnomalyDetectionEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.AnomalyDetectionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.AnomalyDetectionEvaluator input, Microsoft.ML.Legacy.Models.AnomalyDetectionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.AnomalyDetectionEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.AnomalyPipelineEnsemble.Output Add(Microsoft.ML.Legacy.Models.AnomalyPipelineEnsemble input)
            {
                var output = new Microsoft.ML.Legacy.Models.AnomalyPipelineEnsemble.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.AnomalyPipelineEnsemble input, Microsoft.ML.Legacy.Models.AnomalyPipelineEnsemble.Output output)
            {
                _jsonNodes.Add(Serialize("Models.AnomalyPipelineEnsemble", input, output));
            }

            public Microsoft.ML.Legacy.Models.BinaryClassificationEvaluator.Output Add(Microsoft.ML.Legacy.Models.BinaryClassificationEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.BinaryClassificationEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.BinaryClassificationEvaluator input, Microsoft.ML.Legacy.Models.BinaryClassificationEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.BinaryClassificationEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.BinaryCrossValidator.Output Add(Microsoft.ML.Legacy.Models.BinaryCrossValidator input)
            {
                var output = new Microsoft.ML.Legacy.Models.BinaryCrossValidator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.BinaryCrossValidator input, Microsoft.ML.Legacy.Models.BinaryCrossValidator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.BinaryCrossValidator", input, output));
            }

            public Microsoft.ML.Legacy.Models.BinaryEnsemble.Output Add(Microsoft.ML.Legacy.Models.BinaryEnsemble input)
            {
                var output = new Microsoft.ML.Legacy.Models.BinaryEnsemble.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.BinaryEnsemble input, Microsoft.ML.Legacy.Models.BinaryEnsemble.Output output)
            {
                _jsonNodes.Add(Serialize("Models.BinaryEnsemble", input, output));
            }

            public Microsoft.ML.Legacy.Models.BinaryPipelineEnsemble.Output Add(Microsoft.ML.Legacy.Models.BinaryPipelineEnsemble input)
            {
                var output = new Microsoft.ML.Legacy.Models.BinaryPipelineEnsemble.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.BinaryPipelineEnsemble input, Microsoft.ML.Legacy.Models.BinaryPipelineEnsemble.Output output)
            {
                _jsonNodes.Add(Serialize("Models.BinaryPipelineEnsemble", input, output));
            }

            public Microsoft.ML.Legacy.Models.ClassificationEvaluator.Output Add(Microsoft.ML.Legacy.Models.ClassificationEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.ClassificationEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.ClassificationEvaluator input, Microsoft.ML.Legacy.Models.ClassificationEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.ClassificationEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.ClusterEvaluator.Output Add(Microsoft.ML.Legacy.Models.ClusterEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.ClusterEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.ClusterEvaluator input, Microsoft.ML.Legacy.Models.ClusterEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.ClusterEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.CrossValidationResultsCombiner.Output Add(Microsoft.ML.Legacy.Models.CrossValidationResultsCombiner input)
            {
                var output = new Microsoft.ML.Legacy.Models.CrossValidationResultsCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.CrossValidationResultsCombiner input, Microsoft.ML.Legacy.Models.CrossValidationResultsCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Models.CrossValidationResultsCombiner", input, output));
            }

            public Microsoft.ML.Legacy.Models.CrossValidator.Output Add(Microsoft.ML.Legacy.Models.CrossValidator input)
            {
                var output = new Microsoft.ML.Legacy.Models.CrossValidator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.CrossValidator input, Microsoft.ML.Legacy.Models.CrossValidator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.CrossValidator", input, output));
            }

            public Microsoft.ML.Legacy.Models.CrossValidatorDatasetSplitter.Output Add(Microsoft.ML.Legacy.Models.CrossValidatorDatasetSplitter input)
            {
                var output = new Microsoft.ML.Legacy.Models.CrossValidatorDatasetSplitter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.CrossValidatorDatasetSplitter input, Microsoft.ML.Legacy.Models.CrossValidatorDatasetSplitter.Output output)
            {
                _jsonNodes.Add(Serialize("Models.CrossValidatorDatasetSplitter", input, output));
            }

            public Microsoft.ML.Legacy.Models.DatasetTransformer.Output Add(Microsoft.ML.Legacy.Models.DatasetTransformer input)
            {
                var output = new Microsoft.ML.Legacy.Models.DatasetTransformer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.DatasetTransformer input, Microsoft.ML.Legacy.Models.DatasetTransformer.Output output)
            {
                _jsonNodes.Add(Serialize("Models.DatasetTransformer", input, output));
            }

            public Microsoft.ML.Legacy.Models.EnsembleSummary.Output Add(Microsoft.ML.Legacy.Models.EnsembleSummary input)
            {
                var output = new Microsoft.ML.Legacy.Models.EnsembleSummary.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.EnsembleSummary input, Microsoft.ML.Legacy.Models.EnsembleSummary.Output output)
            {
                _jsonNodes.Add(Serialize("Models.EnsembleSummary", input, output));
            }

            public Microsoft.ML.Legacy.Models.FixedPlattCalibrator.Output Add(Microsoft.ML.Legacy.Models.FixedPlattCalibrator input)
            {
                var output = new Microsoft.ML.Legacy.Models.FixedPlattCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.FixedPlattCalibrator input, Microsoft.ML.Legacy.Models.FixedPlattCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.FixedPlattCalibrator", input, output));
            }

            public Microsoft.ML.Legacy.Models.MultiClassPipelineEnsemble.Output Add(Microsoft.ML.Legacy.Models.MultiClassPipelineEnsemble input)
            {
                var output = new Microsoft.ML.Legacy.Models.MultiClassPipelineEnsemble.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.MultiClassPipelineEnsemble input, Microsoft.ML.Legacy.Models.MultiClassPipelineEnsemble.Output output)
            {
                _jsonNodes.Add(Serialize("Models.MultiClassPipelineEnsemble", input, output));
            }

            public Microsoft.ML.Legacy.Models.MultiOutputRegressionEvaluator.Output Add(Microsoft.ML.Legacy.Models.MultiOutputRegressionEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.MultiOutputRegressionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.MultiOutputRegressionEvaluator input, Microsoft.ML.Legacy.Models.MultiOutputRegressionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.MultiOutputRegressionEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.NaiveCalibrator.Output Add(Microsoft.ML.Legacy.Models.NaiveCalibrator input)
            {
                var output = new Microsoft.ML.Legacy.Models.NaiveCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.NaiveCalibrator input, Microsoft.ML.Legacy.Models.NaiveCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.NaiveCalibrator", input, output));
            }

            public Microsoft.ML.Legacy.Models.OneVersusAll.Output Add(Microsoft.ML.Legacy.Models.OneVersusAll input)
            {
                var output = new Microsoft.ML.Legacy.Models.OneVersusAll.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.OneVersusAll input, Microsoft.ML.Legacy.Models.OneVersusAll.Output output)
            {
                _jsonNodes.Add(Serialize("Models.OneVersusAll", input, output));
            }

            public Microsoft.ML.Legacy.Models.OnnxConverter.Output Add(Microsoft.ML.Legacy.Models.OnnxConverter input)
            {
                var output = new Microsoft.ML.Legacy.Models.OnnxConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.OnnxConverter input, Microsoft.ML.Legacy.Models.OnnxConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Models.OnnxConverter", input, output));
            }

            public Microsoft.ML.Legacy.Models.OvaModelCombiner.Output Add(Microsoft.ML.Legacy.Models.OvaModelCombiner input)
            {
                var output = new Microsoft.ML.Legacy.Models.OvaModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.OvaModelCombiner input, Microsoft.ML.Legacy.Models.OvaModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Models.OvaModelCombiner", input, output));
            }

            public Microsoft.ML.Legacy.Models.PAVCalibrator.Output Add(Microsoft.ML.Legacy.Models.PAVCalibrator input)
            {
                var output = new Microsoft.ML.Legacy.Models.PAVCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.PAVCalibrator input, Microsoft.ML.Legacy.Models.PAVCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.PAVCalibrator", input, output));
            }

            public Microsoft.ML.Legacy.Models.PipelineSweeper.Output Add(Microsoft.ML.Legacy.Models.PipelineSweeper input)
            {
                var output = new Microsoft.ML.Legacy.Models.PipelineSweeper.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.PipelineSweeper input, Microsoft.ML.Legacy.Models.PipelineSweeper.Output output)
            {
                _jsonNodes.Add(Serialize("Models.PipelineSweeper", input, output));
            }

            public Microsoft.ML.Legacy.Models.PlattCalibrator.Output Add(Microsoft.ML.Legacy.Models.PlattCalibrator input)
            {
                var output = new Microsoft.ML.Legacy.Models.PlattCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.PlattCalibrator input, Microsoft.ML.Legacy.Models.PlattCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.PlattCalibrator", input, output));
            }

            public Microsoft.ML.Legacy.Models.QuantileRegressionEvaluator.Output Add(Microsoft.ML.Legacy.Models.QuantileRegressionEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.QuantileRegressionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.QuantileRegressionEvaluator input, Microsoft.ML.Legacy.Models.QuantileRegressionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.QuantileRegressionEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.RankerEvaluator.Output Add(Microsoft.ML.Legacy.Models.RankerEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.RankerEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.RankerEvaluator input, Microsoft.ML.Legacy.Models.RankerEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.RankerEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.RegressionEnsemble.Output Add(Microsoft.ML.Legacy.Models.RegressionEnsemble input)
            {
                var output = new Microsoft.ML.Legacy.Models.RegressionEnsemble.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.RegressionEnsemble input, Microsoft.ML.Legacy.Models.RegressionEnsemble.Output output)
            {
                _jsonNodes.Add(Serialize("Models.RegressionEnsemble", input, output));
            }

            public Microsoft.ML.Legacy.Models.RegressionEvaluator.Output Add(Microsoft.ML.Legacy.Models.RegressionEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.RegressionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.RegressionEvaluator input, Microsoft.ML.Legacy.Models.RegressionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.RegressionEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.RegressionPipelineEnsemble.Output Add(Microsoft.ML.Legacy.Models.RegressionPipelineEnsemble input)
            {
                var output = new Microsoft.ML.Legacy.Models.RegressionPipelineEnsemble.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.RegressionPipelineEnsemble input, Microsoft.ML.Legacy.Models.RegressionPipelineEnsemble.Output output)
            {
                _jsonNodes.Add(Serialize("Models.RegressionPipelineEnsemble", input, output));
            }

            public Microsoft.ML.Legacy.Models.Summarizer.Output Add(Microsoft.ML.Legacy.Models.Summarizer input)
            {
                var output = new Microsoft.ML.Legacy.Models.Summarizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.Summarizer input, Microsoft.ML.Legacy.Models.Summarizer.Output output)
            {
                _jsonNodes.Add(Serialize("Models.Summarizer", input, output));
            }

            public Microsoft.ML.Legacy.Models.SweepResultExtractor.Output Add(Microsoft.ML.Legacy.Models.SweepResultExtractor input)
            {
                var output = new Microsoft.ML.Legacy.Models.SweepResultExtractor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.SweepResultExtractor input, Microsoft.ML.Legacy.Models.SweepResultExtractor.Output output)
            {
                _jsonNodes.Add(Serialize("Models.SweepResultExtractor", input, output));
            }

            public Microsoft.ML.Legacy.Models.TrainTestBinaryEvaluator.Output Add(Microsoft.ML.Legacy.Models.TrainTestBinaryEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.TrainTestBinaryEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.TrainTestBinaryEvaluator input, Microsoft.ML.Legacy.Models.TrainTestBinaryEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.TrainTestBinaryEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.Models.TrainTestEvaluator.Output Add(Microsoft.ML.Legacy.Models.TrainTestEvaluator input)
            {
                var output = new Microsoft.ML.Legacy.Models.TrainTestEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Models.TrainTestEvaluator input, Microsoft.ML.Legacy.Models.TrainTestEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.TrainTestEvaluator", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.ExponentialAverage.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.ExponentialAverage input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.ExponentialAverage.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.ExponentialAverage input, Microsoft.ML.Legacy.TimeSeriesProcessing.ExponentialAverage.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.ExponentialAverage", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.IidChangePointDetector.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.IidChangePointDetector input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.IidChangePointDetector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.IidChangePointDetector input, Microsoft.ML.Legacy.TimeSeriesProcessing.IidChangePointDetector.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.IidChangePointDetector", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.IidSpikeDetector.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.IidSpikeDetector input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.IidSpikeDetector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.IidSpikeDetector input, Microsoft.ML.Legacy.TimeSeriesProcessing.IidSpikeDetector.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.IidSpikeDetector", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.PercentileThresholdTransform.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.PercentileThresholdTransform input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.PercentileThresholdTransform.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.PercentileThresholdTransform input, Microsoft.ML.Legacy.TimeSeriesProcessing.PercentileThresholdTransform.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.PercentileThresholdTransform", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.PValueTransform.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.PValueTransform input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.PValueTransform.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.PValueTransform input, Microsoft.ML.Legacy.TimeSeriesProcessing.PValueTransform.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.PValueTransform", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.SlidingWindowTransform.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.SlidingWindowTransform input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.SlidingWindowTransform.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.SlidingWindowTransform input, Microsoft.ML.Legacy.TimeSeriesProcessing.SlidingWindowTransform.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.SlidingWindowTransform", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.SsaChangePointDetector.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.SsaChangePointDetector input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.SsaChangePointDetector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.SsaChangePointDetector input, Microsoft.ML.Legacy.TimeSeriesProcessing.SsaChangePointDetector.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.SsaChangePointDetector", input, output));
            }

            public Microsoft.ML.Legacy.TimeSeriesProcessing.SsaSpikeDetector.Output Add(Microsoft.ML.Legacy.TimeSeriesProcessing.SsaSpikeDetector input)
            {
                var output = new Microsoft.ML.Legacy.TimeSeriesProcessing.SsaSpikeDetector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.TimeSeriesProcessing.SsaSpikeDetector input, Microsoft.ML.Legacy.TimeSeriesProcessing.SsaSpikeDetector.Output output)
            {
                _jsonNodes.Add(Serialize("TimeSeriesProcessing.SsaSpikeDetector", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.AveragedPerceptronBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.AveragedPerceptronBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.AveragedPerceptronBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.AveragedPerceptronBinaryClassifier input, Microsoft.ML.Legacy.Trainers.AveragedPerceptronBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.AveragedPerceptronBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.EnsembleBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.EnsembleBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.EnsembleBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.EnsembleBinaryClassifier input, Microsoft.ML.Legacy.Trainers.EnsembleBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.EnsembleBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.EnsembleClassification.Output Add(Microsoft.ML.Legacy.Trainers.EnsembleClassification input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.EnsembleClassification.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.EnsembleClassification input, Microsoft.ML.Legacy.Trainers.EnsembleClassification.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.EnsembleClassification", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.EnsembleRegression.Output Add(Microsoft.ML.Legacy.Trainers.EnsembleRegression input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.EnsembleRegression.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.EnsembleRegression input, Microsoft.ML.Legacy.Trainers.EnsembleRegression.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.EnsembleRegression", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FastForestBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.FastForestBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FastForestBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FastForestBinaryClassifier input, Microsoft.ML.Legacy.Trainers.FastForestBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastForestBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FastForestRegressor.Output Add(Microsoft.ML.Legacy.Trainers.FastForestRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FastForestRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FastForestRegressor input, Microsoft.ML.Legacy.Trainers.FastForestRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastForestRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FastTreeBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.FastTreeBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FastTreeBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FastTreeBinaryClassifier input, Microsoft.ML.Legacy.Trainers.FastTreeBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FastTreeRanker.Output Add(Microsoft.ML.Legacy.Trainers.FastTreeRanker input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FastTreeRanker.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FastTreeRanker input, Microsoft.ML.Legacy.Trainers.FastTreeRanker.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeRanker", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FastTreeRegressor.Output Add(Microsoft.ML.Legacy.Trainers.FastTreeRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FastTreeRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FastTreeRegressor input, Microsoft.ML.Legacy.Trainers.FastTreeRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FastTreeTweedieRegressor.Output Add(Microsoft.ML.Legacy.Trainers.FastTreeTweedieRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FastTreeTweedieRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FastTreeTweedieRegressor input, Microsoft.ML.Legacy.Trainers.FastTreeTweedieRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeTweedieRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.FieldAwareFactorizationMachineBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.FieldAwareFactorizationMachineBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.FieldAwareFactorizationMachineBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.FieldAwareFactorizationMachineBinaryClassifier input, Microsoft.ML.Legacy.Trainers.FieldAwareFactorizationMachineBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FieldAwareFactorizationMachineBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelBinaryClassifier input, Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.GeneralizedAdditiveModelBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelRegressor.Output Add(Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelRegressor input, Microsoft.ML.Legacy.Trainers.GeneralizedAdditiveModelRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.GeneralizedAdditiveModelRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.KMeansPlusPlusClusterer.Output Add(Microsoft.ML.Legacy.Trainers.KMeansPlusPlusClusterer input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.KMeansPlusPlusClusterer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.KMeansPlusPlusClusterer input, Microsoft.ML.Legacy.Trainers.KMeansPlusPlusClusterer.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.KMeansPlusPlusClusterer", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LightGbmBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.LightGbmBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LightGbmBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LightGbmBinaryClassifier input, Microsoft.ML.Legacy.Trainers.LightGbmBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LightGbmBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LightGbmClassifier.Output Add(Microsoft.ML.Legacy.Trainers.LightGbmClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LightGbmClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LightGbmClassifier input, Microsoft.ML.Legacy.Trainers.LightGbmClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LightGbmClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LightGbmRanker.Output Add(Microsoft.ML.Legacy.Trainers.LightGbmRanker input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LightGbmRanker.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LightGbmRanker input, Microsoft.ML.Legacy.Trainers.LightGbmRanker.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LightGbmRanker", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LightGbmRegressor.Output Add(Microsoft.ML.Legacy.Trainers.LightGbmRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LightGbmRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LightGbmRegressor input, Microsoft.ML.Legacy.Trainers.LightGbmRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LightGbmRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LinearSvmBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.LinearSvmBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LinearSvmBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LinearSvmBinaryClassifier input, Microsoft.ML.Legacy.Trainers.LinearSvmBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LinearSvmBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LogisticRegressionBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.LogisticRegressionBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LogisticRegressionBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LogisticRegressionBinaryClassifier input, Microsoft.ML.Legacy.Trainers.LogisticRegressionBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LogisticRegressionBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.LogisticRegressionClassifier.Output Add(Microsoft.ML.Legacy.Trainers.LogisticRegressionClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.LogisticRegressionClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.LogisticRegressionClassifier input, Microsoft.ML.Legacy.Trainers.LogisticRegressionClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LogisticRegressionClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.NaiveBayesClassifier.Output Add(Microsoft.ML.Legacy.Trainers.NaiveBayesClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.NaiveBayesClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.NaiveBayesClassifier input, Microsoft.ML.Legacy.Trainers.NaiveBayesClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.NaiveBayesClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.OnlineGradientDescentRegressor.Output Add(Microsoft.ML.Legacy.Trainers.OnlineGradientDescentRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.OnlineGradientDescentRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.OnlineGradientDescentRegressor input, Microsoft.ML.Legacy.Trainers.OnlineGradientDescentRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.OnlineGradientDescentRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.OrdinaryLeastSquaresRegressor.Output Add(Microsoft.ML.Legacy.Trainers.OrdinaryLeastSquaresRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.OrdinaryLeastSquaresRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.OrdinaryLeastSquaresRegressor input, Microsoft.ML.Legacy.Trainers.OrdinaryLeastSquaresRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.OrdinaryLeastSquaresRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.PcaAnomalyDetector.Output Add(Microsoft.ML.Legacy.Trainers.PcaAnomalyDetector input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.PcaAnomalyDetector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.PcaAnomalyDetector input, Microsoft.ML.Legacy.Trainers.PcaAnomalyDetector.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.PcaAnomalyDetector", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.PoissonRegressor.Output Add(Microsoft.ML.Legacy.Trainers.PoissonRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.PoissonRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.PoissonRegressor input, Microsoft.ML.Legacy.Trainers.PoissonRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.PoissonRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentBinaryClassifier input, Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticDualCoordinateAscentBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentClassifier.Output Add(Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentClassifier input, Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticDualCoordinateAscentClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentRegressor.Output Add(Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentRegressor input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentRegressor input, Microsoft.ML.Legacy.Trainers.StochasticDualCoordinateAscentRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticDualCoordinateAscentRegressor", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.StochasticGradientDescentBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.StochasticGradientDescentBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.StochasticGradientDescentBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.StochasticGradientDescentBinaryClassifier input, Microsoft.ML.Legacy.Trainers.StochasticGradientDescentBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticGradientDescentBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Trainers.SymSgdBinaryClassifier.Output Add(Microsoft.ML.Legacy.Trainers.SymSgdBinaryClassifier input)
            {
                var output = new Microsoft.ML.Legacy.Trainers.SymSgdBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Trainers.SymSgdBinaryClassifier input, Microsoft.ML.Legacy.Trainers.SymSgdBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.SymSgdBinaryClassifier", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ApproximateBootstrapSampler.Output Add(Microsoft.ML.Legacy.Transforms.ApproximateBootstrapSampler input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ApproximateBootstrapSampler.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ApproximateBootstrapSampler input, Microsoft.ML.Legacy.Transforms.ApproximateBootstrapSampler.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ApproximateBootstrapSampler", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.BinaryPredictionScoreColumnsRenamer.Output Add(Microsoft.ML.Legacy.Transforms.BinaryPredictionScoreColumnsRenamer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.BinaryPredictionScoreColumnsRenamer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.BinaryPredictionScoreColumnsRenamer input, Microsoft.ML.Legacy.Transforms.BinaryPredictionScoreColumnsRenamer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.BinaryPredictionScoreColumnsRenamer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.BinNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.BinNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.BinNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.BinNormalizer input, Microsoft.ML.Legacy.Transforms.BinNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.BinNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.CategoricalHashOneHotVectorizer.Output Add(Microsoft.ML.Legacy.Transforms.CategoricalHashOneHotVectorizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.CategoricalHashOneHotVectorizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.CategoricalHashOneHotVectorizer input, Microsoft.ML.Legacy.Transforms.CategoricalHashOneHotVectorizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CategoricalHashOneHotVectorizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.CategoricalOneHotVectorizer.Output Add(Microsoft.ML.Legacy.Transforms.CategoricalOneHotVectorizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.CategoricalOneHotVectorizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.CategoricalOneHotVectorizer input, Microsoft.ML.Legacy.Transforms.CategoricalOneHotVectorizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CategoricalOneHotVectorizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.CharacterTokenizer.Output Add(Microsoft.ML.Legacy.Transforms.CharacterTokenizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.CharacterTokenizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.CharacterTokenizer input, Microsoft.ML.Legacy.Transforms.CharacterTokenizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CharacterTokenizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ColumnConcatenator.Output Add(Microsoft.ML.Legacy.Transforms.ColumnConcatenator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ColumnConcatenator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ColumnConcatenator input, Microsoft.ML.Legacy.Transforms.ColumnConcatenator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnConcatenator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ColumnCopier.Output Add(Microsoft.ML.Legacy.Transforms.ColumnCopier input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ColumnCopier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ColumnCopier input, Microsoft.ML.Legacy.Transforms.ColumnCopier.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnCopier", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ColumnSelector.Output Add(Microsoft.ML.Legacy.Transforms.ColumnSelector input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ColumnSelector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ColumnSelector input, Microsoft.ML.Legacy.Transforms.ColumnSelector.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnSelector", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ColumnTypeConverter.Output Add(Microsoft.ML.Legacy.Transforms.ColumnTypeConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ColumnTypeConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ColumnTypeConverter input, Microsoft.ML.Legacy.Transforms.ColumnTypeConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnTypeConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.CombinerByContiguousGroupId.Output Add(Microsoft.ML.Legacy.Transforms.CombinerByContiguousGroupId input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.CombinerByContiguousGroupId.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.CombinerByContiguousGroupId input, Microsoft.ML.Legacy.Transforms.CombinerByContiguousGroupId.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CombinerByContiguousGroupId", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ConditionalNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.ConditionalNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ConditionalNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ConditionalNormalizer input, Microsoft.ML.Legacy.Transforms.ConditionalNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ConditionalNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.DataCache.Output Add(Microsoft.ML.Legacy.Transforms.DataCache input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.DataCache.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.DataCache input, Microsoft.ML.Legacy.Transforms.DataCache.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.DataCache", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.DatasetScorer.Output Add(Microsoft.ML.Legacy.Transforms.DatasetScorer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.DatasetScorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.DatasetScorer input, Microsoft.ML.Legacy.Transforms.DatasetScorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.DatasetScorer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.DatasetTransformScorer.Output Add(Microsoft.ML.Legacy.Transforms.DatasetTransformScorer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.DatasetTransformScorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.DatasetTransformScorer input, Microsoft.ML.Legacy.Transforms.DatasetTransformScorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.DatasetTransformScorer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.Dictionarizer.Output Add(Microsoft.ML.Legacy.Transforms.Dictionarizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.Dictionarizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.Dictionarizer input, Microsoft.ML.Legacy.Transforms.Dictionarizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.Dictionarizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.FeatureCombiner.Output Add(Microsoft.ML.Legacy.Transforms.FeatureCombiner input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.FeatureCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.FeatureCombiner input, Microsoft.ML.Legacy.Transforms.FeatureCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.FeatureCombiner", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.FeatureSelectorByCount.Output Add(Microsoft.ML.Legacy.Transforms.FeatureSelectorByCount input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.FeatureSelectorByCount.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.FeatureSelectorByCount input, Microsoft.ML.Legacy.Transforms.FeatureSelectorByCount.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.FeatureSelectorByCount", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.FeatureSelectorByMutualInformation.Output Add(Microsoft.ML.Legacy.Transforms.FeatureSelectorByMutualInformation input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.FeatureSelectorByMutualInformation.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.FeatureSelectorByMutualInformation input, Microsoft.ML.Legacy.Transforms.FeatureSelectorByMutualInformation.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.FeatureSelectorByMutualInformation", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.GlobalContrastNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.GlobalContrastNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.GlobalContrastNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.GlobalContrastNormalizer input, Microsoft.ML.Legacy.Transforms.GlobalContrastNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.GlobalContrastNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.HashConverter.Output Add(Microsoft.ML.Legacy.Transforms.HashConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.HashConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.HashConverter input, Microsoft.ML.Legacy.Transforms.HashConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.HashConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ImageGrayscale.Output Add(Microsoft.ML.Legacy.Transforms.ImageGrayscale input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ImageGrayscale.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ImageGrayscale input, Microsoft.ML.Legacy.Transforms.ImageGrayscale.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ImageGrayscale", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ImageLoader.Output Add(Microsoft.ML.Legacy.Transforms.ImageLoader input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ImageLoader.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ImageLoader input, Microsoft.ML.Legacy.Transforms.ImageLoader.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ImageLoader", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ImagePixelExtractor.Output Add(Microsoft.ML.Legacy.Transforms.ImagePixelExtractor input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ImagePixelExtractor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ImagePixelExtractor input, Microsoft.ML.Legacy.Transforms.ImagePixelExtractor.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ImagePixelExtractor", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ImageResizer.Output Add(Microsoft.ML.Legacy.Transforms.ImageResizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ImageResizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ImageResizer input, Microsoft.ML.Legacy.Transforms.ImageResizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ImageResizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.KeyToTextConverter.Output Add(Microsoft.ML.Legacy.Transforms.KeyToTextConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.KeyToTextConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.KeyToTextConverter input, Microsoft.ML.Legacy.Transforms.KeyToTextConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.KeyToTextConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.LabelColumnKeyBooleanConverter.Output Add(Microsoft.ML.Legacy.Transforms.LabelColumnKeyBooleanConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.LabelColumnKeyBooleanConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.LabelColumnKeyBooleanConverter input, Microsoft.ML.Legacy.Transforms.LabelColumnKeyBooleanConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LabelColumnKeyBooleanConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.LabelIndicator.Output Add(Microsoft.ML.Legacy.Transforms.LabelIndicator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.LabelIndicator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.LabelIndicator input, Microsoft.ML.Legacy.Transforms.LabelIndicator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LabelIndicator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.LabelToFloatConverter.Output Add(Microsoft.ML.Legacy.Transforms.LabelToFloatConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.LabelToFloatConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.LabelToFloatConverter input, Microsoft.ML.Legacy.Transforms.LabelToFloatConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LabelToFloatConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.LightLda.Output Add(Microsoft.ML.Legacy.Transforms.LightLda input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.LightLda.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.LightLda input, Microsoft.ML.Legacy.Transforms.LightLda.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LightLda", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.LogMeanVarianceNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.LogMeanVarianceNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.LogMeanVarianceNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.LogMeanVarianceNormalizer input, Microsoft.ML.Legacy.Transforms.LogMeanVarianceNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LogMeanVarianceNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.LpNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.LpNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.LpNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.LpNormalizer input, Microsoft.ML.Legacy.Transforms.LpNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LpNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ManyHeterogeneousModelCombiner.Output Add(Microsoft.ML.Legacy.Transforms.ManyHeterogeneousModelCombiner input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ManyHeterogeneousModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ManyHeterogeneousModelCombiner input, Microsoft.ML.Legacy.Transforms.ManyHeterogeneousModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ManyHeterogeneousModelCombiner", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MeanVarianceNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.MeanVarianceNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MeanVarianceNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MeanVarianceNormalizer input, Microsoft.ML.Legacy.Transforms.MeanVarianceNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MeanVarianceNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MinMaxNormalizer.Output Add(Microsoft.ML.Legacy.Transforms.MinMaxNormalizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MinMaxNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MinMaxNormalizer input, Microsoft.ML.Legacy.Transforms.MinMaxNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MinMaxNormalizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MissingValueHandler.Output Add(Microsoft.ML.Legacy.Transforms.MissingValueHandler input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MissingValueHandler.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MissingValueHandler input, Microsoft.ML.Legacy.Transforms.MissingValueHandler.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValueHandler", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MissingValueIndicator.Output Add(Microsoft.ML.Legacy.Transforms.MissingValueIndicator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MissingValueIndicator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MissingValueIndicator input, Microsoft.ML.Legacy.Transforms.MissingValueIndicator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValueIndicator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MissingValuesDropper.Output Add(Microsoft.ML.Legacy.Transforms.MissingValuesDropper input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MissingValuesDropper.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MissingValuesDropper input, Microsoft.ML.Legacy.Transforms.MissingValuesDropper.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValuesDropper", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MissingValuesRowDropper.Output Add(Microsoft.ML.Legacy.Transforms.MissingValuesRowDropper input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MissingValuesRowDropper.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MissingValuesRowDropper input, Microsoft.ML.Legacy.Transforms.MissingValuesRowDropper.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValuesRowDropper", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.MissingValueSubstitutor.Output Add(Microsoft.ML.Legacy.Transforms.MissingValueSubstitutor input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.MissingValueSubstitutor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.MissingValueSubstitutor input, Microsoft.ML.Legacy.Transforms.MissingValueSubstitutor.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValueSubstitutor", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ModelCombiner.Output Add(Microsoft.ML.Legacy.Transforms.ModelCombiner input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ModelCombiner input, Microsoft.ML.Legacy.Transforms.ModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ModelCombiner", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.NGramTranslator.Output Add(Microsoft.ML.Legacy.Transforms.NGramTranslator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.NGramTranslator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.NGramTranslator input, Microsoft.ML.Legacy.Transforms.NGramTranslator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.NGramTranslator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.NoOperation.Output Add(Microsoft.ML.Legacy.Transforms.NoOperation input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.NoOperation.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.NoOperation input, Microsoft.ML.Legacy.Transforms.NoOperation.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.NoOperation", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.OptionalColumnCreator.Output Add(Microsoft.ML.Legacy.Transforms.OptionalColumnCreator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.OptionalColumnCreator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.OptionalColumnCreator input, Microsoft.ML.Legacy.Transforms.OptionalColumnCreator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.OptionalColumnCreator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.PcaCalculator.Output Add(Microsoft.ML.Legacy.Transforms.PcaCalculator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.PcaCalculator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.PcaCalculator input, Microsoft.ML.Legacy.Transforms.PcaCalculator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.PcaCalculator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.PredictedLabelColumnOriginalValueConverter.Output Add(Microsoft.ML.Legacy.Transforms.PredictedLabelColumnOriginalValueConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.PredictedLabelColumnOriginalValueConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.PredictedLabelColumnOriginalValueConverter input, Microsoft.ML.Legacy.Transforms.PredictedLabelColumnOriginalValueConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.PredictedLabelColumnOriginalValueConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.RandomNumberGenerator.Output Add(Microsoft.ML.Legacy.Transforms.RandomNumberGenerator input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.RandomNumberGenerator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.RandomNumberGenerator input, Microsoft.ML.Legacy.Transforms.RandomNumberGenerator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RandomNumberGenerator", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.RowRangeFilter.Output Add(Microsoft.ML.Legacy.Transforms.RowRangeFilter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.RowRangeFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.RowRangeFilter input, Microsoft.ML.Legacy.Transforms.RowRangeFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowRangeFilter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.RowSkipAndTakeFilter.Output Add(Microsoft.ML.Legacy.Transforms.RowSkipAndTakeFilter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.RowSkipAndTakeFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.RowSkipAndTakeFilter input, Microsoft.ML.Legacy.Transforms.RowSkipAndTakeFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowSkipAndTakeFilter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.RowSkipFilter.Output Add(Microsoft.ML.Legacy.Transforms.RowSkipFilter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.RowSkipFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.RowSkipFilter input, Microsoft.ML.Legacy.Transforms.RowSkipFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowSkipFilter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.RowTakeFilter.Output Add(Microsoft.ML.Legacy.Transforms.RowTakeFilter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.RowTakeFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.RowTakeFilter input, Microsoft.ML.Legacy.Transforms.RowTakeFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowTakeFilter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.ScoreColumnSelector.Output Add(Microsoft.ML.Legacy.Transforms.ScoreColumnSelector input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.ScoreColumnSelector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.ScoreColumnSelector input, Microsoft.ML.Legacy.Transforms.ScoreColumnSelector.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ScoreColumnSelector", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.Scorer.Output Add(Microsoft.ML.Legacy.Transforms.Scorer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.Scorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.Scorer input, Microsoft.ML.Legacy.Transforms.Scorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.Scorer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.SentimentAnalyzer.Output Add(Microsoft.ML.Legacy.Transforms.SentimentAnalyzer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.SentimentAnalyzer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.SentimentAnalyzer input, Microsoft.ML.Legacy.Transforms.SentimentAnalyzer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.SentimentAnalyzer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.TensorFlowScorer.Output Add(Microsoft.ML.Legacy.Transforms.TensorFlowScorer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.TensorFlowScorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.TensorFlowScorer input, Microsoft.ML.Legacy.Transforms.TensorFlowScorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TensorFlowScorer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.TextFeaturizer.Output Add(Microsoft.ML.Legacy.Transforms.TextFeaturizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.TextFeaturizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.TextFeaturizer input, Microsoft.ML.Legacy.Transforms.TextFeaturizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TextFeaturizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.TextToKeyConverter.Output Add(Microsoft.ML.Legacy.Transforms.TextToKeyConverter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.TextToKeyConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.TextToKeyConverter input, Microsoft.ML.Legacy.Transforms.TextToKeyConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TextToKeyConverter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.TrainTestDatasetSplitter.Output Add(Microsoft.ML.Legacy.Transforms.TrainTestDatasetSplitter input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.TrainTestDatasetSplitter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.TrainTestDatasetSplitter input, Microsoft.ML.Legacy.Transforms.TrainTestDatasetSplitter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TrainTestDatasetSplitter", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.TreeLeafFeaturizer.Output Add(Microsoft.ML.Legacy.Transforms.TreeLeafFeaturizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.TreeLeafFeaturizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.TreeLeafFeaturizer input, Microsoft.ML.Legacy.Transforms.TreeLeafFeaturizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TreeLeafFeaturizer", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.TwoHeterogeneousModelCombiner.Output Add(Microsoft.ML.Legacy.Transforms.TwoHeterogeneousModelCombiner input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.TwoHeterogeneousModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.TwoHeterogeneousModelCombiner input, Microsoft.ML.Legacy.Transforms.TwoHeterogeneousModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TwoHeterogeneousModelCombiner", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.VectorToImage.Output Add(Microsoft.ML.Legacy.Transforms.VectorToImage input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.VectorToImage.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.VectorToImage input, Microsoft.ML.Legacy.Transforms.VectorToImage.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.VectorToImage", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.WordEmbeddings.Output Add(Microsoft.ML.Legacy.Transforms.WordEmbeddings input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.WordEmbeddings.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.WordEmbeddings input, Microsoft.ML.Legacy.Transforms.WordEmbeddings.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.WordEmbeddings", input, output));
            }

            public Microsoft.ML.Legacy.Transforms.WordTokenizer.Output Add(Microsoft.ML.Legacy.Transforms.WordTokenizer input)
            {
                var output = new Microsoft.ML.Legacy.Transforms.WordTokenizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Legacy.Transforms.WordTokenizer input, Microsoft.ML.Legacy.Transforms.WordTokenizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.WordTokenizer", input, output));
            }

        }
    }
    namespace Legacy.Data
    {

        /// <summary>
        /// Import a dataset from a text file
        /// </summary>
        [Obsolete("Use TextLoader instead.")]
        public sealed partial class CustomTextLoader
        {


            /// <summary>
            /// Location of the input file
            /// </summary>
            public Var<Microsoft.ML.Runtime.IFileHandle> InputFile { get; set; } = new Var<Microsoft.ML.Runtime.IFileHandle>();

            /// <summary>
            /// Custom schema to use for parsing
            /// </summary>
            public string CustomSchema { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// The resulting data view
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Data
    {

        /// <summary>
        /// Pass dataview from memory to experiment
        /// </summary>
        public sealed partial class DataViewReference
        {


            /// <summary>
            /// Pointer to IDataView in memory
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// The resulting data view
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Data
    {

        /// <summary>
        /// Create an array variable of IDataView
        /// </summary>
        public sealed partial class IDataViewArrayConverter
        {


            /// <summary>
            /// The data sets
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// The data set array
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Data
    {

        /// <summary>
        /// Create an array variable of IPredictorModel
        /// </summary>
        public sealed partial class PredictorModelArrayConverter
        {


            /// <summary>
            /// The models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The model array
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> OutputModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Data
    {

        public enum DataKind : byte
        {
            I1 = 1,
            U1 = 2,
            I2 = 3,
            U2 = 4,
            I4 = 5,
            U4 = 6,
            I8 = 7,
            U8 = 8,
            R4 = 9,
            Num = 9,
            R8 = 10,
            TX = 11,
            Text = 11,
            TXT = 11,
            BL = 12,
            Bool = 12,
            TimeSpan = 13,
            TS = 13,
            DT = 14,
            DateTime = 14,
            DZ = 15,
            DateTimeZone = 15,
            UG = 16,
            U16 = 16
        }

        public sealed partial class TextLoaderRange
        {
            /// <summary>
            /// First index in the range
            /// </summary>
            public int Min { get; set; }

            /// <summary>
            /// Last index in the range
            /// </summary>
            public int? Max { get; set; }

            /// <summary>
            /// This range extends to the end of the line, but should be a fixed number of items
            /// </summary>
            public bool AutoEnd { get; set; } = false;

            /// <summary>
            /// This range extends to the end of the line, which can vary from line to line
            /// </summary>
            public bool VariableEnd { get; set; } = false;

            /// <summary>
            /// This range includes only other indices not specified
            /// </summary>
            public bool AllOther { get; set; } = false;

            /// <summary>
            /// Force scalar columns to be treated as vectors of length one
            /// </summary>
            public bool ForceVector { get; set; } = false;

        }

        public sealed partial class KeyRange
        {
            /// <summary>
            /// First index in the range
            /// </summary>
            public ulong Min { get; set; } = 0;

            /// <summary>
            /// Last index in the range
            /// </summary>
            public ulong? Max { get; set; }

            /// <summary>
            /// Whether the key is contiguous
            /// </summary>
            public bool Contiguous { get; set; } = true;

        }

        public sealed partial class TextLoaderColumn
        {
            /// <summary>
            /// Name of the column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Type of the items in the column
            /// </summary>
            public DataKind? Type { get; set; }

            /// <summary>
            /// Source index range(s) of the column
            /// </summary>
            public TextLoaderRange[] Source { get; set; }

            /// <summary>
            /// For a key column, this defines the range of values
            /// </summary>
            public KeyRange KeyRange { get; set; }

        }

        public sealed partial class TextLoaderArguments
        {
            /// <summary>
            /// Use separate parsing threads?
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// File containing a header with feature names. If specified, header defined in the data file (header+) is ignored.
            /// </summary>
            public string HeaderFile { get; set; }

            /// <summary>
            /// Maximum number of rows to produce
            /// </summary>
            public long? MaxRows { get; set; }

            /// <summary>
            /// Whether the input may include quoted values, which can contain separator characters, colons, and distinguish empty values from missing values. When true, consecutive separators denote a missing value and an empty value is denoted by "". When false, consecutive separators denote an empty value.
            /// </summary>
            public bool AllowQuoting { get; set; } = true;

            /// <summary>
            /// Whether the input may include sparse representations
            /// </summary>
            public bool AllowSparse { get; set; } = true;

            /// <summary>
            /// Number of source columns in the text data. Default is that sparse rows contain their size information.
            /// </summary>
            public int? InputSize { get; set; }

            /// <summary>
            /// Source column separator.
            /// </summary>
            public char[] Separator { get; set; } = { '\t' };

            /// <summary>
            /// Column groups. Each group is specified as name:type:numeric-ranges, eg, col=Features:R4:1-17,26,35-40
            /// </summary>
            public TextLoaderColumn[] Column { get; set; }

            /// <summary>
            /// Remove trailing whitespace from lines
            /// </summary>
            public bool TrimWhitespace { get; set; } = false;

            /// <summary>
            /// Data file has header with feature names. Header is read only if options 'hs' and 'hf' are not specified.
            /// </summary>
            public bool HasHeader { get; set; } = false;

        }

        /// <summary>
        /// Import a dataset from a text file
        /// </summary>
        public sealed partial class TextLoader : Microsoft.ML.Legacy.ILearningPipelineLoader
        {

            [JsonIgnore]
            private string _inputFilePath = null;
            public TextLoader(string filePath)
            {
                _inputFilePath = filePath;
            }
            
            public void SetInput(IHostEnvironment env, Experiment experiment)
            {
                IFileHandle inputFile = new SimpleFileHandle(env, _inputFilePath, false, false);
                experiment.SetInput(InputFile, inputFile);
            }
            
            public Var<IDataView> GetInputData() => null;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                Contracts.Assert(previousStep == null);
                
                return new TextLoaderPipelineStep(experiment.Add(this));
            }
            
            private class TextLoaderPipelineStep : ILearningPipelineDataStep
            {
                public TextLoaderPipelineStep (Output output)
                {
                    Data = output.Data;
                    Model = null;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }

            /// <summary>
            /// Location of the input file
            /// </summary>
            public Var<Microsoft.ML.Runtime.IFileHandle> InputFile { get; set; } = new Var<Microsoft.ML.Runtime.IFileHandle>();

            /// <summary>
            /// Arguments
            /// </summary>
            public TextLoaderArguments Arguments { get; set; } = new TextLoaderArguments();


            public sealed class Output
            {
                /// <summary>
                /// The resulting data view
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Data
    {

        /// <summary>
        /// Create an array variable of ITransformModel
        /// </summary>
        public sealed partial class TransformModelArrayConverter
        {


            /// <summary>
            /// The models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();


            public sealed class Output
            {
                /// <summary>
                /// The model array
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> OutputModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates an anomaly detection scored dataset.
        /// </summary>
        public sealed partial class AnomalyDetectionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Expected number of false positives
            /// </summary>
            public int K { get; set; } = 10;

            /// <summary>
            /// Expected false positive rate
            /// </summary>
            public double P { get; set; } = 0.01d;

            /// <summary>
            /// Number of top-scored predictions to display
            /// </summary>
            public int NumTopResults { get; set; } = 50;

            /// <summary>
            /// Whether to calculate metrics in one pass
            /// </summary>
            public bool Stream { get; set; } = true;

            /// <summary>
            /// The number of samples to use for AUC calculation. If 0, AUC is not computed. If -1, the whole dataset is used
            /// </summary>
            public int MaxAucExamples { get; set; } = -1;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {
        public enum EnsembleCreatorScoreCombiner
        {
            Median = 0,
            Average = 1
        }


        /// <summary>
        /// Combine anomaly detection models into an ensemble
        /// </summary>
        public sealed partial class AnomalyPipelineEnsemble
        {


            /// <summary>
            /// The combiner used to combine the scores
            /// </summary>
            public EnsembleCreatorScoreCombiner ModelCombiner { get; set; } = EnsembleCreatorScoreCombiner.Average;

            /// <summary>
            /// The models to combine into an ensemble
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IAnomalyDetectionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a binary classification scored dataset.
        /// </summary>
        public sealed partial class BinaryClassificationEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Probability column name
            /// </summary>
            public string ProbabilityColumn { get; set; }

            /// <summary>
            /// Probability value for classification thresholding
            /// </summary>
            public float Threshold { get; set; }

            /// <summary>
            /// Use raw score value instead of probability for classification thresholding
            /// </summary>
            public bool UseRawScoreThreshold { get; set; } = true;

            /// <summary>
            /// The number of samples to use for p/r curve generation. Specify 0 for no p/r curve generation
            /// </summary>
            public int NumRocExamples { get; set; } = 100000;

            /// <summary>
            /// The number of samples to use for AUC calculation. If 0, AUC is not computed. If -1, the whole dataset is used
            /// </summary>
            public int MaxAucExamples { get; set; } = -1;

            /// <summary>
            /// The number of samples to use for AUPRC calculation. Specify 0 for no AUPRC calculation
            /// </summary>
            public int NumAuPrcExamples { get; set; } = 100000;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IClassificationEvaluatorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        public sealed partial class CrossValidationBinaryMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed partial class CrossValidationBinaryMacroSubGraphOutput
        {
            /// <summary>
            /// The model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// Cross validation for binary classification
        /// </summary>
        public sealed partial class BinaryCrossValidator
        {


            /// <summary>
            /// The data set
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public CrossValidationBinaryMacroSubGraphInput Inputs { get; set; } = new CrossValidationBinaryMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public CrossValidationBinaryMacroSubGraphOutput Outputs { get; set; } = new CrossValidationBinaryMacroSubGraphOutput();

            /// <summary>
            /// Column to use for stratification
            /// </summary>
            public string StratificationColumn { get; set; }

            /// <summary>
            /// Number of folds in k-fold cross-validation
            /// </summary>
            public int NumFolds { get; set; } = 2;


            public sealed class Output
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {
        public enum EnsembleCreatorClassifierCombiner
        {
            Median = 0,
            Average = 1,
            Vote = 2
        }


        /// <summary>
        /// Combine binary classifiers into an ensemble
        /// </summary>
        public sealed partial class BinaryEnsemble
        {


            /// <summary>
            /// The combiner used to combine the scores
            /// </summary>
            public EnsembleCreatorClassifierCombiner ModelCombiner { get; set; } = EnsembleCreatorClassifierCombiner.Median;

            /// <summary>
            /// The models to combine into an ensemble
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Whether to validate that all the pipelines are identical
            /// </summary>
            public bool ValidatePipelines { get; set; } = true;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Combine binary classification models into an ensemble
        /// </summary>
        public sealed partial class BinaryPipelineEnsemble
        {


            /// <summary>
            /// The combiner used to combine the scores
            /// </summary>
            public EnsembleCreatorClassifierCombiner ModelCombiner { get; set; } = EnsembleCreatorClassifierCombiner.Median;

            /// <summary>
            /// The models to combine into an ensemble
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a multi class classification scored dataset.
        /// </summary>
        public sealed partial class ClassificationEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Output top-K accuracy.
            /// </summary>
            public int? OutputTopKAcc { get; set; }

            /// <summary>
            /// Output top-K classes.
            /// </summary>
            public int NumTopClassesToOutput { get; set; } = 3;

            /// <summary>
            /// Maximum number of classes in confusion matrix.
            /// </summary>
            public int NumClassesConfusionMatrix { get; set; } = 10;

            /// <summary>
            /// Output per class statistics and confusion matrix.
            /// </summary>
            public bool OutputPerClassStatistics { get; set; } = false;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IClassificationEvaluatorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a clustering scored dataset.
        /// </summary>
        public sealed partial class ClusterEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Features column name
            /// </summary>
            public string FeatureColumn { get; set; }

            /// <summary>
            /// Calculate DBI? (time-consuming unsupervised metric)
            /// </summary>
            public bool CalculateDbi { get; set; } = false;

            /// <summary>
            /// Output top K clusters
            /// </summary>
            public int NumTopClustersToOutput { get; set; } = 3;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {
        public enum MacroUtilsTrainerKinds
        {
            SignatureBinaryClassifierTrainer = 0,
            SignatureMultiClassClassifierTrainer = 1,
            SignatureRankerTrainer = 2,
            SignatureRegressorTrainer = 3,
            SignatureMultiOutputRegressorTrainer = 4,
            SignatureAnomalyDetectorTrainer = 5,
            SignatureClusteringTrainer = 6
        }


        /// <summary>
        /// Combine the metric data views returned from cross validation.
        /// </summary>
        public sealed partial class CrossValidationResultsCombiner
        {


            /// <summary>
            /// Overall metrics datasets
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Per instance metrics datasets
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Confusion matrix datasets
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Warning datasets
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The label column name
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for grouping
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupColumn { get; set; }

            /// <summary>
            /// Name column name
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> NameColumn { get; set; }

            /// <summary>
            /// Specifies the trainer kind, which determines the evaluator to be used.
            /// </summary>
            public MacroUtilsTrainerKinds Kind { get; set; } = MacroUtilsTrainerKinds.SignatureBinaryClassifierTrainer;


            public sealed class Output
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        public sealed partial class CrossValidationMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed partial class CrossValidationMacroSubGraphOutput
        {
            /// <summary>
            /// The predictor model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The transform model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

        }

        /// <summary>
        /// Cross validation for general learning
        /// </summary>
        public sealed partial class CrossValidator
        {


            /// <summary>
            /// The data set
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The transform model from the pipeline before this command. It gets included in the Output.PredictorModel.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public CrossValidationMacroSubGraphInput Inputs { get; set; } = new CrossValidationMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public CrossValidationMacroSubGraphOutput Outputs { get; set; } = new CrossValidationMacroSubGraphOutput();

            /// <summary>
            /// Column to use for stratification
            /// </summary>
            public string StratificationColumn { get; set; }

            /// <summary>
            /// Number of folds in k-fold cross-validation
            /// </summary>
            public int NumFolds { get; set; } = 2;

            /// <summary>
            /// Specifies the trainer kind, which determines the evaluator to be used.
            /// </summary>
            public MacroUtilsTrainerKinds Kind { get; set; } = MacroUtilsTrainerKinds.SignatureBinaryClassifierTrainer;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for grouping
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupColumn { get; set; }

            /// <summary>
            /// Name column name
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> NameColumn { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// The final model including the trained predictor model and the model from the transforms, provided as the Input.TransformModel.
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// The final model including the trained predictor model and the model from the transforms, provided as the Input.TransformModel.
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Split the dataset into the specified number of cross-validation folds (train and test sets)
        /// </summary>
        public sealed partial class CrossValidatorDatasetSplitter
        {


            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Number of folds to split into
            /// </summary>
            public int NumFolds { get; set; } = 2;

            /// <summary>
            /// Stratification column
            /// </summary>
            public string StratificationColumn { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// Training data (one dataset per fold)
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> TrainData { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Testing data (one dataset per fold)
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> TestData { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Applies a TransformModel to a dataset.
        /// </summary>
        public sealed partial class DatasetTransformer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Transform model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(DatasetTransformer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new DatasetTransformerPipelineStep(output);
            }

            private class DatasetTransformerPipelineStep : ILearningPipelineDataStep
            {
                public DatasetTransformerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Summarize a pipeline ensemble predictor.
        /// </summary>
        public sealed partial class EnsembleSummary
        {


            /// <summary>
            /// The predictor to summarize
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The summaries of the individual predictors
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Summaries { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The model statistics of the individual predictors
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Stats { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Apply a Platt calibrator with a fixed slope and offset to an input model
        /// </summary>
        public sealed partial class FixedPlattCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The slope parameter of the calibration function 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Slope { get; set; } = 1d;

            /// <summary>
            /// The offset parameter of the calibration function 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Offset { get; set; }

            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FixedPlattCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FixedPlattCalibratorPipelineStep(output);
            }

            private class FixedPlattCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public FixedPlattCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Combine multiclass classifiers into an ensemble
        /// </summary>
        public sealed partial class MultiClassPipelineEnsemble
        {


            /// <summary>
            /// The combiner used to combine the scores
            /// </summary>
            public EnsembleCreatorClassifierCombiner ModelCombiner { get; set; } = EnsembleCreatorClassifierCombiner.Median;

            /// <summary>
            /// The models to combine into an ensemble
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a multi output regression scored dataset.
        /// </summary>
        public sealed partial class MultiOutputRegressionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Loss function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Supress labels and scores in per-instance outputs?
            /// </summary>
            public bool SupressScoresAndLabels { get; set; } = false;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Apply a Naive calibrator to an input model
        /// </summary>
        public sealed partial class NaiveCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(NaiveCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new NaiveCalibratorPipelineStep(output);
            }

            private class NaiveCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public NaiveCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {
        public enum NormalizeOption
        {
            No = 0,
            Warn = 1,
            Auto = 2,
            Yes = 3
        }

        public enum CachingOptions
        {
            Auto = 0,
            Memory = 1,
            Disk = 2,
            None = 3
        }


        public sealed partial class OneVersusAllMacroSubGraphOutput
        {
            /// <summary>
            /// The predictor model for the subgraph exemplar.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <include file='../Microsoft.ML.StandardLearners/Standard/MultiClass/doc.xml' path='doc/members/member[@name="OVA"]/*'/>
        public sealed partial class OneVersusAll : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The subgraph for the binary trainer used to construct the OVA learner. This should be a TrainBinary node.
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph output.
            /// </summary>
            public OneVersusAllMacroSubGraphOutput OutputForSubGraph { get; set; } = new OneVersusAllMacroSubGraphOutput();

            /// <summary>
            /// Use probabilities in OVA combiner
            /// </summary>
            public bool UseProbabilities { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public NormalizeOption NormalizeFeatures { get; set; } = NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public CachingOptions Caching { get; set; } = CachingOptions.Auto;


            public sealed class Output
            {
                /// <summary>
                /// The trained multiclass model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(OneVersusAll)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new OneVersusAllPipelineStep(output);
            }

            private class OneVersusAllPipelineStep : ILearningPipelinePredictorStep
            {
                public OneVersusAllPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {
        public enum OnnxVersion
        {
            Stable = 0,
            Experimental = 1
        }


        /// <summary>
        /// Converts the model to ONNX format.
        /// </summary>
        public sealed partial class OnnxConverter
        {


            /// <summary>
            /// The path to write the output ONNX to.
            /// </summary>
            public string Onnx { get; set; }

            /// <summary>
            /// The path to write the output JSON to.
            /// </summary>
            public string Json { get; set; }

            /// <summary>
            /// The 'name' property in the output ONNX. By default this will be the ONNX extension-less name.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The 'domain' property in the output ONNX.
            /// </summary>
            public string Domain { get; set; }

            /// <summary>
            /// Array of input column names to drop
            /// </summary>
            public string[] InputsToDrop { get; set; }

            /// <summary>
            /// Array of output column names to drop
            /// </summary>
            public string[] OutputsToDrop { get; set; }

            /// <summary>
            /// Model that needs to be converted to ONNX format.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// The targeted ONNX version. It can be either "Stable" or "Experimental". If "Experimental" is used, produced model can contain components that is not officially supported in ONNX standard.
            /// </summary>
            public OnnxVersion OnnxVersion { get; set; } = OnnxVersion.Stable;

            /// <summary>
            /// The data file
            /// </summary>
            public string DataFile { get; set; }


            public sealed class Output
            {
            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Combines a sequence of PredictorModels into a single model
        /// </summary>
        public sealed partial class OvaModelCombiner : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Input models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> ModelArray { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Use probabilities from learners instead of raw values.
            /// </summary>
            public bool UseProbabilities { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public NormalizeOption NormalizeFeatures { get; set; } = NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public CachingOptions Caching { get; set; } = CachingOptions.Auto;


            public sealed class Output
            {
                /// <summary>
                /// Predictor model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(OvaModelCombiner)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new OvaModelCombinerPipelineStep(output);
            }

            private class OvaModelCombinerPipelineStep : ILearningPipelinePredictorStep
            {
                public OvaModelCombinerPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Apply a PAV calibrator to an input model
        /// </summary>
        public sealed partial class PAVCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PAVCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PAVCalibratorPipelineStep(output);
            }

            private class PAVCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public PAVCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// AutoML pipeline sweeping optimzation macro.
        /// </summary>
        public sealed partial class PipelineSweeper
        {


            /// <summary>
            /// The data to be used for training.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The data to be used for testing.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TestingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The arguments for creating an AutoMlState component.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public AutoMlStateBase StateArguments { get; set; }

            /// <summary>
            /// The stateful object conducting of the autoML search.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IMlState> State { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IMlState>();

            /// <summary>
            /// Number of candidate pipelines to retrieve each round.
            /// </summary>
            public int BatchSize { get; set; }

            /// <summary>
            /// Output datasets from previous iteration of sweep.
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> CandidateOutputs { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column(s) to use as Role 'Label'
            /// </summary>
            public string[] LabelColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'Group'
            /// </summary>
            public string[] GroupColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'Weight'
            /// </summary>
            public string[] WeightColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'Name'
            /// </summary>
            public string[] NameColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'NumericFeature'
            /// </summary>
            public string[] NumericFeatureColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'CategoricalFeature'
            /// </summary>
            public string[] CategoricalFeatureColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'TextFeature'
            /// </summary>
            public string[] TextFeatureColumns { get; set; }

            /// <summary>
            /// Column(s) to use as Role 'ImagePath'
            /// </summary>
            public string[] ImagePathColumns { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// Stateful autoML object, keeps track of where the search in progress.
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IMlState> State { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IMlState>();

                /// <summary>
                /// Results of the sweep, including pipelines (as graph strings), IDs, and metric values.
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Results { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Apply a Platt calibrator to an input model
        /// </summary>
        public sealed partial class PlattCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PlattCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PlattCalibratorPipelineStep(output);
            }

            private class PlattCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public PlattCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a quantile regression scored dataset.
        /// </summary>
        public sealed partial class QuantileRegressionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Loss function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Quantile index to select
            /// </summary>
            public int? Index { get; set; }

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a ranking scored dataset.
        /// </summary>
        public sealed partial class RankerEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Column to use for the group ID
            /// </summary>
            public string GroupIdColumn { get; set; }

            /// <summary>
            /// Maximum truncation level for computing (N)DCG
            /// </summary>
            public int DcgTruncationLevel { get; set; } = 3;

            /// <summary>
            /// Label relevance gains
            /// </summary>
            public string LabelGains { get; set; } = "0,3,7,15,31";

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Combine regression models into an ensemble
        /// </summary>
        public sealed partial class RegressionEnsemble
        {


            /// <summary>
            /// The combiner used to combine the scores
            /// </summary>
            public EnsembleCreatorScoreCombiner ModelCombiner { get; set; } = EnsembleCreatorScoreCombiner.Median;

            /// <summary>
            /// The models to combine into an ensemble
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Whether to validate that all the pipelines are identical
            /// </summary>
            public bool ValidatePipelines { get; set; } = true;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Evaluates a regression scored dataset.
        /// </summary>
        public sealed partial class RegressionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Loss function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Combine regression models into an ensemble
        /// </summary>
        public sealed partial class RegressionPipelineEnsemble
        {


            /// <summary>
            /// The combiner used to combine the scores
            /// </summary>
            public EnsembleCreatorScoreCombiner ModelCombiner { get; set; } = EnsembleCreatorScoreCombiner.Median;

            /// <summary>
            /// The models to combine into an ensemble
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Summarize a linear regression predictor.
        /// </summary>
        public sealed partial class Summarizer
        {


            /// <summary>
            /// The predictor to summarize
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The summary of a predictor
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Summary { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The training set statistics. Note that this output can be null.
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Stats { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        /// <summary>
        /// Extracts the sweep result.
        /// </summary>
        public sealed partial class SweepResultExtractor
        {


            /// <summary>
            /// The stateful object conducting of the autoML search.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IMlState> State { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IMlState>();


            public sealed class Output
            {
                /// <summary>
                /// Stateful autoML object, keeps track of where the search in progress.
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IMlState> State { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IMlState>();

                /// <summary>
                /// Results of the sweep, including pipelines (as graph strings), IDs, and metric values.
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Results { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        public sealed partial class TrainTestBinaryMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed partial class TrainTestBinaryMacroSubGraphOutput
        {
            /// <summary>
            /// The model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// Train test for binary classification
        /// </summary>
        public sealed partial class TrainTestBinaryEvaluator
        {


            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The data to be used for testing
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TestingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public TrainTestBinaryMacroSubGraphInput Inputs { get; set; } = new TrainTestBinaryMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public TrainTestBinaryMacroSubGraphOutput Outputs { get; set; } = new TrainTestBinaryMacroSubGraphOutput();


            public sealed class Output
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Models
    {

        public sealed partial class TrainTestMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed partial class TrainTestMacroSubGraphOutput
        {
            /// <summary>
            /// The predictor model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Transform model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

        }

        /// <summary>
        /// General train test for any supported evaluator
        /// </summary>
        public sealed partial class TrainTestEvaluator
        {


            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The data to be used for testing
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TestingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The aggregated transform model from the pipeline before this command, to apply to the test data, and also include in the final model, together with the predictor model.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public TrainTestMacroSubGraphInput Inputs { get; set; } = new TrainTestMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public TrainTestMacroSubGraphOutput Outputs { get; set; } = new TrainTestMacroSubGraphOutput();

            /// <summary>
            /// Specifies the trainer kind, which determines the evaluator to be used.
            /// </summary>
            public MacroUtilsTrainerKinds Kind { get; set; } = MacroUtilsTrainerKinds.SignatureBinaryClassifierTrainer;

            /// <summary>
            /// Identifies which pipeline was run for this train test.
            /// </summary>
            public string PipelineId { get; set; }

            /// <summary>
            /// Indicates whether to include and output training dataset metrics.
            /// </summary>
            public bool IncludeTrainingMetrics { get; set; } = false;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for grouping
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupColumn { get; set; }

            /// <summary>
            /// Name column name
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> NameColumn { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// The final model including the trained predictor model and the model from the transforms, provided as the Input.TransformModel.
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// The final model including the trained predictor model and the model from the transforms, provided as the Input.TransformModel.
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Warning dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingWarnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingOverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingPerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {

        /// <summary>
        /// Applies a Exponential average on a time series.
        /// </summary>
        public sealed partial class ExponentialAverage : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Coefficient d in: d m(y_t) = d * y_t + (1-d) * m(y_(t-1)), it should be in [0, 1].
            /// </summary>
            public float Decay { get; set; } = 0.9f;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ExponentialAverage)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ExponentialAveragePipelineStep(output);
            }

            private class ExponentialAveragePipelineStep : ILearningPipelineDataStep
            {
                public ExponentialAveragePipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {
        public enum SequentialAnomalyDetectionTransformBaseSingleIidAnomalyDetectionBaseStateMartingaleType : byte
        {
            None = 0,
            Power = 1,
            Mixture = 2
        }


        /// <summary>
        /// This transform detects the change-points in an i.i.d. sequence using adaptive kernel density estimation and martingales.
        /// </summary>
        public sealed partial class IidChangePointDetector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column.
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The change history length.
            /// </summary>
            public int ChangeHistoryLength { get; set; } = 20;

            /// <summary>
            /// The confidence for change point detection in the range [0, 100].
            /// </summary>
            public double Confidence { get; set; } = 95d;

            /// <summary>
            /// The martingale used for scoring.
            /// </summary>
            public SequentialAnomalyDetectionTransformBaseSingleIidAnomalyDetectionBaseStateMartingaleType Martingale { get; set; } = SequentialAnomalyDetectionTransformBaseSingleIidAnomalyDetectionBaseStateMartingaleType.Power;

            /// <summary>
            /// The epsilon parameter for the Power martingale.
            /// </summary>
            public double PowerMartingaleEpsilon { get; set; } = 0.1d;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(IidChangePointDetector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new IidChangePointDetectorPipelineStep(output);
            }

            private class IidChangePointDetectorPipelineStep : ILearningPipelineDataStep
            {
                public IidChangePointDetectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {
        public enum SequentialAnomalyDetectionTransformBaseSingleIidAnomalyDetectionBaseStateAnomalySide : byte
        {
            Positive = 0,
            Negative = 1,
            TwoSided = 2
        }


        /// <summary>
        /// This transform detects the spikes in a i.i.d. sequence using adaptive kernel density estimation.
        /// </summary>
        public sealed partial class IidSpikeDetector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column.
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The argument that determines whether to detect positive or negative anomalies, or both.
            /// </summary>
            public SequentialAnomalyDetectionTransformBaseSingleIidAnomalyDetectionBaseStateAnomalySide Side { get; set; } = SequentialAnomalyDetectionTransformBaseSingleIidAnomalyDetectionBaseStateAnomalySide.TwoSided;

            /// <summary>
            /// The size of the sliding window for computing the p-value.
            /// </summary>
            public int PvalueHistoryLength { get; set; } = 100;

            /// <summary>
            /// The confidence for spike detection in the range [0, 100].
            /// </summary>
            public double Confidence { get; set; } = 99d;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(IidSpikeDetector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new IidSpikeDetectorPipelineStep(output);
            }

            private class IidSpikeDetectorPipelineStep : ILearningPipelineDataStep
            {
                public IidSpikeDetectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {

        /// <summary>
        /// Detects the values of time-series that are in the top percentile of the sliding window.
        /// </summary>
        public sealed partial class PercentileThresholdTransform : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The percentile value for thresholding in the range [0, 100]
            /// </summary>
            public double Percentile { get; set; } = 1d;

            /// <summary>
            /// The size of the sliding window for computing the percentile threshold. The default value is set to 1.
            /// </summary>
            public int WindowSize { get; set; } = 1;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PercentileThresholdTransform)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PercentileThresholdTransformPipelineStep(output);
            }

            private class PercentileThresholdTransformPipelineStep : ILearningPipelineDataStep
            {
                public PercentileThresholdTransformPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {

        /// <summary>
        /// This P-Value transform calculates the p-value of the current input in the sequence with regard to the values in the sliding window.
        /// </summary>
        public sealed partial class PValueTransform : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The seed value of the random generator
            /// </summary>
            public int Seed { get; set; }

            /// <summary>
            /// The flag that determines whether the p-values are calculated on the positive side
            /// </summary>
            public bool PositiveSide { get; set; } = true;

            /// <summary>
            /// The size of the sliding window for computing the p-value
            /// </summary>
            public int WindowSize { get; set; } = 1;

            /// <summary>
            /// The size of the initial window for computing the p-value. The default value is set to 0, which means there is no initial window considered.
            /// </summary>
            public int InitialWindowSize { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PValueTransform)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PValueTransformPipelineStep(output);
            }

            private class PValueTransformPipelineStep : ILearningPipelineDataStep
            {
                public PValueTransformPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {
        public enum SlidingWindowTransformBaseSingleBeginOptions : byte
        {
            NaNValues = 0,
            FirstValue = 1
        }


        /// <summary>
        /// Returns the last values for a time series [y(t-d-l+1), y(t-d-l+2), ..., y(t-l-1), y(t-l)] where d is the size of the window, l the lag and y is a Float.
        /// </summary>
        public sealed partial class SlidingWindowTransform : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The size of the sliding window for computing the moving average
            /// </summary>
            public int WindowSize { get; set; } = 2;

            /// <summary>
            /// Lag between current observation and last observation from the sliding window
            /// </summary>
            public int Lag { get; set; } = 1;

            /// <summary>
            /// Define how to populate the first rows of the produced series
            /// </summary>
            public SlidingWindowTransformBaseSingleBeginOptions Begin { get; set; } = SlidingWindowTransformBaseSingleBeginOptions.NaNValues;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(SlidingWindowTransform)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new SlidingWindowTransformPipelineStep(output);
            }

            private class SlidingWindowTransformPipelineStep : ILearningPipelineDataStep
            {
                public SlidingWindowTransformPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {
        public enum ErrorFunctionUtilsErrorFunction : byte
        {
            SignedDifference = 0,
            AbsoluteDifference = 1,
            SignedProportion = 2,
            AbsoluteProportion = 3,
            SquaredDifference = 4
        }

        public enum SequentialAnomalyDetectionTransformBaseSingleSsaAnomalyDetectionBaseStateMartingaleType : byte
        {
            None = 0,
            Power = 1,
            Mixture = 2
        }


        /// <summary>
        /// This transform detects the change-points in a seasonal time-series using Singular Spectrum Analysis (SSA).
        /// </summary>
        public sealed partial class SsaChangePointDetector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column.
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The change history length.
            /// </summary>
            public int ChangeHistoryLength { get; set; } = 20;

            /// <summary>
            /// The number of points from the beginning of the sequence used for training.
            /// </summary>
            public int TrainingWindowSize { get; set; } = 100;

            /// <summary>
            /// The confidence for change point detection in the range [0, 100].
            /// </summary>
            public double Confidence { get; set; } = 95d;

            /// <summary>
            /// An upper bound on the largest relevant seasonality in the input time-series.
            /// </summary>
            public int SeasonalWindowSize { get; set; } = 10;

            /// <summary>
            /// The function used to compute the error between the expected and the observed value.
            /// </summary>
            public ErrorFunctionUtilsErrorFunction ErrorFunction { get; set; } = ErrorFunctionUtilsErrorFunction.SignedDifference;

            /// <summary>
            /// The martingale used for scoring.
            /// </summary>
            public SequentialAnomalyDetectionTransformBaseSingleSsaAnomalyDetectionBaseStateMartingaleType Martingale { get; set; } = SequentialAnomalyDetectionTransformBaseSingleSsaAnomalyDetectionBaseStateMartingaleType.Power;

            /// <summary>
            /// The epsilon parameter for the Power martingale.
            /// </summary>
            public double PowerMartingaleEpsilon { get; set; } = 0.1d;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(SsaChangePointDetector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new SsaChangePointDetectorPipelineStep(output);
            }

            private class SsaChangePointDetectorPipelineStep : ILearningPipelineDataStep
            {
                public SsaChangePointDetectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.TimeSeriesProcessing
    {
        public enum SequentialAnomalyDetectionTransformBaseSingleSsaAnomalyDetectionBaseStateAnomalySide : byte
        {
            Positive = 0,
            Negative = 1,
            TwoSided = 2
        }


        /// <summary>
        /// This transform detects the spikes in a seasonal time-series using Singular Spectrum Analysis (SSA).
        /// </summary>
        public sealed partial class SsaSpikeDetector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The name of the source column.
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// The name of the new column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// The argument that determines whether to detect positive or negative anomalies, or both.
            /// </summary>
            public SequentialAnomalyDetectionTransformBaseSingleSsaAnomalyDetectionBaseStateAnomalySide Side { get; set; } = SequentialAnomalyDetectionTransformBaseSingleSsaAnomalyDetectionBaseStateAnomalySide.TwoSided;

            /// <summary>
            /// The size of the sliding window for computing the p-value.
            /// </summary>
            public int PvalueHistoryLength { get; set; } = 100;

            /// <summary>
            /// The number of points from the beginning of the sequence used for training.
            /// </summary>
            public int TrainingWindowSize { get; set; } = 100;

            /// <summary>
            /// The confidence for spike detection in the range [0, 100].
            /// </summary>
            public double Confidence { get; set; } = 99d;

            /// <summary>
            /// An upper bound on the largest relevant seasonality in the input time-series.
            /// </summary>
            public int SeasonalWindowSize { get; set; } = 10;

            /// <summary>
            /// The function used to compute the error between the expected and the observed value.
            /// </summary>
            public ErrorFunctionUtilsErrorFunction ErrorFunction { get; set; } = ErrorFunctionUtilsErrorFunction.SignedDifference;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(SsaSpikeDetector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new SsaSpikeDetectorPipelineStep(output);
            }

            private class SsaSpikeDetectorPipelineStep : ILearningPipelineDataStep
            {
                public SsaSpikeDetectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/Online/doc.xml' path='doc/members/member[@name="AP"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/Online/doc.xml' path='doc/members/example[@name="AP"]/*' />
        public sealed partial class AveragedPerceptronBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ClassificationLossFunction LossFunction { get; set; } = new HingeLossClassificationLossFunction();

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("LearningRate", new object[]{0.01f, 0.1f, 0.5f, 1f})]
            public float LearningRate { get; set; } = 1f;

            /// <summary>
            /// Decrease learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DecreaseLearningRate", new object[]{false, true})]
            public bool DecreaseLearningRate { get; set; } = false;

            /// <summary>
            /// Number of examples after which weights will be reset to the current average
            /// </summary>
            public long? ResetWeightsAfterXExamples { get; set; }

            /// <summary>
            /// Instead of updating averaged weights on every example, only update when loss is nonzero
            /// </summary>
            public bool DoLazyUpdates { get; set; } = true;

            /// <summary>
            /// L2 Regularization Weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2RegularizerWeight", 0f, 0.4f)]
            public float L2RegularizerWeight { get; set; }

            /// <summary>
            /// Extra weight given to more recent updates
            /// </summary>
            public float RecencyGain { get; set; }

            /// <summary>
            /// Whether Recency Gain is multiplicative (vs. additive)
            /// </summary>
            public bool RecencyGainMulti { get; set; } = false;

            /// <summary>
            /// Do averaging?
            /// </summary>
            public bool Averaged { get; set; } = true;

            /// <summary>
            /// The inexactness tolerance for averaging
            /// </summary>
            public float AveragedTolerance { get; set; } = 0.01f;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumIterations", 1, 100, stepSize:10, isLogScale:true)]
            public int NumIterations { get; set; } = 1;

            /// <summary>
            /// Initial Weights and bias, comma-separated
            /// </summary>
            public string InitialWeights { get; set; }

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Size of cache when trained in Scope
            /// </summary>
            public int StreamingCacheSize { get; set; } = 1000000;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(AveragedPerceptronBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new AveragedPerceptronBinaryClassifierPipelineStep(output);
            }

            private class AveragedPerceptronBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public AveragedPerceptronBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Train binary ensemble.
        /// </summary>
        public sealed partial class EnsembleBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Algorithm to prune the base learners for selective Ensemble
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleBinarySubModelSelector SubModelSelectorType { get; set; } = new AllSelectorEnsembleBinarySubModelSelector();

            /// <summary>
            /// Output combiner
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleBinaryOutputCombiner OutputCombiner { get; set; } = new MedianEnsembleBinaryOutputCombiner();

            /// <summary>
            /// Number of models per batch. If not specified, will default to 50 if there is only one base predictor, or the number of base predictors otherwise.
            /// </summary>
            public int? NumModels { get; set; }

            /// <summary>
            /// Batch size
            /// </summary>
            public int BatchSize { get; set; } = -1;

            /// <summary>
            /// Sampling Type
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleSubsetSelector SamplingType { get; set; } = new BootstrapSelectorEnsembleSubsetSelector();

            /// <summary>
            /// All the base learners will run asynchronously if the value is true
            /// </summary>
            public bool TrainParallel { get; set; } = false;

            /// <summary>
            /// True, if metrics for each model need to be evaluated and shown in comparison table. This is done by using validation set if available or the training set
            /// </summary>
            public bool ShowMetrics { get; set; } = false;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(EnsembleBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new EnsembleBinaryClassifierPipelineStep(output);
            }

            private class EnsembleBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public EnsembleBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Train multiclass ensemble.
        /// </summary>
        public sealed partial class EnsembleClassification : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Algorithm to prune the base learners for selective Ensemble
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleMulticlassSubModelSelector SubModelSelectorType { get; set; } = new AllSelectorMultiClassEnsembleMulticlassSubModelSelector();

            /// <summary>
            /// Output combiner
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleMulticlassOutputCombiner OutputCombiner { get; set; } = new MultiMedianEnsembleMulticlassOutputCombiner();

            /// <summary>
            /// Number of models per batch. If not specified, will default to 50 if there is only one base predictor, or the number of base predictors otherwise.
            /// </summary>
            public int? NumModels { get; set; }

            /// <summary>
            /// Batch size
            /// </summary>
            public int BatchSize { get; set; } = -1;

            /// <summary>
            /// Sampling Type
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleSubsetSelector SamplingType { get; set; } = new BootstrapSelectorEnsembleSubsetSelector();

            /// <summary>
            /// All the base learners will run asynchronously if the value is true
            /// </summary>
            public bool TrainParallel { get; set; } = false;

            /// <summary>
            /// True, if metrics for each model need to be evaluated and shown in comparison table. This is done by using validation set if available or the training set
            /// </summary>
            public bool ShowMetrics { get; set; } = false;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(EnsembleClassification)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new EnsembleClassificationPipelineStep(output);
            }

            private class EnsembleClassificationPipelineStep : ILearningPipelinePredictorStep
            {
                public EnsembleClassificationPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Train regression ensemble.
        /// </summary>
        public sealed partial class EnsembleRegression : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Algorithm to prune the base learners for selective Ensemble
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleRegressionSubModelSelector SubModelSelectorType { get; set; } = new AllSelectorEnsembleRegressionSubModelSelector();

            /// <summary>
            /// Output combiner
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleRegressionOutputCombiner OutputCombiner { get; set; } = new MedianEnsembleRegressionOutputCombiner();

            /// <summary>
            /// Number of models per batch. If not specified, will default to 50 if there is only one base predictor, or the number of base predictors otherwise.
            /// </summary>
            public int? NumModels { get; set; }

            /// <summary>
            /// Batch size
            /// </summary>
            public int BatchSize { get; set; } = -1;

            /// <summary>
            /// Sampling Type
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleSubsetSelector SamplingType { get; set; } = new BootstrapSelectorEnsembleSubsetSelector();

            /// <summary>
            /// All the base learners will run asynchronously if the value is true
            /// </summary>
            public bool TrainParallel { get; set; } = false;

            /// <summary>
            /// True, if metrics for each model need to be evaluated and shown in comparison table. This is done by using validation set if available or the training set
            /// </summary>
            public bool ShowMetrics { get; set; } = false;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(EnsembleRegression)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new EnsembleRegressionPipelineStep(output);
            }

            private class EnsembleRegressionPipelineStep : ILearningPipelinePredictorStep
            {
                public EnsembleRegressionPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {
        public enum Bundle : byte
        {
            None = 0,
            AggregateLowPopulation = 1,
            Adjacent = 2
        }


        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="FastForest"]/*' />
        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/example[@name="FastForestBinaryClassifier"]/*' />
        public sealed partial class FastForestBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Number of labels to be sampled from each leaf to make the distribtuion
            /// </summary>
            public int QuantileSampleCount { get; set; } = 100;

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Bundle Bundling { get; set; } = Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 0.7d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; } = 1;

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 0.7d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FastForestBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FastForestBinaryClassifierPipelineStep(output);
            }

            private class FastForestBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public FastForestBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="FastForest"]/*' />
        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/example[@name="FastForestRegressor"]/*' />
        public sealed partial class FastForestRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Shuffle the labels on every iteration. Useful probably only if using this tree as a tree leaf featurizer for multiclass.
            /// </summary>
            public bool ShuffleLabels { get; set; } = false;

            /// <summary>
            /// Number of labels to be sampled from each leaf to make the distribtuion
            /// </summary>
            public int QuantileSampleCount { get; set; } = 100;

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Bundle Bundling { get; set; } = Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 0.7d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; } = 1;

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 0.7d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FastForestRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FastForestRegressorPipelineStep(output);
            }

            private class FastForestRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public FastForestRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {
        public enum BoostedTreeArgsOptimizationAlgorithmType
        {
            GradientDescent = 0,
            AcceleratedGradientDescent = 1,
            ConjugateGradientDescent = 2
        }


        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="FastTree"]/*' />
        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/example[@name="FastTreeBinaryClassifier"]/*' />
        public sealed partial class FastTreeBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Should we use derivatives optimized for unbalanced sets
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Bundle Bundling { get; set; } = Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FastTreeBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FastTreeBinaryClassifierPipelineStep(output);
            }

            private class FastTreeBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="FastTree"]/*' />
        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/example[@name="FastTreeRanker"]/*' />
        public sealed partial class FastTreeRanker : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31";

            /// <summary>
            /// Train DCG instead of NDCG
            /// </summary>
            public bool TrainDcg { get; set; } = false;

            /// <summary>
            /// The sorting algorithm to use for DCG and LambdaMart calculations [DescendingStablePessimistic/DescendingStable/DescendingReverse/DescendingDotNet]
            /// </summary>
            public string SortingAlgorithm { get; set; } = "DescendingStablePessimistic";

            /// <summary>
            /// max-NDCG truncation to use in the Lambda Mart algorithm
            /// </summary>
            public int LambdaMartMaxTruncation { get; set; } = 100;

            /// <summary>
            /// Use shifted NDCG
            /// </summary>
            public bool ShiftedNdcg { get; set; } = false;

            /// <summary>
            /// Cost function parameter (w/c)
            /// </summary>
            public char CostFunctionParam { get; set; } = 'w';

            /// <summary>
            /// Distance weight 2 adjustment to cost
            /// </summary>
            public bool DistanceWeight2 { get; set; } = false;

            /// <summary>
            /// Normalize query lambdas
            /// </summary>
            public bool NormalizeQueryLambdas { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Bundle Bundling { get; set; } = Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRankingOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FastTreeRanker)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FastTreeRankerPipelineStep(output);
            }

            private class FastTreeRankerPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeRankerPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="FastTree"]/*' />
        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/example[@name="FastTreeRegressor"]/*' />
        public sealed partial class FastTreeRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Bundle Bundling { get; set; } = Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FastTreeRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FastTreeRegressorPipelineStep(output);
            }

            private class FastTreeRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="FastTreeTweedieRegression"]/*' />
        public sealed partial class FastTreeTweedieRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Index parameter for the Tweedie distribution, in the range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate values are compound Poisson loss.
            /// </summary>
            public double Index { get; set; } = 1.5d;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Bundle Bundling { get; set; } = Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FastTreeTweedieRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FastTreeTweedieRegressorPipelineStep(output);
            }

            private class FastTreeTweedieRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeTweedieRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/FactorizationMachine/doc.xml' path='doc/members/member[@name="FieldAwareFactorizationMachineBinaryClassifier"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/FactorizationMachine/doc.xml' path='doc/members/example[@name="FieldAwareFactorizationMachineBinaryClassifier"]/*' />
        public sealed partial class FieldAwareFactorizationMachineBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Initial learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRate", 0.001f, 1f, isLogScale:true)]
            public float LearningRate { get; set; } = 0.1f;

            /// <summary>
            /// Number of training iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("Iters", 1, 100)]
            public int Iters { get; set; } = 5;

            /// <summary>
            /// Latent space dimension
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("LatentDim", 4, 100)]
            public int LatentDim { get; set; } = 20;

            /// <summary>
            /// Regularization coefficient of linear weights
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LambdaLinear", 1E-08f, 1f, isLogScale:true)]
            public float LambdaLinear { get; set; } = 0.0001f;

            /// <summary>
            /// Regularization coefficient of latent weights
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LambdaLatent", 1E-08f, 1f, isLogScale:true)]
            public float LambdaLatent { get; set; } = 0.0001f;

            /// <summary>
            /// Whether to normalize the input vectors so that the concatenation of all fields' feature vectors is unit-length
            /// </summary>
            public bool Norm { get; set; } = true;

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Report traning progress or not
            /// </summary>
            public bool Verbose { get; set; } = true;

            /// <summary>
            /// Radius of initial latent factors
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Radius", 0.1f, 1f)]
            public float Radius { get; set; } = 0.5f;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FieldAwareFactorizationMachineBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FieldAwareFactorizationMachineBinaryClassifierPipelineStep(output);
            }

            private class FieldAwareFactorizationMachineBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public FieldAwareFactorizationMachineBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Trains a gradient boosted stump per feature, on all features simultaneously, to fit target values using least-squares. It mantains no interactions between features.
        /// </summary>
        public sealed partial class GeneralizedAdditiveModelBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Should we use derivatives optimized for unbalanced sets
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public int GainConfidenceLevel { get; set; }

            /// <summary>
            /// Total number of iterations over all features
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumIterations", new object[]{200, 1500, 9500})]
            public int NumIterations { get; set; } = 9500;

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.001f, 0.1f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.002d;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Upper bound on absolute value of single output
            /// </summary>
            public double MaxOutput { get; set; } = double.PositiveInfinity;

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// Minimum number of training instances required to form a partition
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocuments", new object[]{1, 10, 50})]
            public int MinDocuments { get; set; } = 10;

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(GeneralizedAdditiveModelBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new GeneralizedAdditiveModelBinaryClassifierPipelineStep(output);
            }

            private class GeneralizedAdditiveModelBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public GeneralizedAdditiveModelBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Trains a gradient boosted stump per feature, on all features simultaneously, to fit target values using least-squares. It mantains no interactions between features.
        /// </summary>
        public sealed partial class GeneralizedAdditiveModelRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Metric for pruning. (For regression, 1: L1, 2:L2; default L2)
            /// </summary>
            public int PruningMetrics { get; set; } = 2;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public int GainConfidenceLevel { get; set; }

            /// <summary>
            /// Total number of iterations over all features
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumIterations", new object[]{200, 1500, 9500})]
            public int NumIterations { get; set; } = 9500;

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.001f, 0.1f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.002d;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Upper bound on absolute value of single output
            /// </summary>
            public double MaxOutput { get; set; } = double.PositiveInfinity;

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// Minimum number of training instances required to form a partition
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocuments", new object[]{1, 10, 50})]
            public int MinDocuments { get; set; } = 10;

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(GeneralizedAdditiveModelRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new GeneralizedAdditiveModelRegressorPipelineStep(output);
            }

            private class GeneralizedAdditiveModelRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public GeneralizedAdditiveModelRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {
        public enum KMeansPlusPlusTrainerInitAlgorithm
        {
            KMeansPlusPlus = 0,
            Random = 1,
            KMeansParallel = 2
        }


        /// <include file='../Microsoft.ML.KMeansClustering/doc.xml' path='doc/members/member[@name="KMeans++"]/*' />
        /// <include file='../Microsoft.ML.KMeansClustering/doc.xml' path='doc/members/example[@name="KMeans++"]/*' />
        public sealed partial class KMeansPlusPlusClusterer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IUnsupervisedTrainerWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The number of clusters
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("K", new object[]{5, 10, 20, 40})]
            public int K { get; set; } = 5;

            /// <summary>
            /// Cluster initialization algorithm
            /// </summary>
            public KMeansPlusPlusTrainerInitAlgorithm InitAlgorithm { get; set; } = KMeansPlusPlusTrainerInitAlgorithm.KMeansParallel;

            /// <summary>
            /// Tolerance parameter for trainer convergence. Lower = slower, more accurate
            /// </summary>
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Maximum number of iterations.
            /// </summary>
            public int MaxIterations { get; set; } = 1000;

            /// <summary>
            /// Memory budget (in MBs) to use for KMeans acceleration
            /// </summary>
            public int AccelMemBudgetMb { get; set; } = 4096;

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IClusteringOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(KMeansPlusPlusClusterer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new KMeansPlusPlusClustererPipelineStep(output);
            }

            private class KMeansPlusPlusClustererPipelineStep : ILearningPipelinePredictorStep
            {
                public KMeansPlusPlusClustererPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {
        public enum LightGbmArgumentsEvalMetricType
        {
            DefaultMetric = 0,
            Rmse = 1,
            Mae = 2,
            Logloss = 3,
            Error = 4,
            Merror = 5,
            Mlogloss = 6,
            Auc = 7,
            Ndcg = 8,
            Map = 9
        }


        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/member[@name="LightGBM"]/*' />
        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/example[@name="LightGbmBinaryClassifier"]/*' />
        public sealed partial class LightGbmBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of iterations.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumBoostRound", new object[]{10, 20, 50, 100, 150, 200})]
            public int NumBoostRound { get; set; } = 100;

            /// <summary>
            /// Shrinkage rate for trees, used to prevent over-fitting. Range: (0,1].
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRate", 0.025f, 0.4f, isLogScale:true)]
            public double? LearningRate { get; set; }

            /// <summary>
            /// Maximum leaves for trees.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int? NumLeaves { get; set; }

            /// <summary>
            /// Minimum number of instances needed in a child.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerLeaf", new object[]{1, 10, 20, 50})]
            public int? MinDataPerLeaf { get; set; }

            /// <summary>
            /// Max number of bucket bin for features.
            /// </summary>
            public int MaxBin { get; set; } = 255;

            /// <summary>
            /// Which booster to use, can be gbtree, gblinear or dart. gbtree and dart use tree based model while gblinear uses linear function.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public BoosterParameterFunction Booster { get; set; } = new GbdtBoosterParameterFunction();

            /// <summary>
            /// Verbose
            /// </summary>
            public bool VerboseEval { get; set; } = false;

            /// <summary>
            /// Printing running messages.
            /// </summary>
            public bool Silent { get; set; } = true;

            /// <summary>
            /// Number of parallel threads used to run LightGBM.
            /// </summary>
            public int? NThread { get; set; }

            /// <summary>
            /// Evaluation metrics.
            /// </summary>
            public LightGbmArgumentsEvalMetricType EvalMetric { get; set; } = LightGbmArgumentsEvalMetricType.DefaultMetric;

            /// <summary>
            /// Use softmax loss for the multi classification.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseSoftmax", new object[]{true, false})]
            public bool? UseSoftmax { get; set; }

            /// <summary>
            /// Rounds of early stopping, 0 will disable it.
            /// </summary>
            public int EarlyStoppingRound { get; set; }

            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31,63,127,255,511,1023,2047,4095";

            /// <summary>
            /// Parameter for the sigmoid function. Used only in LightGbmBinaryTrainer, LightGbmMulticlassTrainer and in LightGbmRankingTrainer.
            /// </summary>
            public double Sigmoid { get; set; } = 0.5d;

            /// <summary>
            /// Number of entries in a batch when loading data.
            /// </summary>
            public int BatchSize { get; set; } = 1048576;

            /// <summary>
            /// Enable categorical split or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseCat", new object[]{true, false})]
            public bool? UseCat { get; set; }

            /// <summary>
            /// Enable missing value auto infer or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseMissing", new object[]{true, false})]
            public bool UseMissing { get; set; } = false;

            /// <summary>
            /// Min number of instances per categorical group.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerGroup", new object[]{10, 50, 100, 200})]
            public int MinDataPerGroup { get; set; } = 100;

            /// <summary>
            /// Max number of categorical thresholds.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MaxCatThreshold", new object[]{8, 16, 32, 64})]
            public int MaxCatThreshold { get; set; } = 32;

            /// <summary>
            /// Lapalace smooth term in categorical feature spilt. Avoid the bias of small categories.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatSmooth", new object[]{1, 10, 20})]
            public double CatSmooth { get; set; } = 10d;

            /// <summary>
            /// L2 Regularization for categorical split.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatL2", new object[]{0.1f, 0.5f, 1, 5, 10})]
            public double CatL2 { get; set; } = 10d;

            /// <summary>
            /// Parallel LightGBM Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelLightGBM ParallelTrainer { get; set; } = new SingleParallelLightGBM();

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LightGbmBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LightGbmBinaryClassifierPipelineStep(output);
            }

            private class LightGbmBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public LightGbmBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/member[@name="LightGBM"]/*' />
        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/example[@name="LightGbmClassifier"]/*' />
        public sealed partial class LightGbmClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of iterations.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumBoostRound", new object[]{10, 20, 50, 100, 150, 200})]
            public int NumBoostRound { get; set; } = 100;

            /// <summary>
            /// Shrinkage rate for trees, used to prevent over-fitting. Range: (0,1].
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRate", 0.025f, 0.4f, isLogScale:true)]
            public double? LearningRate { get; set; }

            /// <summary>
            /// Maximum leaves for trees.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int? NumLeaves { get; set; }

            /// <summary>
            /// Minimum number of instances needed in a child.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerLeaf", new object[]{1, 10, 20, 50})]
            public int? MinDataPerLeaf { get; set; }

            /// <summary>
            /// Max number of bucket bin for features.
            /// </summary>
            public int MaxBin { get; set; } = 255;

            /// <summary>
            /// Which booster to use, can be gbtree, gblinear or dart. gbtree and dart use tree based model while gblinear uses linear function.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public BoosterParameterFunction Booster { get; set; } = new GbdtBoosterParameterFunction();

            /// <summary>
            /// Verbose
            /// </summary>
            public bool VerboseEval { get; set; } = false;

            /// <summary>
            /// Printing running messages.
            /// </summary>
            public bool Silent { get; set; } = true;

            /// <summary>
            /// Number of parallel threads used to run LightGBM.
            /// </summary>
            public int? NThread { get; set; }

            /// <summary>
            /// Evaluation metrics.
            /// </summary>
            public LightGbmArgumentsEvalMetricType EvalMetric { get; set; } = LightGbmArgumentsEvalMetricType.DefaultMetric;

            /// <summary>
            /// Use softmax loss for the multi classification.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseSoftmax", new object[]{true, false})]
            public bool? UseSoftmax { get; set; }

            /// <summary>
            /// Rounds of early stopping, 0 will disable it.
            /// </summary>
            public int EarlyStoppingRound { get; set; }

            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31,63,127,255,511,1023,2047,4095";

            /// <summary>
            /// Parameter for the sigmoid function. Used only in LightGbmBinaryTrainer, LightGbmMulticlassTrainer and in LightGbmRankingTrainer.
            /// </summary>
            public double Sigmoid { get; set; } = 0.5d;

            /// <summary>
            /// Number of entries in a batch when loading data.
            /// </summary>
            public int BatchSize { get; set; } = 1048576;

            /// <summary>
            /// Enable categorical split or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseCat", new object[]{true, false})]
            public bool? UseCat { get; set; }

            /// <summary>
            /// Enable missing value auto infer or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseMissing", new object[]{true, false})]
            public bool UseMissing { get; set; } = false;

            /// <summary>
            /// Min number of instances per categorical group.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerGroup", new object[]{10, 50, 100, 200})]
            public int MinDataPerGroup { get; set; } = 100;

            /// <summary>
            /// Max number of categorical thresholds.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MaxCatThreshold", new object[]{8, 16, 32, 64})]
            public int MaxCatThreshold { get; set; } = 32;

            /// <summary>
            /// Lapalace smooth term in categorical feature spilt. Avoid the bias of small categories.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatSmooth", new object[]{1, 10, 20})]
            public double CatSmooth { get; set; } = 10d;

            /// <summary>
            /// L2 Regularization for categorical split.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatL2", new object[]{0.1f, 0.5f, 1, 5, 10})]
            public double CatL2 { get; set; } = 10d;

            /// <summary>
            /// Parallel LightGBM Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelLightGBM ParallelTrainer { get; set; } = new SingleParallelLightGBM();

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LightGbmClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LightGbmClassifierPipelineStep(output);
            }

            private class LightGbmClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public LightGbmClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/member[@name="LightGBM"]/*' />
        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/example[@name="LightGbmRanker"]/*' />
        public sealed partial class LightGbmRanker : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of iterations.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumBoostRound", new object[]{10, 20, 50, 100, 150, 200})]
            public int NumBoostRound { get; set; } = 100;

            /// <summary>
            /// Shrinkage rate for trees, used to prevent over-fitting. Range: (0,1].
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRate", 0.025f, 0.4f, isLogScale:true)]
            public double? LearningRate { get; set; }

            /// <summary>
            /// Maximum leaves for trees.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int? NumLeaves { get; set; }

            /// <summary>
            /// Minimum number of instances needed in a child.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerLeaf", new object[]{1, 10, 20, 50})]
            public int? MinDataPerLeaf { get; set; }

            /// <summary>
            /// Max number of bucket bin for features.
            /// </summary>
            public int MaxBin { get; set; } = 255;

            /// <summary>
            /// Which booster to use, can be gbtree, gblinear or dart. gbtree and dart use tree based model while gblinear uses linear function.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public BoosterParameterFunction Booster { get; set; } = new GbdtBoosterParameterFunction();

            /// <summary>
            /// Verbose
            /// </summary>
            public bool VerboseEval { get; set; } = false;

            /// <summary>
            /// Printing running messages.
            /// </summary>
            public bool Silent { get; set; } = true;

            /// <summary>
            /// Number of parallel threads used to run LightGBM.
            /// </summary>
            public int? NThread { get; set; }

            /// <summary>
            /// Evaluation metrics.
            /// </summary>
            public LightGbmArgumentsEvalMetricType EvalMetric { get; set; } = LightGbmArgumentsEvalMetricType.DefaultMetric;

            /// <summary>
            /// Use softmax loss for the multi classification.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseSoftmax", new object[]{true, false})]
            public bool? UseSoftmax { get; set; }

            /// <summary>
            /// Rounds of early stopping, 0 will disable it.
            /// </summary>
            public int EarlyStoppingRound { get; set; }

            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31,63,127,255,511,1023,2047,4095";

            /// <summary>
            /// Parameter for the sigmoid function. Used only in LightGbmBinaryTrainer, LightGbmMulticlassTrainer and in LightGbmRankingTrainer.
            /// </summary>
            public double Sigmoid { get; set; } = 0.5d;

            /// <summary>
            /// Number of entries in a batch when loading data.
            /// </summary>
            public int BatchSize { get; set; } = 1048576;

            /// <summary>
            /// Enable categorical split or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseCat", new object[]{true, false})]
            public bool? UseCat { get; set; }

            /// <summary>
            /// Enable missing value auto infer or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseMissing", new object[]{true, false})]
            public bool UseMissing { get; set; } = false;

            /// <summary>
            /// Min number of instances per categorical group.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerGroup", new object[]{10, 50, 100, 200})]
            public int MinDataPerGroup { get; set; } = 100;

            /// <summary>
            /// Max number of categorical thresholds.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MaxCatThreshold", new object[]{8, 16, 32, 64})]
            public int MaxCatThreshold { get; set; } = 32;

            /// <summary>
            /// Lapalace smooth term in categorical feature spilt. Avoid the bias of small categories.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatSmooth", new object[]{1, 10, 20})]
            public double CatSmooth { get; set; } = 10d;

            /// <summary>
            /// L2 Regularization for categorical split.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatL2", new object[]{0.1f, 0.5f, 1, 5, 10})]
            public double CatL2 { get; set; } = 10d;

            /// <summary>
            /// Parallel LightGBM Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelLightGBM ParallelTrainer { get; set; } = new SingleParallelLightGBM();

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRankingOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LightGbmRanker)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LightGbmRankerPipelineStep(output);
            }

            private class LightGbmRankerPipelineStep : ILearningPipelinePredictorStep
            {
                public LightGbmRankerPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/member[@name="LightGBM"]/*' />
        /// <include file='../Microsoft.ML.LightGBM/doc.xml' path='doc/members/example[@name="LightGbmRegressor"]/*' />
        public sealed partial class LightGbmRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of iterations.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumBoostRound", new object[]{10, 20, 50, 100, 150, 200})]
            public int NumBoostRound { get; set; } = 100;

            /// <summary>
            /// Shrinkage rate for trees, used to prevent over-fitting. Range: (0,1].
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRate", 0.025f, 0.4f, isLogScale:true)]
            public double? LearningRate { get; set; }

            /// <summary>
            /// Maximum leaves for trees.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int? NumLeaves { get; set; }

            /// <summary>
            /// Minimum number of instances needed in a child.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerLeaf", new object[]{1, 10, 20, 50})]
            public int? MinDataPerLeaf { get; set; }

            /// <summary>
            /// Max number of bucket bin for features.
            /// </summary>
            public int MaxBin { get; set; } = 255;

            /// <summary>
            /// Which booster to use, can be gbtree, gblinear or dart. gbtree and dart use tree based model while gblinear uses linear function.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public BoosterParameterFunction Booster { get; set; } = new GbdtBoosterParameterFunction();

            /// <summary>
            /// Verbose
            /// </summary>
            public bool VerboseEval { get; set; } = false;

            /// <summary>
            /// Printing running messages.
            /// </summary>
            public bool Silent { get; set; } = true;

            /// <summary>
            /// Number of parallel threads used to run LightGBM.
            /// </summary>
            public int? NThread { get; set; }

            /// <summary>
            /// Evaluation metrics.
            /// </summary>
            public LightGbmArgumentsEvalMetricType EvalMetric { get; set; } = LightGbmArgumentsEvalMetricType.DefaultMetric;

            /// <summary>
            /// Use softmax loss for the multi classification.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseSoftmax", new object[]{true, false})]
            public bool? UseSoftmax { get; set; }

            /// <summary>
            /// Rounds of early stopping, 0 will disable it.
            /// </summary>
            public int EarlyStoppingRound { get; set; }

            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31,63,127,255,511,1023,2047,4095";

            /// <summary>
            /// Parameter for the sigmoid function. Used only in LightGbmBinaryTrainer, LightGbmMulticlassTrainer and in LightGbmRankingTrainer.
            /// </summary>
            public double Sigmoid { get; set; } = 0.5d;

            /// <summary>
            /// Number of entries in a batch when loading data.
            /// </summary>
            public int BatchSize { get; set; } = 1048576;

            /// <summary>
            /// Enable categorical split or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseCat", new object[]{true, false})]
            public bool? UseCat { get; set; }

            /// <summary>
            /// Enable missing value auto infer or not.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UseMissing", new object[]{true, false})]
            public bool UseMissing { get; set; } = false;

            /// <summary>
            /// Min number of instances per categorical group.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MinDataPerGroup", new object[]{10, 50, 100, 200})]
            public int MinDataPerGroup { get; set; } = 100;

            /// <summary>
            /// Max number of categorical thresholds.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            [TlcModule.SweepableDiscreteParamAttribute("MaxCatThreshold", new object[]{8, 16, 32, 64})]
            public int MaxCatThreshold { get; set; } = 32;

            /// <summary>
            /// Lapalace smooth term in categorical feature spilt. Avoid the bias of small categories.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatSmooth", new object[]{1, 10, 20})]
            public double CatSmooth { get; set; } = 10d;

            /// <summary>
            /// L2 Regularization for categorical split.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("CatL2", new object[]{0.1f, 0.5f, 1, 5, 10})]
            public double CatL2 { get; set; } = 10d;

            /// <summary>
            /// Parallel LightGBM Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelLightGBM ParallelTrainer { get; set; } = new SingleParallelLightGBM();

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LightGbmRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LightGbmRegressorPipelineStep(output);
            }

            private class LightGbmRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public LightGbmRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Train a linear SVM.
        /// </summary>
        public sealed partial class LinearSvmBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Regularizer constant
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Lambda", 1E-05f, 0.1f, stepSize:10, isLogScale:true)]
            public float Lambda { get; set; } = 0.001f;

            /// <summary>
            /// Batch size
            /// </summary>
            public int BatchSize { get; set; } = 1;

            /// <summary>
            /// Perform projection to unit-ball? Typically used with batch size > 1.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("PerformProjection", new object[]{false, true})]
            public bool PerformProjection { get; set; } = false;

            /// <summary>
            /// No bias
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NoBias", new object[]{false, true})]
            public bool NoBias { get; set; } = false;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumIterations", 1, 100, stepSize:10, isLogScale:true)]
            public int NumIterations { get; set; } = 1;

            /// <summary>
            /// Initial Weights and bias, comma-separated
            /// </summary>
            public string InitialWeights { get; set; }

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Size of cache when trained in Scope
            /// </summary>
            public int StreamingCacheSize { get; set; } = 1000000;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LinearSvmBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LinearSvmBinaryClassifierPipelineStep(output);
            }

            private class LinearSvmBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public LinearSvmBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/LogisticRegression/doc.xml' path='doc/members/member[@name="LBFGS"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/LogisticRegression/doc.xml' path='doc/members/example[@name="LogisticRegressionBinaryClassifier"]/*' />
        public sealed partial class LogisticRegressionBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Show statistics of training examples.
            /// </summary>
            public bool ShowTrainingStats { get; set; } = false;

            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2Weight", 0f, 1f, numSteps:4)]
            public float L2Weight { get; set; } = 1f;

            /// <summary>
            /// L1 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L1Weight", 0f, 1f, numSteps:4)]
            public float L1Weight { get; set; } = 1f;

            /// <summary>
            /// Tolerance parameter for optimization convergence. Lower = slower, more accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("OptTol", new object[]{0.0001f, 1E-07f})]
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Memory size for L-BFGS. Lower=faster, less accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MemorySize", new object[]{5, 20, 50})]
            public int MemorySize { get; set; } = 20;

            /// <summary>
            /// Maximum iterations.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("MaxIterations", 1, 2147483647)]
            public int MaxIterations { get; set; } = 2147483647;

            /// <summary>
            /// Run SGD to initialize LR weights, converging to this tolerance
            /// </summary>
            public float SgdInitializationTolerance { get; set; }

            /// <summary>
            /// If set to true, produce no output during training.
            /// </summary>
            public bool Quiet { get; set; } = false;

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether or not to use threads. Default is true
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// Number of threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Force densification of the internal optimization vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DenseOptimizer", new object[]{false, true})]
            public bool DenseOptimizer { get; set; } = false;

            /// <summary>
            /// Enforce non-negative weights
            /// </summary>
            public bool EnforceNonNegativity { get; set; } = false;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LogisticRegressionBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LogisticRegressionBinaryClassifierPipelineStep(output);
            }

            private class LogisticRegressionBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public LogisticRegressionBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/LogisticRegression/doc.xml' path='doc/members/member[@name="LBFGS"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/LogisticRegression/doc.xml' path='doc/members/example[@name="LogisticRegressionClassifier"]/*' />
        public sealed partial class LogisticRegressionClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Show statistics of training examples.
            /// </summary>
            public bool ShowTrainingStats { get; set; } = false;

            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2Weight", 0f, 1f, numSteps:4)]
            public float L2Weight { get; set; } = 1f;

            /// <summary>
            /// L1 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L1Weight", 0f, 1f, numSteps:4)]
            public float L1Weight { get; set; } = 1f;

            /// <summary>
            /// Tolerance parameter for optimization convergence. Lower = slower, more accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("OptTol", new object[]{0.0001f, 1E-07f})]
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Memory size for L-BFGS. Lower=faster, less accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MemorySize", new object[]{5, 20, 50})]
            public int MemorySize { get; set; } = 20;

            /// <summary>
            /// Maximum iterations.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("MaxIterations", 1, 2147483647)]
            public int MaxIterations { get; set; } = 2147483647;

            /// <summary>
            /// Run SGD to initialize LR weights, converging to this tolerance
            /// </summary>
            public float SgdInitializationTolerance { get; set; }

            /// <summary>
            /// If set to true, produce no output during training.
            /// </summary>
            public bool Quiet { get; set; } = false;

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether or not to use threads. Default is true
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// Number of threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Force densification of the internal optimization vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DenseOptimizer", new object[]{false, true})]
            public bool DenseOptimizer { get; set; } = false;

            /// <summary>
            /// Enforce non-negative weights
            /// </summary>
            public bool EnforceNonNegativity { get; set; } = false;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LogisticRegressionClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LogisticRegressionClassifierPipelineStep(output);
            }

            private class LogisticRegressionClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public LogisticRegressionClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/MultiClass/doc.xml' path='doc/members/member[@name="MultiClassNaiveBayesTrainer"]/*'/>
        /// <include file='../Microsoft.ML.StandardLearners/Standard/MultiClass/doc.xml' path='doc/members/example[@name="MultiClassNaiveBayesTrainer"]/*'/>
        public sealed partial class NaiveBayesClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(NaiveBayesClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new NaiveBayesClassifierPipelineStep(output);
            }

            private class NaiveBayesClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public NaiveBayesClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/Online/doc.xml' path='doc/members/member[@name="OGD"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/Online/doc.xml' path='doc/members/example[@name="OGD"]/*' />
        public sealed partial class OnlineGradientDescentRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("LearningRate", new object[]{0.01f, 0.1f, 0.5f, 1f})]
            public float LearningRate { get; set; } = 0.1f;

            /// <summary>
            /// Decrease learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DecreaseLearningRate", new object[]{false, true})]
            public bool DecreaseLearningRate { get; set; } = true;

            /// <summary>
            /// Number of examples after which weights will be reset to the current average
            /// </summary>
            public long? ResetWeightsAfterXExamples { get; set; }

            /// <summary>
            /// Instead of updating averaged weights on every example, only update when loss is nonzero
            /// </summary>
            public bool DoLazyUpdates { get; set; } = true;

            /// <summary>
            /// L2 Regularization Weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2RegularizerWeight", 0f, 0.4f)]
            public float L2RegularizerWeight { get; set; }

            /// <summary>
            /// Extra weight given to more recent updates
            /// </summary>
            public float RecencyGain { get; set; }

            /// <summary>
            /// Whether Recency Gain is multiplicative (vs. additive)
            /// </summary>
            public bool RecencyGainMulti { get; set; } = false;

            /// <summary>
            /// Do averaging?
            /// </summary>
            public bool Averaged { get; set; } = true;

            /// <summary>
            /// The inexactness tolerance for averaging
            /// </summary>
            public float AveragedTolerance { get; set; } = 0.01f;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumIterations", 1, 100, stepSize:10, isLogScale:true)]
            public int NumIterations { get; set; } = 1;

            /// <summary>
            /// Initial Weights and bias, comma-separated
            /// </summary>
            public string InitialWeights { get; set; }

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Size of cache when trained in Scope
            /// </summary>
            public int StreamingCacheSize { get; set; } = 1000000;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(OnlineGradientDescentRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new OnlineGradientDescentRegressorPipelineStep(output);
            }

            private class OnlineGradientDescentRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public OnlineGradientDescentRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.HalLearners/doc.xml' path='doc/members/member[@name="OLS"]/*' />
        public sealed partial class OrdinaryLeastSquaresRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Weight", new object[]{1E-06f, 0.1f, 1f})]
            public float L2Weight { get; set; } = 1E-06f;

            /// <summary>
            /// Whether to calculate per parameter significance statistics
            /// </summary>
            public bool PerParameterSignificance { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(OrdinaryLeastSquaresRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new OrdinaryLeastSquaresRegressorPipelineStep(output);
            }

            private class OrdinaryLeastSquaresRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public OrdinaryLeastSquaresRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.PCA/doc.xml' path='doc/members/member[@name="PCA"]/*' />
        /// <include file='../Microsoft.ML.PCA/doc.xml' path='doc/members/example[@name="PcaAnomalyDetector"]/*' />
        public sealed partial class PcaAnomalyDetector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IUnsupervisedTrainerWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The number of components in the PCA
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Rank", new object[]{10, 20, 40, 80})]
            public int Rank { get; set; } = 20;

            /// <summary>
            /// Oversampling parameter for randomized PCA training
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Oversampling", new object[]{10, 20, 40})]
            public int Oversampling { get; set; } = 20;

            /// <summary>
            /// If enabled, data is centered to be zero mean
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Center", new object[]{false, true})]
            public bool Center { get; set; } = true;

            /// <summary>
            /// The seed for random number generation
            /// </summary>
            public int? Seed { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IAnomalyDetectionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PcaAnomalyDetector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PcaAnomalyDetectorPipelineStep(output);
            }

            private class PcaAnomalyDetectorPipelineStep : ILearningPipelinePredictorStep
            {
                public PcaAnomalyDetectorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/PoissonRegression/doc.xml' path='doc/members/member[@name="PoissonRegression"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/PoissonRegression/doc.xml' path='doc/members/example[@name="PoissonRegression"]/*' />
        public sealed partial class PoissonRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2Weight", 0f, 1f, numSteps:4)]
            public float L2Weight { get; set; } = 1f;

            /// <summary>
            /// L1 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L1Weight", 0f, 1f, numSteps:4)]
            public float L1Weight { get; set; } = 1f;

            /// <summary>
            /// Tolerance parameter for optimization convergence. Lower = slower, more accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("OptTol", new object[]{0.0001f, 1E-07f})]
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Memory size for L-BFGS. Lower=faster, less accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MemorySize", new object[]{5, 20, 50})]
            public int MemorySize { get; set; } = 20;

            /// <summary>
            /// Maximum iterations.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("MaxIterations", 1, 2147483647)]
            public int MaxIterations { get; set; } = 2147483647;

            /// <summary>
            /// Run SGD to initialize LR weights, converging to this tolerance
            /// </summary>
            public float SgdInitializationTolerance { get; set; }

            /// <summary>
            /// If set to true, produce no output during training.
            /// </summary>
            public bool Quiet { get; set; } = false;

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether or not to use threads. Default is true
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// Number of threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Force densification of the internal optimization vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DenseOptimizer", new object[]{false, true})]
            public bool DenseOptimizer { get; set; } = false;

            /// <summary>
            /// Enforce non-negative weights
            /// </summary>
            public bool EnforceNonNegativity { get; set; } = false;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PoissonRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PoissonRegressorPipelineStep(output);
            }

            private class PoissonRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public PoissonRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/doc.xml' path='doc/members/member[@name="SDCA"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/doc.xml' path='doc/members/example[@name="StochasticDualCoordinateAscentBinaryClassifier"]/*'/>
        public sealed partial class StochasticDualCoordinateAscentBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SDCAClassificationLossFunction LossFunction { get; set; } = new LogLossSDCAClassificationLossFunction();

            /// <summary>
            /// Apply weight to the positive class, for imbalanced data
            /// </summary>
            public float PositiveInstanceWeight { get; set; } = 1f;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// L2 regularizer constant. By default the l2 constant is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{"<Auto>", 1E-07f, 1E-06f, 1E-05f, 0.0001f, 0.001f, 0.01f})]
            public float? L2Const { get; set; }

            /// <summary>
            /// L1 soft threshold (L1/L2). Note that it is easier to control and sweep using the threshold parameter than the raw L1-regularizer constant. By default the l1 threshold is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L1Threshold", new object[]{"<Auto>", 0f, 0.25f, 0.5f, 0.75f, 1f})]
            public float? L1Threshold { get; set; }

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The tolerance for the ratio between duality gap and primal loss for convergence checking.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.001f, 0.01f, 0.1f, 0.2f})]
            public float ConvergenceTolerance { get; set; } = 0.1f;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning. Defaults to automatic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{"<Auto>", 10, 20, 100})]
            public int? MaxIterations { get; set; }

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Set as negative or zero for not checking at all. If left blank, it defaults to check after every 'numThreads' iterations.
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The learning rate for adjusting bias from being regularized.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("BiasLearningRate", new object[]{0f, 0.01f, 0.1f, 1f})]
            public float BiasLearningRate { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(StochasticDualCoordinateAscentBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new StochasticDualCoordinateAscentBinaryClassifierPipelineStep(output);
            }

            private class StochasticDualCoordinateAscentBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticDualCoordinateAscentBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/doc.xml' path='doc/members/member[@name="SDCA"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/doc.xml' path='doc/members/example[@name="StochasticDualCoordinateAscentClassifier"]/*' />
        public sealed partial class StochasticDualCoordinateAscentClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SDCAClassificationLossFunction LossFunction { get; set; } = new LogLossSDCAClassificationLossFunction();

            /// <summary>
            /// L2 regularizer constant. By default the l2 constant is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{"<Auto>", 1E-07f, 1E-06f, 1E-05f, 0.0001f, 0.001f, 0.01f})]
            public float? L2Const { get; set; }

            /// <summary>
            /// L1 soft threshold (L1/L2). Note that it is easier to control and sweep using the threshold parameter than the raw L1-regularizer constant. By default the l1 threshold is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L1Threshold", new object[]{"<Auto>", 0f, 0.25f, 0.5f, 0.75f, 1f})]
            public float? L1Threshold { get; set; }

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The tolerance for the ratio between duality gap and primal loss for convergence checking.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.001f, 0.01f, 0.1f, 0.2f})]
            public float ConvergenceTolerance { get; set; } = 0.1f;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning. Defaults to automatic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{"<Auto>", 10, 20, 100})]
            public int? MaxIterations { get; set; }

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Set as negative or zero for not checking at all. If left blank, it defaults to check after every 'numThreads' iterations.
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The learning rate for adjusting bias from being regularized.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("BiasLearningRate", new object[]{0f, 0.01f, 0.1f, 1f})]
            public float BiasLearningRate { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(StochasticDualCoordinateAscentClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new StochasticDualCoordinateAscentClassifierPipelineStep(output);
            }

            private class StochasticDualCoordinateAscentClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticDualCoordinateAscentClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.StandardLearners/Standard/doc.xml' path='doc/members/member[@name="SDCA"]/*' />
        /// <include file='../Microsoft.ML.StandardLearners/Standard/doc.xml' path='doc/members/example[@name="StochasticDualCoordinateAscentRegressor"]/*' />
        public sealed partial class StochasticDualCoordinateAscentRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SDCARegressionLossFunction LossFunction { get; set; } = new SquaredLossSDCARegressionLossFunction();

            /// <summary>
            /// L2 regularizer constant. By default the l2 constant is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{"<Auto>", 1E-07f, 1E-06f, 1E-05f, 0.0001f, 0.001f, 0.01f})]
            public float? L2Const { get; set; }

            /// <summary>
            /// L1 soft threshold (L1/L2). Note that it is easier to control and sweep using the threshold parameter than the raw L1-regularizer constant. By default the l1 threshold is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L1Threshold", new object[]{"<Auto>", 0f, 0.25f, 0.5f, 0.75f, 1f})]
            public float? L1Threshold { get; set; }

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The tolerance for the ratio between duality gap and primal loss for convergence checking.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.001f, 0.01f, 0.1f, 0.2f})]
            public float ConvergenceTolerance { get; set; } = 0.01f;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning. Defaults to automatic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{"<Auto>", 10, 20, 100})]
            public int? MaxIterations { get; set; }

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Set as negative or zero for not checking at all. If left blank, it defaults to check after every 'numThreads' iterations.
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The learning rate for adjusting bias from being regularized.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("BiasLearningRate", new object[]{0f, 0.01f, 0.1f, 1f})]
            public float BiasLearningRate { get; set; } = 1f;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(StochasticDualCoordinateAscentRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new StochasticDualCoordinateAscentRegressorPipelineStep(output);
            }

            private class StochasticDualCoordinateAscentRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticDualCoordinateAscentRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <summary>
        /// Train an Hogwild SGD binary model.
        /// </summary>
        public sealed partial class StochasticGradientDescentBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ClassificationLossFunction LossFunction { get; set; } = new LogLossClassificationLossFunction();

            /// <summary>
            /// L2 Regularization constant
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{1E-07f, 5E-07f, 1E-06f, 5E-06f, 1E-05f})]
            public float L2Weight { get; set; } = 1E-06f;

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic depending on data sparseness. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Exponential moving averaged improvement tolerance for convergence
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.01f, 0.001f, 0.0001f, 1E-05f})]
            public double ConvergenceTolerance { get; set; } = 0.0001d;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{1, 5, 10, 20})]
            public int MaxIterations { get; set; } = 20;

            /// <summary>
            /// Initial learning rate (only used by SGD)
            /// </summary>
            public double InitLearningRate { get; set; } = 0.01d;

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Apply weight to the positive class, for imbalanced data
            /// </summary>
            public float PositiveInstanceWeight { get; set; } = 1f;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Default equals number of threads
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(StochasticGradientDescentBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new StochasticGradientDescentBinaryClassifierPipelineStep(output);
            }

            private class StochasticGradientDescentBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticGradientDescentBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Trainers
    {

        /// <include file='../Microsoft.ML.HalLearners/doc.xml' path='doc/members/member[@name="SymSGD"]/*' />
        public sealed partial class SymSgdBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Degree of lock-free parallelism. Determinism not guaranteed. Multi-threading is not supported currently.
            /// </summary>
            public int? NumberOfThreads { get; set; }

            /// <summary>
            /// Number of passes over the data.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumberOfIterations", new object[]{1, 5, 10, 20, 30, 40, 50})]
            public int NumberOfIterations { get; set; } = 50;

            /// <summary>
            /// Tolerance for difference in average loss in consecutive passes.
            /// </summary>
            public float Tolerance { get; set; } = 0.0001f;

            /// <summary>
            /// Learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("LearningRate", new object[]{"<Auto>", 10f, 1f, 0.1f, 0.01f, 0.001f})]
            public float? LearningRate { get; set; }

            /// <summary>
            /// L2 regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Regularization", new object[]{0f, 1E-05f, 1E-05f, 1E-06f, 1E-07f})]
            public float L2Regularization { get; set; }

            /// <summary>
            /// The number of iterations each thread learns a local model until combining it with the global model. Low value means more updated global model and high value means less cache traffic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("UpdateFrequency", new object[]{"<Auto>", 5, 20})]
            public int? UpdateFrequency { get; set; }

            /// <summary>
            /// The acceleration memory budget in MB
            /// </summary>
            public long MemorySize { get; set; } = 1024;

            /// <summary>
            /// Shuffle data?
            /// </summary>
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Apply weight to the positive class, for imbalanced data
            /// </summary>
            public float PositiveInstanceWeight { get; set; } = 1f;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public Var<IDataView> GetInputData() => TrainingData;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(SymSgdBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    TrainingData = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new SymSgdBinaryClassifierPipelineStep(output);
            }

            private class SymSgdBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public SymSgdBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Approximate bootstrap sampling.
        /// </summary>
        public sealed partial class ApproximateBootstrapSampler : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Whether this is the out-of-bag sample, that is, all those rows that are not selected by the transform.
            /// </summary>
            public bool Complement { get; set; } = false;

            /// <summary>
            /// The random seed. If unspecified random state will be instead derived from the environment.
            /// </summary>
            public uint? Seed { get; set; }

            /// <summary>
            /// Whether we should attempt to shuffle the source data. By default on, but can be turned off for efficiency.
            /// </summary>
            public bool ShuffleInput { get; set; } = true;

            /// <summary>
            /// When shuffling the output, the number of output rows to keep in that pool. Note that shuffling of output is completely distinct from shuffling of input.
            /// </summary>
            public int PoolSize { get; set; } = 1000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ApproximateBootstrapSampler)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ApproximateBootstrapSamplerPipelineStep(output);
            }

            private class ApproximateBootstrapSamplerPipelineStep : ILearningPipelineDataStep
            {
                public ApproximateBootstrapSamplerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// For binary prediction, it renames the PredictedLabel and Score columns to include the name of the positive class.
        /// </summary>
        public sealed partial class BinaryPredictionScoreColumnsRenamer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor model used in scoring
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(BinaryPredictionScoreColumnsRenamer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new BinaryPredictionScoreColumnsRenamerPipelineStep(output);
            }

            private class BinaryPredictionScoreColumnsRenamerPipelineStep : ILearningPipelineDataStep
            {
                public BinaryPredictionScoreColumnsRenamerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class NormalizeTransformBinColumn : OneToOneColumn<NormalizeTransformBinColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Max number of bins, power of 2 recommended
            /// </summary>
            public int? NumBins { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool? FixZero { get; set; }

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long? MaxTrainingExamples { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// The values are assigned into equidensity bins and a value is mapped to its bin_number/number_of_bins.
        /// </summary>
        public sealed partial class BinNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public BinNormalizer()
            {
            }
            
            public BinNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public BinNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformBinColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformBinColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformBinColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformBinColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformBinColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformBinColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NormalizeTransformBinColumn[] Column { get; set; }

            /// <summary>
            /// Max number of bins, power of 2 recommended
            /// </summary>
            public int NumBins { get; set; } = 1024;

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(BinNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new BinNormalizerPipelineStep(output);
            }

            private class BinNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public BinNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum CategoricalTransformOutputKind : byte
        {
            Bag = 1,
            Ind = 2,
            Key = 3,
            Bin = 4
        }


        public sealed partial class CategoricalHashTransformColumn : OneToOneColumn<CategoricalHashTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The number of bits to hash into. Must be between 1 and 30, inclusive.
            /// </summary>
            public int? HashBits { get; set; }

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint? Seed { get; set; }

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool? Ordered { get; set; }

            /// <summary>
            /// Limit the number of keys used to generate the slot name to this many. 0 means no invert hashing, -1 means no limit.
            /// </summary>
            public int? InvertHash { get; set; }

            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), or Key (index)
            /// </summary>
            public CategoricalTransformOutputKind? OutputKind { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="CategoricalHashOneHotVectorizer"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="CategoricalHashOneHotVectorizer"]/*' />
        public sealed partial class CategoricalHashOneHotVectorizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public CategoricalHashOneHotVectorizer()
            {
            }
            
            public CategoricalHashOneHotVectorizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public CategoricalHashOneHotVectorizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CategoricalHashTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CategoricalHashTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CategoricalHashTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CategoricalHashTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CategoricalHashTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CategoricalHashTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:hashBits:src)
            /// </summary>
            public CategoricalHashTransformColumn[] Column { get; set; }

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 30, inclusive.
            /// </summary>
            public int HashBits { get; set; } = 16;

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint Seed { get; set; } = 314489979;

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool Ordered { get; set; } = true;

            /// <summary>
            /// Limit the number of keys used to generate the slot name to this many. 0 means no invert hashing, -1 means no limit.
            /// </summary>
            public int InvertHash { get; set; }

            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), or Key (index)
            /// </summary>
            public CategoricalTransformOutputKind OutputKind { get; set; } = CategoricalTransformOutputKind.Bag;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(CategoricalHashOneHotVectorizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new CategoricalHashOneHotVectorizerPipelineStep(output);
            }

            private class CategoricalHashOneHotVectorizerPipelineStep : ILearningPipelineDataStep
            {
                public CategoricalHashOneHotVectorizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum TermTransformSortOrder : byte
        {
            Occurrence = 0,
            Value = 1
        }


        public sealed partial class CategoricalTransformColumn : OneToOneColumn<CategoricalTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), Key (index), or Binary encoded indicator vector
            /// </summary>
            public CategoricalTransformOutputKind? OutputKind { get; set; }

            /// <summary>
            /// Maximum number of terms to keep when auto-training
            /// </summary>
            public int? MaxNumTerms { get; set; }

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, for example, text sorting will be case sensitive (for example, 'A' then 'Z' then 'a').
            /// </summary>
            public TermTransformSortOrder? Sort { get; set; }

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool? TextKeyValues { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="CategoricalOneHotVectorizer"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="CategoricalOneHotVectorizer"]/*' />
        public sealed partial class CategoricalOneHotVectorizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public CategoricalOneHotVectorizer()
            {
            }
            
            public CategoricalOneHotVectorizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public CategoricalOneHotVectorizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CategoricalTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CategoricalTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CategoricalTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CategoricalTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CategoricalTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CategoricalTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public CategoricalTransformColumn[] Column { get; set; }

            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), or Key (index)
            /// </summary>
            public CategoricalTransformOutputKind OutputKind { get; set; } = CategoricalTransformOutputKind.Ind;

            /// <summary>
            /// Maximum number of terms to keep per column when auto-training
            /// </summary>
            public int MaxNumTerms { get; set; } = 1000000;

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, for example, text sorting will be case sensitive (for example, 'A' then 'Z' then 'a').
            /// </summary>
            public TermTransformSortOrder Sort { get; set; } = TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool TextKeyValues { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(CategoricalOneHotVectorizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new CategoricalOneHotVectorizerPipelineStep(output);
            }

            private class CategoricalOneHotVectorizerPipelineStep : ILearningPipelineDataStep
            {
                public CategoricalOneHotVectorizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class CharTokenizeTransformColumn : OneToOneColumn<CharTokenizeTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="CharacterTokenizer"]/*' />
        public sealed partial class CharacterTokenizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public CharacterTokenizer()
            {
            }
            
            public CharacterTokenizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public CharacterTokenizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CharTokenizeTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CharTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CharTokenizeTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CharTokenizeTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CharTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CharTokenizeTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public CharTokenizeTransformColumn[] Column { get; set; }

            /// <summary>
            /// Whether to mark the beginning/end of each row/slot with start of text character (0x02)/end of text character (0x03)
            /// </summary>
            public bool UseMarkerChars { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(CharacterTokenizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new CharacterTokenizerPipelineStep(output);
            }

            private class CharacterTokenizerPipelineStep : ILearningPipelineDataStep
            {
                public CharacterTokenizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class ConcatTransformColumn : ManyToOneColumn<ConcatTransformColumn>, IManyToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string[] Source { get; set; }

        }

        /// <summary>
        /// Concatenates one or more columns of the same item type.
        /// </summary>
        public sealed partial class ColumnConcatenator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ColumnConcatenator()
            {
            }
            
            public ColumnConcatenator(string outputColumn, params string[] inputColumns)
            {
                AddColumn(outputColumn, inputColumns);
            }
            
            public void AddColumn(string name, params string[] source)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ConcatTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ConcatTransformColumn>(Column);
                list.Add(ManyToOneColumn<Microsoft.ML.Legacy.Transforms.ConcatTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:srcs)
            /// </summary>
            public ConcatTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ColumnConcatenator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ColumnConcatenatorPipelineStep(output);
            }

            private class ColumnConcatenatorPipelineStep : ILearningPipelineDataStep
            {
                public ColumnConcatenatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class CopyColumnsTransformColumn : OneToOneColumn<CopyColumnsTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Duplicates columns from the dataset
        /// </summary>
        public sealed partial class ColumnCopier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ColumnCopier()
            {
            }
            
            public ColumnCopier(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ColumnCopier(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CopyColumnsTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CopyColumnsTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CopyColumnsTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.CopyColumnsTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.CopyColumnsTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.CopyColumnsTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public CopyColumnsTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ColumnCopier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ColumnCopierPipelineStep(output);
            }

            private class ColumnCopierPipelineStep : ILearningPipelineDataStep
            {
                public ColumnCopierPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Selects a set of columns, dropping all others
        /// </summary>
        public sealed partial class ColumnSelector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// List of columns to keep.
            /// </summary>
            public string[] KeepColumns { get; set; }

            /// <summary>
            /// List of columns to drop.
            /// </summary>
            public string[] DropColumns { get; set; }

            /// <summary>
            /// Specifies whether to keep or remove hidden columns.
            /// </summary>
            public bool KeepHidden { get; set; } = true;

            /// <summary>
            /// Specifies whether to ignore columns that are missing from the input.
            /// </summary>
            public bool IgnoreMissing { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ColumnSelector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ColumnSelectorPipelineStep(output);
            }

            private class ColumnSelectorPipelineStep : ILearningPipelineDataStep
            {
                public ColumnSelectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class ConvertTransformColumn : OneToOneColumn<ConvertTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The result type
            /// </summary>
            public Microsoft.ML.Legacy.Data.DataKind? ResultType { get; set; }

            /// <summary>
            /// For a key column, this defines the range of values
            /// </summary>
            public string Range { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Converts a column to a different type, using standard conversions.
        /// </summary>
        public sealed partial class ColumnTypeConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ColumnTypeConverter()
            {
            }
            
            public ColumnTypeConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ColumnTypeConverter(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ConvertTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ConvertTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ConvertTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ConvertTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ConvertTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ConvertTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:type:src)
            /// </summary>
            public ConvertTransformColumn[] Column { get; set; }

            /// <summary>
            /// The result type
            /// </summary>
            public Microsoft.ML.Legacy.Data.DataKind? ResultType { get; set; }

            /// <summary>
            /// For a key column, this defines the range of values
            /// </summary>
            public string Range { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ColumnTypeConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ColumnTypeConverterPipelineStep(output);
            }

            private class ColumnTypeConverterPipelineStep : ILearningPipelineDataStep
            {
                public ColumnTypeConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="Group"]/*' />
        public sealed partial class CombinerByContiguousGroupId : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to group by
            /// </summary>
            public string[] GroupKey { get; set; }

            /// <summary>
            /// Columns to group together
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(CombinerByContiguousGroupId)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new CombinerByContiguousGroupIdPipelineStep(output);
            }

            private class CombinerByContiguousGroupIdPipelineStep : ILearningPipelineDataStep
            {
                public CombinerByContiguousGroupIdPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class NormalizeTransformAffineColumn : OneToOneColumn<NormalizeTransformAffineColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool? FixZero { get; set; }

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long? MaxTrainingExamples { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Normalize the columns only if needed
        /// </summary>
        public sealed partial class ConditionalNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ConditionalNormalizer()
            {
            }
            
            public ConditionalNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ConditionalNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NormalizeTransformAffineColumn[] Column { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ConditionalNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ConditionalNormalizerPipelineStep(output);
            }

            private class ConditionalNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public ConditionalNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum CacheCachingType
        {
            Memory = 0,
            Disk = 1
        }


        /// <summary>
        /// Caches using the specified cache option.
        /// </summary>
        public sealed partial class DataCache : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Caching strategy
            /// </summary>
            public CacheCachingType Caching { get; set; } = CacheCachingType.Memory;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// Dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(DataCache)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new DataCachePipelineStep(output);
            }

            private class DataCachePipelineStep : ILearningPipelineDataStep
            {
                public DataCachePipelineStep(Output output)
                {
                    Data = output.OutputData;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Score a dataset with a predictor model
        /// </summary>
        public sealed partial class DatasetScorer
        {


            /// <summary>
            /// The dataset to be scored
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The predictor model to apply to data
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Suffix to append to the score columns
            /// </summary>
            public string Suffix { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// The scored dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ScoredData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The scoring transform
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> ScoringTransform { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Score a dataset with a transform model
        /// </summary>
        public sealed partial class DatasetTransformScorer
        {


            /// <summary>
            /// The dataset to be scored
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The transform model to apply to data
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();


            public sealed class Output
            {
                /// <summary>
                /// The scored dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ScoredData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The scoring transform
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> ScoringTransform { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class TermTransformColumn : OneToOneColumn<TermTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Maximum number of terms to keep when auto-training
            /// </summary>
            public int? MaxNumTerms { get; set; }

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, for example, text sorting will be case sensitive (for example, 'A' then 'Z' then 'a').
            /// </summary>
            public TermTransformSortOrder? Sort { get; set; }

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool? TextKeyValues { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Converts input values (words, numbers, etc.) to index in a dictionary.
        /// </summary>
        public sealed partial class Dictionarizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public Dictionarizer()
            {
            }
            
            public Dictionarizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public Dictionarizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.TermTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.TermTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public TermTransformColumn[] Column { get; set; }

            /// <summary>
            /// Maximum number of terms to keep per column when auto-training
            /// </summary>
            public int MaxNumTerms { get; set; } = 1000000;

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, for example, text sorting will be case sensitive (for example, 'A' then 'Z' then 'a').
            /// </summary>
            public TermTransformSortOrder Sort { get; set; } = TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool TextKeyValues { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(Dictionarizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new DictionarizerPipelineStep(output);
            }

            private class DictionarizerPipelineStep : ILearningPipelineDataStep
            {
                public DictionarizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Combines all the features into one feature column.
        /// </summary>
        public sealed partial class FeatureCombiner : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Features
            /// </summary>
            public string[] Features { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FeatureCombiner)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FeatureCombinerPipelineStep(output);
            }

            private class FeatureCombinerPipelineStep : ILearningPipelineDataStep
            {
                public FeatureCombinerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="CountFeatureSelection"]/*'/>
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="CountFeatureSelection"]/*'/>
        public sealed partial class FeatureSelectorByCount : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to use for feature selection
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// If the count of non-default values for a slot is greater than or equal to this threshold, the slot is preserved
            /// </summary>
            public long Count { get; set; } = 1;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FeatureSelectorByCount)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FeatureSelectorByCountPipelineStep(output);
            }

            private class FeatureSelectorByCountPipelineStep : ILearningPipelineDataStep
            {
                public FeatureSelectorByCountPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="MutualInformationFeatureSelection"]/*'/>
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="MutualInformationFeatureSelection"]/*'/>
        public sealed partial class FeatureSelectorByMutualInformation : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to use for feature selection
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The maximum number of slots to preserve in output
            /// </summary>
            public int SlotsInOutput { get; set; } = 1000;

            /// <summary>
            /// Max number of bins for R4/R8 columns, power of 2 recommended
            /// </summary>
            public int NumBins { get; set; } = 256;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(FeatureSelectorByMutualInformation)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new FeatureSelectorByMutualInformationPipelineStep(output);
            }

            private class FeatureSelectorByMutualInformationPipelineStep : ILearningPipelineDataStep
            {
                public FeatureSelectorByMutualInformationPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class LpNormNormalizerTransformGcnColumn : OneToOneColumn<LpNormNormalizerTransformGcnColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Normalize by standard deviation rather than L2 norm
            /// </summary>
            public bool? UseStdDev { get; set; }

            /// <summary>
            /// Scale features by this value
            /// </summary>
            public float? Scale { get; set; }

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool? SubMean { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="GcNormalize"]/*' />
        public sealed partial class GlobalContrastNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public GlobalContrastNormalizer()
            {
            }
            
            public GlobalContrastNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public GlobalContrastNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformGcnColumn>() : new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformGcnColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformGcnColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformGcnColumn>() : new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformGcnColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformGcnColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public LpNormNormalizerTransformGcnColumn[] Column { get; set; }

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool SubMean { get; set; } = true;

            /// <summary>
            /// Normalize by standard deviation rather than L2 norm
            /// </summary>
            public bool UseStdDev { get; set; } = false;

            /// <summary>
            /// Scale features by this value
            /// </summary>
            public float Scale { get; set; } = 1f;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(GlobalContrastNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new GlobalContrastNormalizerPipelineStep(output);
            }

            private class GlobalContrastNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public GlobalContrastNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class HashJoinTransformColumn : OneToOneColumn<HashJoinTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Whether the values need to be combined for a single hash
            /// </summary>
            public bool? Join { get; set; }

            /// <summary>
            /// Which slots should be combined together. Example: 0,3,5;0,1;3;2,1,0. Overrides 'join'.
            /// </summary>
            public string CustomSlotMap { get; set; }

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 31, inclusive.
            /// </summary>
            public int? HashBits { get; set; }

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint? Seed { get; set; }

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool? Ordered { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="HashJoin"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="HashJoin"]/*' />
        public sealed partial class HashConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public HashConverter()
            {
            }
            
            public HashConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public HashConverter(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.HashJoinTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.HashJoinTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.HashJoinTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.HashJoinTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.HashJoinTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.HashJoinTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public HashJoinTransformColumn[] Column { get; set; }

            /// <summary>
            /// Whether the values need to be combined for a single hash
            /// </summary>
            public bool Join { get; set; } = true;

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 31, inclusive.
            /// </summary>
            public int HashBits { get; set; } = 31;

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint Seed { get; set; } = 314489979;

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool Ordered { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(HashConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new HashConverterPipelineStep(output);
            }

            private class HashConverterPipelineStep : ILearningPipelineDataStep
            {
                public HashConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class ImageGrayscaleTransformColumn : OneToOneColumn<ImageGrayscaleTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Convert image into grayscale.
        /// </summary>
        public sealed partial class ImageGrayscale : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ImageGrayscale()
            {
            }
            
            public ImageGrayscale(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ImageGrayscale(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImageGrayscaleTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImageGrayscaleTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImageGrayscaleTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImageGrayscaleTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImageGrayscaleTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImageGrayscaleTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public ImageGrayscaleTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ImageGrayscale)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ImageGrayscalePipelineStep(output);
            }

            private class ImageGrayscalePipelineStep : ILearningPipelineDataStep
            {
                public ImageGrayscalePipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class ImageLoaderTransformColumn : OneToOneColumn<ImageLoaderTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Load images from files.
        /// </summary>
        public sealed partial class ImageLoader : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ImageLoader()
            {
            }
            
            public ImageLoader(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ImageLoader(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImageLoaderTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImageLoaderTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImageLoaderTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImageLoaderTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImageLoaderTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImageLoaderTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public ImageLoaderTransformColumn[] Column { get; set; }

            /// <summary>
            /// Folder where to search for images
            /// </summary>
            public string ImageFolder { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ImageLoader)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ImageLoaderPipelineStep(output);
            }

            private class ImageLoaderPipelineStep : ILearningPipelineDataStep
            {
                public ImageLoaderPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class ImagePixelExtractorTransformColumn : OneToOneColumn<ImagePixelExtractorTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Whether to use alpha channel
            /// </summary>
            public bool? UseAlpha { get; set; }

            /// <summary>
            /// Whether to use red channel
            /// </summary>
            public bool? UseRed { get; set; }

            /// <summary>
            /// Whether to use green channel
            /// </summary>
            public bool? UseGreen { get; set; }

            /// <summary>
            /// Whether to use blue channel
            /// </summary>
            public bool? UseBlue { get; set; }

            /// <summary>
            /// Whether to separate each channel or interleave in ARGB order
            /// </summary>
            public bool? InterleaveArgb { get; set; }

            /// <summary>
            /// Whether to convert to floating point
            /// </summary>
            public bool? Convert { get; set; }

            /// <summary>
            /// Offset (pre-scale)
            /// </summary>
            public float? Offset { get; set; }

            /// <summary>
            /// Scale factor
            /// </summary>
            public float? Scale { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Extract color plane(s) from an image. Options include scaling, offset and conversion to floating point.
        /// </summary>
        public sealed partial class ImagePixelExtractor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ImagePixelExtractor()
            {
            }
            
            public ImagePixelExtractor(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ImagePixelExtractor(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImagePixelExtractorTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImagePixelExtractorTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImagePixelExtractorTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImagePixelExtractorTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImagePixelExtractorTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImagePixelExtractorTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public ImagePixelExtractorTransformColumn[] Column { get; set; }

            /// <summary>
            /// Whether to use alpha channel
            /// </summary>
            public bool UseAlpha { get; set; } = false;

            /// <summary>
            /// Whether to use red channel
            /// </summary>
            public bool UseRed { get; set; } = true;

            /// <summary>
            /// Whether to use green channel
            /// </summary>
            public bool UseGreen { get; set; } = true;

            /// <summary>
            /// Whether to use blue channel
            /// </summary>
            public bool UseBlue { get; set; } = true;

            /// <summary>
            /// Whether to separate each channel or interleave in ARGB order
            /// </summary>
            public bool InterleaveArgb { get; set; } = false;

            /// <summary>
            /// Whether to convert to floating point
            /// </summary>
            public bool Convert { get; set; } = true;

            /// <summary>
            /// Offset (pre-scale)
            /// </summary>
            public float? Offset { get; set; }

            /// <summary>
            /// Scale factor
            /// </summary>
            public float? Scale { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ImagePixelExtractor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ImagePixelExtractorPipelineStep(output);
            }

            private class ImagePixelExtractorPipelineStep : ILearningPipelineDataStep
            {
                public ImagePixelExtractorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum ImageResizerTransformResizingKind : byte
        {
            IsoPad = 0,
            IsoCrop = 1
        }

        public enum ImageResizerTransformAnchor : byte
        {
            Right = 0,
            Left = 1,
            Top = 2,
            Bottom = 3,
            Center = 4
        }


        public sealed partial class ImageResizerTransformColumn : OneToOneColumn<ImageResizerTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Width of the resized image
            /// </summary>
            public int? ImageWidth { get; set; }

            /// <summary>
            /// Height of the resized image
            /// </summary>
            public int? ImageHeight { get; set; }

            /// <summary>
            /// Resizing method
            /// </summary>
            public ImageResizerTransformResizingKind? Resizing { get; set; }

            /// <summary>
            /// Anchor for cropping
            /// </summary>
            public ImageResizerTransformAnchor? CropAnchor { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Scales an image to specified dimensions using one of the three scale types: isotropic with padding, isotropic with cropping or anisotropic. In case of isotropic padding, transparent color is used to pad resulting image.
        /// </summary>
        public sealed partial class ImageResizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public ImageResizer()
            {
            }
            
            public ImageResizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ImageResizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImageResizerTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImageResizerTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImageResizerTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.ImageResizerTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.ImageResizerTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.ImageResizerTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public ImageResizerTransformColumn[] Column { get; set; }

            /// <summary>
            /// Resized width of the image
            /// </summary>
            public int ImageWidth { get; set; }

            /// <summary>
            /// Resized height of the image
            /// </summary>
            public int ImageHeight { get; set; }

            /// <summary>
            /// Resizing method
            /// </summary>
            public ImageResizerTransformResizingKind Resizing { get; set; } = ImageResizerTransformResizingKind.IsoCrop;

            /// <summary>
            /// Anchor for cropping
            /// </summary>
            public ImageResizerTransformAnchor CropAnchor { get; set; } = ImageResizerTransformAnchor.Center;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ImageResizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ImageResizerPipelineStep(output);
            }

            private class ImageResizerPipelineStep : ILearningPipelineDataStep
            {
                public ImageResizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class KeyToValueTransformColumn : OneToOneColumn<KeyToValueTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="KeyToText"]/*' />
        public sealed partial class KeyToTextConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public KeyToTextConverter()
            {
            }
            
            public KeyToTextConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public KeyToTextConverter(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.KeyToValueTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.KeyToValueTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.KeyToValueTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.KeyToValueTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.KeyToValueTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.KeyToValueTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public KeyToValueTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(KeyToTextConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new KeyToTextConverterPipelineStep(output);
            }

            private class KeyToTextConverterPipelineStep : ILearningPipelineDataStep
            {
                public KeyToTextConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Transforms the label to either key or bool (if needed) to make it suitable for classification.
        /// </summary>
        public sealed partial class LabelColumnKeyBooleanConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Convert the key values to text
            /// </summary>
            public bool TextKeyValues { get; set; } = true;

            /// <summary>
            /// The label column
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LabelColumnKeyBooleanConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LabelColumnKeyBooleanConverterPipelineStep(output);
            }

            private class LabelColumnKeyBooleanConverterPipelineStep : ILearningPipelineDataStep
            {
                public LabelColumnKeyBooleanConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class LabelIndicatorTransformColumn : OneToOneColumn<LabelIndicatorTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The positive example class for binary classification.
            /// </summary>
            public int? ClassIndex { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Label remapper used by OVA
        /// </summary>
        public sealed partial class LabelIndicator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public LabelIndicator()
            {
            }
            
            public LabelIndicator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LabelIndicator(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LabelIndicatorTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.LabelIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LabelIndicatorTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LabelIndicatorTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.LabelIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LabelIndicatorTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public LabelIndicatorTransformColumn[] Column { get; set; }

            /// <summary>
            /// Label of the positive class.
            /// </summary>
            public int ClassIndex { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LabelIndicator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LabelIndicatorPipelineStep(output);
            }

            private class LabelIndicatorPipelineStep : ILearningPipelineDataStep
            {
                public LabelIndicatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Transforms the label to float to make it suitable for regression.
        /// </summary>
        public sealed partial class LabelToFloatConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The label column
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LabelToFloatConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LabelToFloatConverterPipelineStep(output);
            }

            private class LabelToFloatConverterPipelineStep : ILearningPipelineDataStep
            {
                public LabelToFloatConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class LdaTransformColumn : OneToOneColumn<LdaTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The number of topics in the LDA
            /// </summary>
            public int? NumTopic { get; set; }

            /// <summary>
            /// Dirichlet prior on document-topic vectors
            /// </summary>
            public float? AlphaSum { get; set; }

            /// <summary>
            /// Dirichlet prior on vocab-topic vectors
            /// </summary>
            public float? Beta { get; set; }

            /// <summary>
            /// Number of Metropolis Hasting step
            /// </summary>
            public int? Mhstep { get; set; }

            /// <summary>
            /// Number of iterations
            /// </summary>
            public int? NumIterations { get; set; }

            /// <summary>
            /// Compute log likelihood over local dataset on this iteration interval
            /// </summary>
            public int? LikelihoodInterval { get; set; }

            /// <summary>
            /// The number of training threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The threshold of maximum count of tokens per doc
            /// </summary>
            public int? NumMaxDocToken { get; set; }

            /// <summary>
            /// The number of words to summarize the topic
            /// </summary>
            public int? NumSummaryTermPerTopic { get; set; }

            /// <summary>
            /// The number of burn-in iterations
            /// </summary>
            public int? NumBurninIterations { get; set; } = 10;

            /// <summary>
            /// Reset the random number generator for each document
            /// </summary>
            public bool? ResetRandomGenerator { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="LightLDA"]/*' />
        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/example[@name="LightLDA"]/*' />
        public sealed partial class LightLda : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public LightLda()
            {
            }
            
            public LightLda(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LightLda(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LdaTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.LdaTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LdaTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LdaTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.LdaTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LdaTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:srcs)
            /// </summary>
            public LdaTransformColumn[] Column { get; set; }

            /// <summary>
            /// The number of topics in the LDA
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTopic", new object[]{20, 40, 100, 200})]
            public int NumTopic { get; set; } = 100;

            /// <summary>
            /// Dirichlet prior on document-topic vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("AlphaSum", new object[]{1, 10, 100, 200})]
            public float AlphaSum { get; set; } = 100f;

            /// <summary>
            /// Dirichlet prior on vocab-topic vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Beta", new object[]{0.01f, 0.015f, 0.07f, 0.02f})]
            public float Beta { get; set; } = 0.01f;

            /// <summary>
            /// Number of Metropolis Hasting step
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Mhstep", new object[]{2, 4, 8, 16})]
            public int Mhstep { get; set; } = 4;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumIterations", new object[]{100, 200, 300, 400})]
            public int NumIterations { get; set; } = 200;

            /// <summary>
            /// Compute log likelihood over local dataset on this iteration interval
            /// </summary>
            public int LikelihoodInterval { get; set; } = 5;

            /// <summary>
            /// The threshold of maximum count of tokens per doc
            /// </summary>
            public int NumMaxDocToken { get; set; } = 512;

            /// <summary>
            /// The number of training threads. Default value depends on number of logical processors.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The number of words to summarize the topic
            /// </summary>
            public int NumSummaryTermPerTopic { get; set; } = 10;

            /// <summary>
            /// The number of burn-in iterations
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumBurninIterations", new object[]{10, 20, 30, 40})]
            public int NumBurninIterations { get; set; } = 10;

            /// <summary>
            /// Reset the random number generator for each document
            /// </summary>
            public bool ResetRandomGenerator { get; set; } = false;

            /// <summary>
            /// Whether to output the topic-word summary in text format
            /// </summary>
            public bool OutputTopicWordSummary { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LightLda)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LightLdaPipelineStep(output);
            }

            private class LightLdaPipelineStep : ILearningPipelineDataStep
            {
                public LightLdaPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class NormalizeTransformLogNormalColumn : OneToOneColumn<NormalizeTransformLogNormalColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long? MaxTrainingExamples { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Normalizes the data based on the computed mean and variance of the logarithm of the data.
        /// </summary>
        public sealed partial class LogMeanVarianceNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public LogMeanVarianceNormalizer()
            {
            }
            
            public LogMeanVarianceNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LogMeanVarianceNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformLogNormalColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformLogNormalColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformLogNormalColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformLogNormalColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformLogNormalColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformLogNormalColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// Whether to use CDF as the output
            /// </summary>
            public bool UseCdf { get; set; } = true;

            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NormalizeTransformLogNormalColumn[] Column { get; set; }

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LogMeanVarianceNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LogMeanVarianceNormalizerPipelineStep(output);
            }

            private class LogMeanVarianceNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public LogMeanVarianceNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum LpNormNormalizerTransformNormalizerKind : byte
        {
            L2Norm = 0,
            StdDev = 1,
            L1Norm = 2,
            LInf = 3
        }


        public sealed partial class LpNormNormalizerTransformColumn : OneToOneColumn<LpNormNormalizerTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The norm to use to normalize each sample
            /// </summary>
            public LpNormNormalizerTransformNormalizerKind? NormKind { get; set; }

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool? SubMean { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="LpNormalize"]/*' />
        public sealed partial class LpNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public LpNormalizer()
            {
            }
            
            public LpNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LpNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.LpNormNormalizerTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public LpNormNormalizerTransformColumn[] Column { get; set; }

            /// <summary>
            /// The norm to use to normalize each sample
            /// </summary>
            public LpNormNormalizerTransformNormalizerKind NormKind { get; set; } = LpNormNormalizerTransformNormalizerKind.L2Norm;

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool SubMean { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(LpNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new LpNormalizerPipelineStep(output);
            }

            private class LpNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public LpNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Combines a sequence of TransformModels and a PredictorModel into a single PredictorModel.
        /// </summary>
        public sealed partial class ManyHeterogeneousModelCombiner
        {


            /// <summary>
            /// Transform model
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModels { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// Predictor model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// Predictor model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Normalizes the data based on the computed mean and variance of the data.
        /// </summary>
        public sealed partial class MeanVarianceNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public MeanVarianceNormalizer()
            {
            }
            
            public MeanVarianceNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MeanVarianceNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// Whether to use CDF as the output
            /// </summary>
            public bool UseCdf { get; set; } = false;

            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NormalizeTransformAffineColumn[] Column { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MeanVarianceNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MeanVarianceNormalizerPipelineStep(output);
            }

            private class MeanVarianceNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public MeanVarianceNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Normalizes the data based on the observed minimum and maximum values of the data.
        /// </summary>
        public sealed partial class MinMaxNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public MinMaxNormalizer()
            {
            }
            
            public MinMaxNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MinMaxNormalizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>() : new List<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NormalizeTransformAffineColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NormalizeTransformAffineColumn[] Column { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MinMaxNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MinMaxNormalizerPipelineStep(output);
            }

            private class MinMaxNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public MinMaxNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum NAHandleTransformReplacementKind : byte
        {
            DefaultValue = 0,
            Mean = 1,
            Minimum = 2,
            Maximum = 3
        }


        public sealed partial class NAHandleTransformColumn : OneToOneColumn<NAHandleTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public NAHandleTransformReplacementKind? Kind { get; set; }

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool? ImputeBySlot { get; set; }

            /// <summary>
            /// Whether or not to concatenate an indicator vector column to the value column
            /// </summary>
            public bool? ConcatIndicator { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Data/Transforms/doc.xml' path='doc/members/member[@name="NAHandle"]/*' />
        /// <include file='../Microsoft.ML.Data/Transforms/doc.xml' path='doc/members/example[@name="NAHandle"]/*' />
        public sealed partial class MissingValueHandler : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public MissingValueHandler()
            {
            }
            
            public MissingValueHandler(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValueHandler(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NAHandleTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NAHandleTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NAHandleTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NAHandleTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NAHandleTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NAHandleTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:rep:src)
            /// </summary>
            public NAHandleTransformColumn[] Column { get; set; }

            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public NAHandleTransformReplacementKind ReplaceWith { get; set; } = NAHandleTransformReplacementKind.DefaultValue;

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool ImputeBySlot { get; set; } = true;

            /// <summary>
            /// Whether or not to concatenate an indicator vector column to the value column
            /// </summary>
            public bool Concat { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MissingValueHandler)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MissingValueHandlerPipelineStep(output);
            }

            private class MissingValueHandlerPipelineStep : ILearningPipelineDataStep
            {
                public MissingValueHandlerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class NAIndicatorTransformColumn : OneToOneColumn<NAIndicatorTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="NAIndicator"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="NAIndicator"]/*' />
        public sealed partial class MissingValueIndicator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public MissingValueIndicator()
            {
            }
            
            public MissingValueIndicator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValueIndicator(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NAIndicatorTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NAIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NAIndicatorTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NAIndicatorTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NAIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NAIndicatorTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NAIndicatorTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MissingValueIndicator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MissingValueIndicatorPipelineStep(output);
            }

            private class MissingValueIndicatorPipelineStep : ILearningPipelineDataStep
            {
                public MissingValueIndicatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class NADropTransformColumn : OneToOneColumn<NADropTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="NADrop"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="NADrop"]/*' />
        public sealed partial class MissingValuesDropper : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public MissingValuesDropper()
            {
            }
            
            public MissingValuesDropper(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValuesDropper(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NADropTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NADropTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NADropTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NADropTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NADropTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NADropTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// Columns to drop the NAs for
            /// </summary>
            public NADropTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MissingValuesDropper)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MissingValuesDropperPipelineStep(output);
            }

            private class MissingValuesDropperPipelineStep : ILearningPipelineDataStep
            {
                public MissingValuesDropperPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Data/Transforms/doc.xml' path='doc/members/member[@name="NAFilter"]/*' />
        /// <include file='../Microsoft.ML.Data/Transforms/doc.xml' path='doc/members/example[@name="NAFilter"]/*' />
        public sealed partial class MissingValuesRowDropper : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Column
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// If true, keep only rows that contain NA values, and filter the rest.
            /// </summary>
            public bool Complement { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MissingValuesRowDropper)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MissingValuesRowDropperPipelineStep(output);
            }

            private class MissingValuesRowDropperPipelineStep : ILearningPipelineDataStep
            {
                public MissingValuesRowDropperPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum NAReplaceTransformReplacementKind : byte
        {
            DefaultValue = 0,
            Mean = 1,
            Minimum = 2,
            Maximum = 3,
            SpecifiedValue = 4
        }


        public sealed partial class NAReplaceTransformColumn : OneToOneColumn<NAReplaceTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Replacement value for NAs (uses default value if not given)
            /// </summary>
            public string ReplacementString { get; set; }

            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public NAReplaceTransformReplacementKind? Kind { get; set; }

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool? Slot { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="NAReplace"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="NAReplace"]/*' />
        public sealed partial class MissingValueSubstitutor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public MissingValueSubstitutor()
            {
            }
            
            public MissingValueSubstitutor(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValueSubstitutor(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NAReplaceTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NAReplaceTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NAReplaceTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NAReplaceTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NAReplaceTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NAReplaceTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:rep:src)
            /// </summary>
            public NAReplaceTransformColumn[] Column { get; set; }

            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public NAReplaceTransformReplacementKind ReplacementKind { get; set; } = NAReplaceTransformReplacementKind.DefaultValue;

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool ImputeBySlot { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(MissingValueSubstitutor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new MissingValueSubstitutorPipelineStep(output);
            }

            private class MissingValueSubstitutorPipelineStep : ILearningPipelineDataStep
            {
                public MissingValueSubstitutorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Combines a sequence of TransformModels into a single model
        /// </summary>
        public sealed partial class ModelCombiner
        {


            /// <summary>
            /// Input models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();


            public sealed class Output
            {
                /// <summary>
                /// Combined model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> OutputModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum NgramTransformWeightingCriteria
        {
            Tf = 0,
            Idf = 1,
            TfIdf = 2
        }


        public sealed partial class NgramTransformColumn : OneToOneColumn<NgramTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Maximum ngram length
            /// </summary>
            public int? NgramLength { get; set; }

            /// <summary>
            /// Whether to include all ngram lengths up to NgramLength or only NgramLength
            /// </summary>
            public bool? AllLengths { get; set; }

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int? SkipLength { get; set; }

            /// <summary>
            /// Maximum number of ngrams to store in the dictionary
            /// </summary>
            public int[] MaxNumTerms { get; set; }

            /// <summary>
            /// Statistical measure used to evaluate how important a word is to a document in a corpus
            /// </summary>
            public NgramTransformWeightingCriteria? Weighting { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="NgramTranslator"]/*' />
        public sealed partial class NGramTranslator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public NGramTranslator()
            {
            }
            
            public NGramTranslator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public NGramTranslator(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NgramTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NgramTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NgramTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.NgramTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.NgramTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.NgramTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public NgramTransformColumn[] Column { get; set; }

            /// <summary>
            /// Maximum ngram length
            /// </summary>
            public int NgramLength { get; set; } = 2;

            /// <summary>
            /// Whether to store all ngram lengths up to ngramLength, or only ngramLength
            /// </summary>
            public bool AllLengths { get; set; } = true;

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int SkipLength { get; set; }

            /// <summary>
            /// Maximum number of ngrams to store in the dictionary
            /// </summary>
            public int[] MaxNumTerms { get; set; } = { 10000000 };

            /// <summary>
            /// The weighting criteria
            /// </summary>
            public NgramTransformWeightingCriteria Weighting { get; set; } = NgramTransformWeightingCriteria.Tf;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(NGramTranslator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new NGramTranslatorPipelineStep(output);
            }

            private class NGramTranslatorPipelineStep : ILearningPipelineDataStep
            {
                public NGramTranslatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Does nothing.
        /// </summary>
        public sealed partial class NoOperation : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(NoOperation)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new NoOperationPipelineStep(output);
            }

            private class NoOperationPipelineStep : ILearningPipelineDataStep
            {
                public NoOperationPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/member[@name="OptionalColumnTransform"]/*' />
        /// <include file='../Microsoft.ML.Transforms/doc.xml' path='doc/members/example[@name="OptionalColumnTransform"]/*' />
        public sealed partial class OptionalColumnCreator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// New column definition(s)
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(OptionalColumnCreator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new OptionalColumnCreatorPipelineStep(output);
            }

            private class OptionalColumnCreatorPipelineStep : ILearningPipelineDataStep
            {
                public OptionalColumnCreatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class PcaTransformColumn : OneToOneColumn<PcaTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The name of the weight column
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// The number of components in the PCA
            /// </summary>
            public int? Rank { get; set; }

            /// <summary>
            /// Oversampling parameter for randomized PCA training
            /// </summary>
            public int? Oversampling { get; set; }

            /// <summary>
            /// If enabled, data is centered to be zero mean
            /// </summary>
            public bool? Center { get; set; }

            /// <summary>
            /// The seed for random number generation
            /// </summary>
            public int? Seed { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.PCA/doc.xml' path='doc/members/member[@name="PCA"]/*' />
        /// <include file='../Microsoft.ML.PCA/doc.xml' path='doc/members/example[@name="PcaCalculator"]/*' />
        public sealed partial class PcaCalculator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public PcaCalculator()
            {
            }
            
            public PcaCalculator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public PcaCalculator(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.PcaTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.PcaTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.PcaTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.PcaTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.PcaTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.PcaTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public PcaTransformColumn[] Column { get; set; }

            /// <summary>
            /// The name of the weight column
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// The number of components in the PCA
            /// </summary>
            public int Rank { get; set; } = 20;

            /// <summary>
            /// Oversampling parameter for randomized PCA training
            /// </summary>
            public int Oversampling { get; set; } = 20;

            /// <summary>
            /// If enabled, data is centered to be zero mean
            /// </summary>
            public bool Center { get; set; } = true;

            /// <summary>
            /// The seed for random number generation
            /// </summary>
            public int Seed { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PcaCalculator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PcaCalculatorPipelineStep(output);
            }

            private class PcaCalculatorPipelineStep : ILearningPipelineDataStep
            {
                public PcaCalculatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Transforms a predicted label column to its original values, unless it is of type bool.
        /// </summary>
        public sealed partial class PredictedLabelColumnOriginalValueConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// The predicted label column
            /// </summary>
            public string PredictedLabelColumn { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(PredictedLabelColumnOriginalValueConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new PredictedLabelColumnOriginalValueConverterPipelineStep(output);
            }

            private class PredictedLabelColumnOriginalValueConverterPipelineStep : ILearningPipelineDataStep
            {
                public PredictedLabelColumnOriginalValueConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class GenerateNumberTransformColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Use an auto-incremented integer starting at zero instead of a random number
            /// </summary>
            public bool? UseCounter { get; set; }

            /// <summary>
            /// The random seed
            /// </summary>
            public uint? Seed { get; set; }

        }

        /// <summary>
        /// Adds a column with a generated number sequence.
        /// </summary>
        public sealed partial class RandomNumberGenerator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// New column definition(s) (optional form: name:seed)
            /// </summary>
            public GenerateNumberTransformColumn[] Column { get; set; }

            /// <summary>
            /// Use an auto-incremented integer starting at zero instead of a random number
            /// </summary>
            public bool UseCounter { get; set; } = false;

            /// <summary>
            /// The random seed
            /// </summary>
            public uint Seed { get; set; } = 42;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(RandomNumberGenerator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new RandomNumberGeneratorPipelineStep(output);
            }

            private class RandomNumberGeneratorPipelineStep : ILearningPipelineDataStep
            {
                public RandomNumberGeneratorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Filters a dataview on a column of type Single, Double or Key (contiguous). Keeps the values that are in the specified min/max range. NaNs are always filtered out. If the input is a Key type, the min/max are considered percentages of the number of values.
        /// </summary>
        public sealed partial class RowRangeFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Column
            /// </summary>
            public string Column { get; set; }

            /// <summary>
            /// Minimum value (0 to 1 for key types)
            /// </summary>
            public double? Min { get; set; }

            /// <summary>
            /// Maximum value (0 to 1 for key types)
            /// </summary>
            public double? Max { get; set; }

            /// <summary>
            /// If true, keep the values that fall outside the range.
            /// </summary>
            public bool Complement { get; set; } = false;

            /// <summary>
            /// If true, include in the range the values that are equal to min.
            /// </summary>
            public bool IncludeMin { get; set; } = true;

            /// <summary>
            /// If true, include in the range the values that are equal to max.
            /// </summary>
            public bool? IncludeMax { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(RowRangeFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new RowRangeFilterPipelineStep(output);
            }

            private class RowRangeFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowRangeFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Allows limiting input to a subset of rows at an optional offset.  Can be used to implement data paging.
        /// </summary>
        public sealed partial class RowSkipAndTakeFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of items to skip
            /// </summary>
            public long? Skip { get; set; }

            /// <summary>
            /// Number of items to take
            /// </summary>
            public long? Take { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(RowSkipAndTakeFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new RowSkipAndTakeFilterPipelineStep(output);
            }

            private class RowSkipAndTakeFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowSkipAndTakeFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Allows limiting input to a subset of rows by skipping a number of rows.
        /// </summary>
        public sealed partial class RowSkipFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of items to skip
            /// </summary>
            public long Count { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(RowSkipFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new RowSkipFilterPipelineStep(output);
            }

            private class RowSkipFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowSkipFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Allows limiting input to a subset of rows by taking N first rows.
        /// </summary>
        public sealed partial class RowTakeFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Number of items to take
            /// </summary>
            public long Count { get; set; } = 9223372036854775807;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(RowTakeFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new RowTakeFilterPipelineStep(output);
            }

            private class RowTakeFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowTakeFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Selects only the last score columns and the extra columns specified in the arguments.
        /// </summary>
        public sealed partial class ScoreColumnSelector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Extra columns to write
            /// </summary>
            public string[] ExtraColumns { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(ScoreColumnSelector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new ScoreColumnSelectorPipelineStep(output);
            }

            private class ScoreColumnSelectorPipelineStep : ILearningPipelineDataStep
            {
                public ScoreColumnSelectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Turn the predictor model into a transform model
        /// </summary>
        public sealed partial class Scorer
        {


            /// <summary>
            /// The predictor model to turn into a transform
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The scored dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ScoredData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The scoring transform
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> ScoringTransform { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="SentimentAnalyzer"]/*' />
        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/example[@name="SentimentAnalyzer"]/*' />
        public sealed partial class SentimentAnalyzer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Name of the source column.
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// Name of the new column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(SentimentAnalyzer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new SentimentAnalyzerPipelineStep(output);
            }

            private class SentimentAnalyzerPipelineStep : ILearningPipelineDataStep
            {
                public SentimentAnalyzerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.TensorFlow/doc.xml' path='doc/members/member[@name="TensorflowTransform"]/*' />
        public sealed partial class TensorFlowScorer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// TensorFlow model used by the transform. Please see https://www.tensorflow.org/mobile/prepare_models for more details.
            /// </summary>
            public string ModelLocation { get; set; }

            /// <summary>
            /// The names of the model inputs
            /// </summary>
            public string[] InputColumns { get; set; }

            /// <summary>
            /// The name of the outputs
            /// </summary>
            public string[] OutputColumns { get; set; }

            /// <summary>
            /// Training labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// TensorFlow label node.
            /// </summary>
            public string TensorFlowLabel { get; set; }

            /// <summary>
            /// The name of the optimization operation in the TensorFlow graph.
            /// </summary>
            public string OptimizationOperation { get; set; }

            /// <summary>
            /// The name of the operation in the TensorFlow graph to compute training loss (Optional)
            /// </summary>
            public string LossOperation { get; set; }

            /// <summary>
            /// The name of the operation in the TensorFlow graph to compute performance metric during training (Optional)
            /// </summary>
            public string MetricOperation { get; set; }

            /// <summary>
            /// Number of samples to use for mini-batch training.
            /// </summary>
            public int BatchSize { get; set; } = 64;

            /// <summary>
            /// Number of training iterations.
            /// </summary>
            public int Epoch { get; set; } = 5;

            /// <summary>
            /// The name of the operation in the TensorFlow graph which sets optimizer learning rate (Optional).
            /// </summary>
            public string LearningRateOperation { get; set; }

            /// <summary>
            /// Learning rate to use during optimization.
            /// </summary>
            public float LearningRate { get; set; } = 0.01f;

            /// <summary>
            /// Name of the input in TensorFlow graph that specifiy the location for saving/restoring models from disk.
            /// </summary>
            public string SaveLocationOperation { get; set; } = "save/Const";

            /// <summary>
            /// Name of the input in TensorFlow graph that specifiy the location for saving/restoring models from disk.
            /// </summary>
            public string SaveOperation { get; set; } = "save/control_dependency";

            /// <summary>
            /// Retrain TensorFlow model.
            /// </summary>
            public bool ReTrain { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(TensorFlowScorer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new TensorFlowScorerPipelineStep(output);
            }

            private class TensorFlowScorerPipelineStep : ILearningPipelineDataStep
            {
                public TensorFlowScorerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum TextFeaturizingEstimatorLanguage
        {
            English = 1,
            French = 2,
            German = 3,
            Dutch = 4,
            Italian = 5,
            Spanish = 6,
            Japanese = 7
        }

        public enum TextNormalizerEstimatorCaseNormalizationMode
        {
            Lower = 0,
            Upper = 1,
            None = 2
        }

        public enum TextFeaturizingEstimatorTextNormKind
        {
            None = 0,
            L1 = 1,
            L2 = 2,
            LInf = 3
        }


        public sealed partial class TextFeaturizingEstimatorColumn : ManyToOneColumn<TextFeaturizingEstimatorColumn>, IManyToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string[] Source { get; set; }

        }

        public sealed partial class TermLoaderArguments
        {
            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, for example, text sorting will be case sensitive (for example, 'A' then 'Z' then 'a').
            /// </summary>
            public TermTransformSortOrder Sort { get; set; } = TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Drop unknown terms instead of mapping them to NA term.
            /// </summary>
            public bool DropUnknowns { get; set; } = false;

        }

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="FeaturizeTextEstimator"]/*' />
        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/example[@name="FeaturizeTextEstimator"]/*' />
        public sealed partial class TextFeaturizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public TextFeaturizer()
            {
            }
            
            public TextFeaturizer(string outputColumn, params string[] inputColumns)
            {
                AddColumn(outputColumn, inputColumns);
            }
            
            public void AddColumn(string name, params string[] source)
            {
                Column = ManyToOneColumn<Microsoft.ML.Legacy.Transforms.TextFeaturizingEstimatorColumn>.Create(name, source);
            }


            /// <summary>
            /// New column definition (optional form: name:srcs).
            /// </summary>
            public TextFeaturizingEstimatorColumn Column { get; set; }

            /// <summary>
            /// Dataset language or 'AutoDetect' to detect language per row.
            /// </summary>
            public TextFeaturizingEstimatorLanguage Language { get; set; } = TextFeaturizingEstimatorLanguage.English;

            /// <summary>
            /// Stopwords remover.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public StopWordsRemover StopWordsRemover { get; set; }

            /// <summary>
            /// Casing text using the rules of the invariant culture.
            /// </summary>
            public TextNormalizerEstimatorCaseNormalizationMode TextCase { get; set; } = TextNormalizerEstimatorCaseNormalizationMode.Lower;

            /// <summary>
            /// Whether to keep diacritical marks or remove them.
            /// </summary>
            public bool KeepDiacritics { get; set; } = false;

            /// <summary>
            /// Whether to keep punctuation marks or remove them.
            /// </summary>
            public bool KeepPunctuations { get; set; } = true;

            /// <summary>
            /// Whether to keep numbers or remove them.
            /// </summary>
            public bool KeepNumbers { get; set; } = true;

            /// <summary>
            /// Whether to output the transformed text tokens as an additional column.
            /// </summary>
            public bool OutputTokens { get; set; } = false;

            /// <summary>
            /// A dictionary of whitelisted terms.
            /// </summary>
            public TermLoaderArguments Dictionary { get; set; }

            /// <summary>
            /// Ngram feature extractor to use for words (WordBag/WordHashBag).
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public NgramExtractor WordFeatureExtractor { get; set; } = new NGramNgramExtractor();

            /// <summary>
            /// Ngram feature extractor to use for characters (WordBag/WordHashBag).
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public NgramExtractor CharFeatureExtractor { get; set; } = new NGramNgramExtractor() { NgramLength = 3, AllLengths = false };

            /// <summary>
            /// Normalize vectors (rows) individually by rescaling them to unit norm.
            /// </summary>
            public TextFeaturizingEstimatorTextNormKind VectorNormalizer { get; set; } = TextFeaturizingEstimatorTextNormKind.L2;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(TextFeaturizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new TextFeaturizerPipelineStep(output);
            }

            private class TextFeaturizerPipelineStep : ILearningPipelineDataStep
            {
                public TextFeaturizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.Data/Transforms/doc.xml' path='doc/members/member[@name="TextToKey"]/*' />
        /// <include file='../Microsoft.ML.Data/Transforms/doc.xml' path='doc/members/example[@name="TextToKey"]/*' />
        public sealed partial class TextToKeyConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public TextToKeyConverter()
            {
            }
            
            public TextToKeyConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public TextToKeyConverter(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.TermTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.TermTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public TermTransformColumn[] Column { get; set; }

            /// <summary>
            /// Maximum number of terms to keep per column when auto-training
            /// </summary>
            public int MaxNumTerms { get; set; } = 1000000;

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, for example, text sorting will be case sensitive (for example, 'A' then 'Z' then 'a').
            /// </summary>
            public TermTransformSortOrder Sort { get; set; } = TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool TextKeyValues { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(TextToKeyConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new TextToKeyConverterPipelineStep(output);
            }

            private class TextToKeyConverterPipelineStep : ILearningPipelineDataStep
            {
                public TextToKeyConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Split the dataset into train and test sets
        /// </summary>
        public sealed partial class TrainTestDatasetSplitter
        {


            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Fraction of training data
            /// </summary>
            public float Fraction { get; set; } = 0.8f;

            /// <summary>
            /// Stratification column
            /// </summary>
            public string StratificationColumn { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// Training data
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Testing data
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TestData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <include file='../Microsoft.ML.FastTree/doc.xml' path='doc/members/member[@name="TreeEnsembleFeaturizerTransform"]/*'/>
        public sealed partial class TreeLeafFeaturizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IFeaturizerInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {


            /// <summary>
            /// Output column: The suffix to append to the default column names
            /// </summary>
            public string Suffix { get; set; }

            /// <summary>
            /// If specified, determines the permutation seed for applying this featurizer to a multiclass problem.
            /// </summary>
            public int LabelPermutationSeed { get; set; }

            /// <summary>
            /// Trainer to use
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(TreeLeafFeaturizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new TreeLeafFeaturizerPipelineStep(output);
            }

            private class TreeLeafFeaturizerPipelineStep : ILearningPipelineDataStep
            {
                public TreeLeafFeaturizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        /// <summary>
        /// Combines a TransformModel and a PredictorModel into a single PredictorModel.
        /// </summary>
        public sealed partial class TwoHeterogeneousModelCombiner
        {


            /// <summary>
            /// Transform model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// Predictor model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// Predictor model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class VectorToImageTransformColumn : OneToOneColumn<VectorToImageTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Whether to use alpha channel
            /// </summary>
            public bool? ContainsAlpha { get; set; }

            /// <summary>
            /// Whether to use red channel
            /// </summary>
            public bool? ContainsRed { get; set; }

            /// <summary>
            /// Whether to use green channel
            /// </summary>
            public bool? ContainsGreen { get; set; }

            /// <summary>
            /// Whether to use blue channel
            /// </summary>
            public bool? ContainsBlue { get; set; }

            /// <summary>
            /// Whether to separate each channel or interleave in ARGB order
            /// </summary>
            public bool? InterleaveArgb { get; set; }

            /// <summary>
            /// Width of the image
            /// </summary>
            public int? ImageWidth { get; set; }

            /// <summary>
            /// Height of the image
            /// </summary>
            public int? ImageHeight { get; set; }

            /// <summary>
            /// Offset (pre-scale)
            /// </summary>
            public float? Offset { get; set; }

            /// <summary>
            /// Scale factor
            /// </summary>
            public float? Scale { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Converts vector array into image type.
        /// </summary>
        public sealed partial class VectorToImage : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public VectorToImage()
            {
            }
            
            public VectorToImage(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public VectorToImage(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.VectorToImageTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.VectorToImageTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.VectorToImageTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.VectorToImageTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.VectorToImageTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.VectorToImageTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public VectorToImageTransformColumn[] Column { get; set; }

            /// <summary>
            /// Whether to use alpha channel
            /// </summary>
            public bool ContainsAlpha { get; set; } = false;

            /// <summary>
            /// Whether to use red channel
            /// </summary>
            public bool ContainsRed { get; set; } = true;

            /// <summary>
            /// Whether to use green channel
            /// </summary>
            public bool ContainsGreen { get; set; } = true;

            /// <summary>
            /// Whether to use blue channel
            /// </summary>
            public bool ContainsBlue { get; set; } = true;

            /// <summary>
            /// Whether to separate each channel or interleave in ARGB order
            /// </summary>
            public bool InterleaveArgb { get; set; } = false;

            /// <summary>
            /// Width of the image
            /// </summary>
            public int ImageWidth { get; set; }

            /// <summary>
            /// Height of the image
            /// </summary>
            public int ImageHeight { get; set; }

            /// <summary>
            /// Offset (pre-scale)
            /// </summary>
            public float? Offset { get; set; }

            /// <summary>
            /// Scale factor
            /// </summary>
            public float? Scale { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(VectorToImage)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new VectorToImagePipelineStep(output);
            }

            private class VectorToImagePipelineStep : ILearningPipelineDataStep
            {
                public VectorToImagePipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {
        public enum WordEmbeddingsTransformPretrainedModelKind
        {
            GloVe50D = 0,
            GloVe100D = 1,
            GloVe200D = 2,
            GloVe300D = 3,
            GloVeTwitter25D = 4,
            GloVeTwitter50D = 5,
            GloVeTwitter100D = 6,
            GloVeTwitter200D = 7,
            FastTextWikipedia300D = 8,
            Sswe = 9
        }


        public sealed partial class WordEmbeddingsTransformColumn : OneToOneColumn<WordEmbeddingsTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="WordEmbeddings"]/*' />
        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/example[@name="WordEmbeddings"]/*' />
        public sealed partial class WordEmbeddings : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public WordEmbeddings()
            {
            }
            
            public WordEmbeddings(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public WordEmbeddings(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.WordEmbeddingsTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.WordEmbeddingsTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.WordEmbeddingsTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.WordEmbeddingsTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.WordEmbeddingsTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.WordEmbeddingsTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public WordEmbeddingsTransformColumn[] Column { get; set; }

            /// <summary>
            /// Pre-trained model used to create the vocabulary
            /// </summary>
            public WordEmbeddingsTransformPretrainedModelKind? ModelKind { get; set; } = WordEmbeddingsTransformPretrainedModelKind.Sswe;

            /// <summary>
            /// Filename for custom word embedding model
            /// </summary>
            public string CustomLookupTable { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(WordEmbeddings)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new WordEmbeddingsPipelineStep(output);
            }

            private class WordEmbeddingsPipelineStep : ILearningPipelineDataStep
            {
                public WordEmbeddingsPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Legacy.Transforms
    {

        public sealed partial class WordTokenizeTransformColumn : OneToOneColumn<WordTokenizeTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Comma separated set of term separator(s). Commonly: 'space', 'comma', 'semicolon' or other single character.
            /// </summary>
            public string TermSeparators { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/member[@name="WordTokenizer"]/*' />
        /// <include file='../Microsoft.ML.Transforms/Text/doc.xml' path='doc/members/example[@name="WordTokenizer"]/*' />
        public sealed partial class WordTokenizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.Legacy.ILearningPipelineItem
        {

            public WordTokenizer()
            {
            }
            
            public WordTokenizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public WordTokenizer(params (string inputColumn, string outputColumn)[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (var inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.outputColumn, inputOutput.inputColumn);
                    }
                }
            }
            
            public void AddColumn(string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.WordTokenizeTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.WordTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.WordTokenizeTransformColumn>.Create(inputColumn));
                Column = list.ToArray();
            }

            public void AddColumn(string outputColumn, string inputColumn)
            {
                var list = Column == null ? new List<Microsoft.ML.Legacy.Transforms.WordTokenizeTransformColumn>() : new List<Microsoft.ML.Legacy.Transforms.WordTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Microsoft.ML.Legacy.Transforms.WordTokenizeTransformColumn>.Create(outputColumn, inputColumn));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s)
            /// </summary>
            public WordTokenizeTransformColumn[] Column { get; set; }

            /// <summary>
            /// Array of single character term separator(s). By default uses space character separator.
            /// </summary>
            public char[] CharArrayTermSeparators { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public Var<IDataView> GetInputData() => Data;
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (previousStep != null)
                {
                    if (!(previousStep is ILearningPipelineDataStep dataStep))
                    {
                        throw new InvalidOperationException($"{ nameof(WordTokenizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                    }

                    Data = dataStep.Data;
                }
                Output output = experiment.Add(this);
                return new WordTokenizerPipelineStep(output);
            }

            private class WordTokenizerPipelineStep : ILearningPipelineDataStep
            {
                public WordTokenizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Runtime
    {
        public abstract class AutoMlEngine : ComponentKind {}



        /// <summary>
        /// AutoML engine that returns learners with default settings.
        /// </summary>
        public sealed class DefaultsAutoMlEngine : AutoMlEngine
        {
            internal override string ComponentName => "Defaults";
        }



        /// <summary>
        /// AutoML engine that consists of distinct, hierarchical stages of operation.
        /// </summary>
        public sealed class RocketAutoMlEngine : AutoMlEngine
        {
            /// <summary>
            /// Number of learners to retain for second stage.
            /// </summary>
            public int TopKLearners { get; set; } = 2;

            /// <summary>
            /// Number of trials for retained second stage learners.
            /// </summary>
            public int SecondRoundTrialsPerLearner { get; set; } = 5;

            /// <summary>
            /// Use random initialization only.
            /// </summary>
            public bool RandomInitialization { get; set; } = false;

            /// <summary>
            /// Number of initilization pipelines, used for random initialization only.
            /// </summary>
            public int NumInitializationPipelines { get; set; } = 20;

            internal override string ComponentName => "Rocket";
        }



        /// <summary>
        /// AutoML engine using uniform random sampling.
        /// </summary>
        public sealed class UniformRandomAutoMlEngine : AutoMlEngine
        {
            internal override string ComponentName => "UniformRandom";
        }

        public abstract class AutoMlStateBase : ComponentKind {}

        public enum PipelineSweeperSupportedMetricsMetrics
        {
            Auc = 0,
            AccuracyMicro = 1,
            AccuracyMacro = 2,
            L1 = 3,
            L2 = 4,
            F1 = 5,
            AuPrc = 6,
            TopKAccuracy = 7,
            Rms = 8,
            LossFn = 9,
            RSquared = 10,
            LogLoss = 11,
            LogLossReduction = 12,
            Ndcg = 13,
            Dcg = 14,
            PositivePrecision = 15,
            PositiveRecall = 16,
            NegativePrecision = 17,
            NegativeRecall = 18,
            DrAtK = 19,
            DrAtPFpr = 20,
            DrAtNumPos = 21,
            NumAnomalies = 22,
            ThreshAtK = 23,
            ThreshAtP = 24,
            ThreshAtNumPos = 25,
            Nmi = 26,
            AvgMinScore = 27,
            Dbi = 28
        }



        /// <summary>
        /// State of an AutoML search and search space.
        /// </summary>
        public sealed class AutoMlStateAutoMlStateBase : AutoMlStateBase
        {
            /// <summary>
            /// Supported metric for evaluator.
            /// </summary>
            public PipelineSweeperSupportedMetricsMetrics Metric { get; set; } = PipelineSweeperSupportedMetricsMetrics.Auc;

            /// <summary>
            /// AutoML engine (pipeline optimizer) that generates next candidates.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public AutoMlEngine Engine { get; set; }

            /// <summary>
            /// Kind of trainer for task, such as binary classification trainer, multiclass trainer, etc.
            /// </summary>
            public Microsoft.ML.Legacy.Models.MacroUtilsTrainerKinds TrainerKind { get; set; } = Microsoft.ML.Legacy.Models.MacroUtilsTrainerKinds.SignatureBinaryClassifierTrainer;

            /// <summary>
            /// Arguments for creating terminator, which determines when to stop search.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SearchTerminator TerminatorArgs { get; set; }

            /// <summary>
            /// Learner set to sweep over (if available).
            /// </summary>
            public string[] RequestedLearners { get; set; }

            internal override string ComponentName => "AutoMlState";
        }

        public abstract class BoosterParameterFunction : ComponentKind {}



        /// <summary>
        /// Dropouts meet Multiple Additive Regresion Trees. See https://arxiv.org/abs/1505.01866
        /// </summary>
        public sealed class DartBoosterParameterFunction : BoosterParameterFunction
        {
            /// <summary>
            /// Drop ratio for trees. Range:(0,1).
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double DropRate { get; set; } = 0.1d;

            /// <summary>
            /// Max number of dropped tree in a boosting round.
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxDrop { get; set; } = 1;

            /// <summary>
            /// Probability for not perform dropping in a boosting round.
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double SkipDrop { get; set; } = 0.5d;

            /// <summary>
            /// True will enable xgboost dart mode.
            /// </summary>
            public bool XgboostDartMode { get; set; } = false;

            /// <summary>
            /// True will enable uniform drop.
            /// </summary>
            public bool UniformDrop { get; set; } = false;

            /// <summary>
            /// Use for binary classification when classes are not balanced.
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more conservative the algorithm will be.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            public double MinSplitGain { get; set; }

            /// <summary>
            /// Maximum depth of a tree. 0 means no limit. However, tree still grows by best-first.
            /// </summary>
            [TlcModule.Range(Min = 0, Max = 2147483647)]
            public int MaxDepth { get; set; }

            /// <summary>
            /// Minimum sum of instance weight(hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression mode, this simply corresponds to minimum number of instances needed to be in each node. The larger, the more conservative the algorithm will be.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            public double MinChildWeight { get; set; } = 0.1d;

            /// <summary>
            /// Subsample frequency. 0 means no subsample. If subsampleFreq > 0, it will use a subset(ratio=subsample) to train. And the subset will be updated on every Subsample iteratinos.
            /// </summary>
            [TlcModule.Range(Min = 0, Max = 2147483647)]
            public int SubsampleFreq { get; set; }

            /// <summary>
            /// Subsample ratio of the training instance. Setting it to 0.5 means that LightGBM randomly collected half of the data instances to grow trees and this will prevent overfitting. Range: (0,1].
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double Subsample { get; set; } = 1d;

            /// <summary>
            /// Subsample ratio of columns when constructing each tree. Range: (0,1].
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// L2 regularization term on weights, increasing this value will make model more conservative.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("RegLambda", new object[]{0f, 0.5f, 1f})]
            public double RegLambda { get; set; } = 0.01d;

            /// <summary>
            /// L1 regularization term on weights, increase this value will make model more conservative.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("RegAlpha", new object[]{0f, 0.5f, 1f})]
            public double RegAlpha { get; set; }

            /// <summary>
            /// Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative cases) / sum(positive cases).
            /// </summary>
            public double ScalePosWeight { get; set; } = 1d;

            internal override string ComponentName => "dart";
        }



        /// <summary>
        /// Traditional Gradient Boosting Decision Tree.
        /// </summary>
        public sealed class GbdtBoosterParameterFunction : BoosterParameterFunction
        {
            /// <summary>
            /// Use for binary classification when classes are not balanced.
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more conservative the algorithm will be.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            public double MinSplitGain { get; set; }

            /// <summary>
            /// Maximum depth of a tree. 0 means no limit. However, tree still grows by best-first.
            /// </summary>
            [TlcModule.Range(Min = 0, Max = 2147483647)]
            public int MaxDepth { get; set; }

            /// <summary>
            /// Minimum sum of instance weight(hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression mode, this simply corresponds to minimum number of instances needed to be in each node. The larger, the more conservative the algorithm will be.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            public double MinChildWeight { get; set; } = 0.1d;

            /// <summary>
            /// Subsample frequency. 0 means no subsample. If subsampleFreq > 0, it will use a subset(ratio=subsample) to train. And the subset will be updated on every Subsample iteratinos.
            /// </summary>
            [TlcModule.Range(Min = 0, Max = 2147483647)]
            public int SubsampleFreq { get; set; }

            /// <summary>
            /// Subsample ratio of the training instance. Setting it to 0.5 means that LightGBM randomly collected half of the data instances to grow trees and this will prevent overfitting. Range: (0,1].
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double Subsample { get; set; } = 1d;

            /// <summary>
            /// Subsample ratio of columns when constructing each tree. Range: (0,1].
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// L2 regularization term on weights, increasing this value will make model more conservative.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("RegLambda", new object[]{0f, 0.5f, 1f})]
            public double RegLambda { get; set; } = 0.01d;

            /// <summary>
            /// L1 regularization term on weights, increase this value will make model more conservative.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("RegAlpha", new object[]{0f, 0.5f, 1f})]
            public double RegAlpha { get; set; }

            /// <summary>
            /// Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative cases) / sum(positive cases).
            /// </summary>
            public double ScalePosWeight { get; set; } = 1d;

            internal override string ComponentName => "gbdt";
        }



        /// <summary>
        /// Gradient-based One-Side Sampling.
        /// </summary>
        public sealed class GossBoosterParameterFunction : BoosterParameterFunction
        {
            /// <summary>
            /// Retain ratio for large gradient instances.
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double TopRate { get; set; } = 0.2d;

            /// <summary>
            /// Retain ratio for small gradient instances.
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double OtherRate { get; set; } = 0.1d;

            /// <summary>
            /// Use for binary classification when classes are not balanced.
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Minimum loss reduction required to make a further partition on a leaf node of the tree. the larger, the more conservative the algorithm will be.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            public double MinSplitGain { get; set; }

            /// <summary>
            /// Maximum depth of a tree. 0 means no limit. However, tree still grows by best-first.
            /// </summary>
            [TlcModule.Range(Min = 0, Max = 2147483647)]
            public int MaxDepth { get; set; }

            /// <summary>
            /// Minimum sum of instance weight(hessian) needed in a child. If the tree partition step results in a leaf node with the sum of instance weight less than min_child_weight, then the building process will give up further partitioning. In linear regression mode, this simply corresponds to minimum number of instances needed to be in each node. The larger, the more conservative the algorithm will be.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            public double MinChildWeight { get; set; } = 0.1d;

            /// <summary>
            /// Subsample frequency. 0 means no subsample. If subsampleFreq > 0, it will use a subset(ratio=subsample) to train. And the subset will be updated on every Subsample iteratinos.
            /// </summary>
            [TlcModule.Range(Min = 0, Max = 2147483647)]
            public int SubsampleFreq { get; set; }

            /// <summary>
            /// Subsample ratio of the training instance. Setting it to 0.5 means that LightGBM randomly collected half of the data instances to grow trees and this will prevent overfitting. Range: (0,1].
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double Subsample { get; set; } = 1d;

            /// <summary>
            /// Subsample ratio of columns when constructing each tree. Range: (0,1].
            /// </summary>
            [TlcModule.Range(Inf = 0d, Max = 1d)]
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// L2 regularization term on weights, increasing this value will make model more conservative.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("RegLambda", new object[]{0f, 0.5f, 1f})]
            public double RegLambda { get; set; } = 0.01d;

            /// <summary>
            /// L1 regularization term on weights, increase this value will make model more conservative.
            /// </summary>
            [TlcModule.Range(Min = 0d)]
            [TlcModule.SweepableDiscreteParamAttribute("RegAlpha", new object[]{0f, 0.5f, 1f})]
            public double RegAlpha { get; set; }

            /// <summary>
            /// Control the balance of positive and negative weights, useful for unbalanced classes. A typical value to consider: sum(negative cases) / sum(positive cases).
            /// </summary>
            public double ScalePosWeight { get; set; } = 1d;

            internal override string ComponentName => "goss";
        }

        public abstract class CalibratorTrainer : ComponentKind {}



        public sealed class FixedPlattCalibratorCalibratorTrainer : CalibratorTrainer
        {
            /// <summary>
            /// The slope parameter of f(x) = 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Slope { get; set; } = 1d;

            /// <summary>
            /// The offset parameter of f(x) = 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Offset { get; set; }

            internal override string ComponentName => "FixedPlattCalibrator";
        }



        public sealed class NaiveCalibratorCalibratorTrainer : CalibratorTrainer
        {
            internal override string ComponentName => "NaiveCalibrator";
        }



        public sealed class PavCalibratorCalibratorTrainer : CalibratorTrainer
        {
            internal override string ComponentName => "PavCalibrator";
        }



        /// <summary>
        /// Platt calibration.
        /// </summary>
        public sealed class PlattCalibratorCalibratorTrainer : CalibratorTrainer
        {
            internal override string ComponentName => "PlattCalibrator";
        }

        public abstract class ClassificationLossFunction : ComponentKind {}



        /// <summary>
        /// Exponential loss.
        /// </summary>
        public sealed class ExpLossClassificationLossFunction : ClassificationLossFunction
        {
            /// <summary>
            /// Beta (dilation)
            /// </summary>
            public float Beta { get; set; } = 1f;

            internal override string ComponentName => "ExpLoss";
        }



        /// <summary>
        /// Hinge loss.
        /// </summary>
        public sealed class HingeLossClassificationLossFunction : ClassificationLossFunction
        {
            /// <summary>
            /// Margin value
            /// </summary>
            public float Margin { get; set; } = 1f;

            internal override string ComponentName => "HingeLoss";
        }



        /// <summary>
        /// Log loss.
        /// </summary>
        public sealed class LogLossClassificationLossFunction : ClassificationLossFunction
        {
            internal override string ComponentName => "LogLoss";
        }



        /// <summary>
        /// Smoothed Hinge loss.
        /// </summary>
        public sealed class SmoothedHingeLossClassificationLossFunction : ClassificationLossFunction
        {
            /// <summary>
            /// Smoothing constant
            /// </summary>
            public float SmoothingConst { get; set; } = 1f;

            internal override string ComponentName => "SmoothedHingeLoss";
        }

        public abstract class EarlyStoppingCriterion : ComponentKind {}



        /// <summary>
        /// Stop in case of loss of generality.
        /// </summary>
        public sealed class GLEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Threshold in range [0,1].
            /// </summary>
            [TlcModule.Range(Min = 0f, Max = 1f)]
            public float Threshold { get; set; } = 0.01f;

            internal override string ComponentName => "GL";
        }



        /// <summary>
        /// Stops in case of low progress.
        /// </summary>
        public sealed class LPEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Threshold in range [0,1].
            /// </summary>
            [TlcModule.Range(Min = 0f, Max = 1f)]
            public float Threshold { get; set; } = 0.01f;

            /// <summary>
            /// The window size.
            /// </summary>
            [TlcModule.Range(Inf = 0)]
            public int WindowSize { get; set; } = 5;

            internal override string ComponentName => "LP";
        }



        /// <summary>
        /// Stops in case of generality to progress ration exceeds threshold.
        /// </summary>
        public sealed class PQEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Threshold in range [0,1].
            /// </summary>
            [TlcModule.Range(Min = 0f, Max = 1f)]
            public float Threshold { get; set; } = 0.01f;

            /// <summary>
            /// The window size.
            /// </summary>
            [TlcModule.Range(Inf = 0)]
            public int WindowSize { get; set; } = 5;

            internal override string ComponentName => "PQ";
        }



        /// <summary>
        /// Stop if validation score exceeds threshold value.
        /// </summary>
        public sealed class TREarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Tolerance threshold. (Non negative value)
            /// </summary>
            [TlcModule.Range(Min = 0f)]
            public float Threshold { get; set; } = 0.01f;

            internal override string ComponentName => "TR";
        }



        /// <summary>
        /// Stops in case of consecutive loss in generality.
        /// </summary>
        public sealed class UPEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// The window size.
            /// </summary>
            [TlcModule.Range(Inf = 0)]
            public int WindowSize { get; set; } = 5;

            internal override string ComponentName => "UP";
        }

        public abstract class EnsembleBinaryDiversityMeasure : ComponentKind {}



        public sealed class DisagreementDiversityMeasureEnsembleBinaryDiversityMeasure : EnsembleBinaryDiversityMeasure
        {
            internal override string ComponentName => "DisagreementDiversityMeasure";
        }

        public abstract class EnsembleBinaryOutputCombiner : ComponentKind {}



        public sealed class AverageEnsembleBinaryOutputCombiner : EnsembleBinaryOutputCombiner
        {
            internal override string ComponentName => "Average";
        }



        public sealed class MedianEnsembleBinaryOutputCombiner : EnsembleBinaryOutputCombiner
        {
            internal override string ComponentName => "Median";
        }



        public sealed class StackingEnsembleBinaryOutputCombiner : EnsembleBinaryOutputCombiner
        {
            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "Stacking";
        }



        public sealed class VotingEnsembleBinaryOutputCombiner : EnsembleBinaryOutputCombiner
        {
            internal override string ComponentName => "Voting";
        }

        public enum WeightageKind
        {
            Accuracy = 0,
            Auc = 1,
            PosPrecision = 2,
            PosRecall = 3,
            NegPrecision = 4,
            NegRecall = 5
        }



        public sealed class WeightedAverageEnsembleBinaryOutputCombiner : EnsembleBinaryOutputCombiner
        {
            /// <summary>
            /// The metric type to be used to find the weights for each model
            /// </summary>
            public WeightageKind WeightageName { get; set; } = WeightageKind.Auc;

            internal override string ComponentName => "WeightedAverage";
        }

        public abstract class EnsembleBinarySubModelSelector : ComponentKind {}



        public sealed class AllSelectorEnsembleBinarySubModelSelector : EnsembleBinarySubModelSelector
        {
            internal override string ComponentName => "AllSelector";
        }



        public sealed class BestDiverseSelectorEnsembleBinarySubModelSelector : EnsembleBinarySubModelSelector
        {
            /// <summary>
            /// The metric type to be used to find the diversity among base learners
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleBinaryDiversityMeasure DiversityMetricType { get; set; } = new DisagreementDiversityMeasureEnsembleBinaryDiversityMeasure();

            /// <summary>
            /// The proportion of best base learners to be selected. The range is 0.0-1.0
            /// </summary>
            public float LearnersSelectionProportion { get; set; } = 0.5f;

            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "BestDiverseSelector";
        }

        public enum BinaryClassifierEvaluatorMetrics
        {
            Accuracy = 0,
            PosPrecName = 1,
            PosRecallName = 2,
            NegPrecName = 3,
            NegRecallName = 4,
            Auc = 5,
            LogLoss = 6,
            LogLossReduction = 7,
            F1 = 8,
            AuPrc = 9
        }



        public sealed class BestPerformanceSelectorEnsembleBinarySubModelSelector : EnsembleBinarySubModelSelector
        {
            /// <summary>
            /// The metric type to be used to find the best performance
            /// </summary>
            public BinaryClassifierEvaluatorMetrics MetricName { get; set; } = BinaryClassifierEvaluatorMetrics.Auc;

            /// <summary>
            /// The proportion of best base learners to be selected. The range is 0.0-1.0
            /// </summary>
            public float LearnersSelectionProportion { get; set; } = 0.5f;

            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "BestPerformanceSelector";
        }

        public abstract class EnsembleFeatureSelector : ComponentKind {}



        public sealed class AllFeatureSelectorEnsembleFeatureSelector : EnsembleFeatureSelector
        {
            internal override string ComponentName => "AllFeatureSelector";
        }



        public sealed class RandomFeatureSelectorEnsembleFeatureSelector : EnsembleFeatureSelector
        {
            /// <summary>
            /// The proportion of features to be selected. The range is 0.0-1.0
            /// </summary>
            public float FeaturesSelectionProportion { get; set; } = 0.8f;

            internal override string ComponentName => "RandomFeatureSelector";
        }

        public abstract class EnsembleMulticlassDiversityMeasure : ComponentKind {}



        public sealed class MultiDisagreementDiversityMeasureEnsembleMulticlassDiversityMeasure : EnsembleMulticlassDiversityMeasure
        {
            internal override string ComponentName => "MultiDisagreementDiversityMeasure";
        }

        public abstract class EnsembleMulticlassOutputCombiner : ComponentKind {}



        public sealed class MultiAverageEnsembleMulticlassOutputCombiner : EnsembleMulticlassOutputCombiner
        {
            /// <summary>
            /// Whether to normalize the output of base models before combining them
            /// </summary>
            public bool Normalize { get; set; } = true;

            internal override string ComponentName => "MultiAverage";
        }



        public sealed class MultiMedianEnsembleMulticlassOutputCombiner : EnsembleMulticlassOutputCombiner
        {
            /// <summary>
            /// Whether to normalize the output of base models before combining them
            /// </summary>
            public bool Normalize { get; set; } = true;

            internal override string ComponentName => "MultiMedian";
        }



        public sealed class MultiStackingEnsembleMulticlassOutputCombiner : EnsembleMulticlassOutputCombiner
        {
            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "MultiStacking";
        }



        public sealed class MultiVotingEnsembleMulticlassOutputCombiner : EnsembleMulticlassOutputCombiner
        {
            internal override string ComponentName => "MultiVoting";
        }

        public enum MultiWeightageKind
        {
            AccuracyMicroAvg = 0,
            AccuracyMacroAvg = 1
        }



        public sealed class MultiWeightedAverageEnsembleMulticlassOutputCombiner : EnsembleMulticlassOutputCombiner
        {
            /// <summary>
            /// The metric type to be used to find the weights for each model
            /// </summary>
            public MultiWeightageKind WeightageName { get; set; } = MultiWeightageKind.AccuracyMicroAvg;

            /// <summary>
            /// Whether to normalize the output of base models before combining them
            /// </summary>
            public bool Normalize { get; set; } = true;

            internal override string ComponentName => "MultiWeightedAverage";
        }

        public abstract class EnsembleMulticlassSubModelSelector : ComponentKind {}



        public sealed class AllSelectorMultiClassEnsembleMulticlassSubModelSelector : EnsembleMulticlassSubModelSelector
        {
            internal override string ComponentName => "AllSelectorMultiClass";
        }



        public sealed class BestDiverseSelectorMultiClassEnsembleMulticlassSubModelSelector : EnsembleMulticlassSubModelSelector
        {
            /// <summary>
            /// The metric type to be used to find the diversity among base learners
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleMulticlassDiversityMeasure DiversityMetricType { get; set; } = new MultiDisagreementDiversityMeasureEnsembleMulticlassDiversityMeasure();

            /// <summary>
            /// The proportion of best base learners to be selected. The range is 0.0-1.0
            /// </summary>
            public float LearnersSelectionProportion { get; set; } = 0.5f;

            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "BestDiverseSelectorMultiClass";
        }

        public enum MultiClassClassifierEvaluatorMetrics
        {
            AccuracyMicro = 0,
            AccuracyMacro = 1,
            LogLoss = 2,
            LogLossReduction = 3
        }



        public sealed class BestPerformanceSelectorMultiClassEnsembleMulticlassSubModelSelector : EnsembleMulticlassSubModelSelector
        {
            /// <summary>
            /// The metric type to be used to find the best performance
            /// </summary>
            public MultiClassClassifierEvaluatorMetrics MetricName { get; set; } = MultiClassClassifierEvaluatorMetrics.AccuracyMicro;

            /// <summary>
            /// The proportion of best base learners to be selected. The range is 0.0-1.0
            /// </summary>
            public float LearnersSelectionProportion { get; set; } = 0.5f;

            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "BestPerformanceSelectorMultiClass";
        }

        public abstract class EnsembleRegressionDiversityMeasure : ComponentKind {}



        public sealed class RegressionDisagreementDiversityMeasureEnsembleRegressionDiversityMeasure : EnsembleRegressionDiversityMeasure
        {
            internal override string ComponentName => "RegressionDisagreementDiversityMeasure";
        }

        public abstract class EnsembleRegressionOutputCombiner : ComponentKind {}



        public sealed class AverageEnsembleRegressionOutputCombiner : EnsembleRegressionOutputCombiner
        {
            internal override string ComponentName => "Average";
        }



        public sealed class MedianEnsembleRegressionOutputCombiner : EnsembleRegressionOutputCombiner
        {
            internal override string ComponentName => "Median";
        }



        public sealed class RegressionStackingEnsembleRegressionOutputCombiner : EnsembleRegressionOutputCombiner
        {
            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "RegressionStacking";
        }

        public abstract class EnsembleRegressionSubModelSelector : ComponentKind {}



        public sealed class AllSelectorEnsembleRegressionSubModelSelector : EnsembleRegressionSubModelSelector
        {
            internal override string ComponentName => "AllSelector";
        }



        public sealed class BestDiverseSelectorRegressionEnsembleRegressionSubModelSelector : EnsembleRegressionSubModelSelector
        {
            /// <summary>
            /// The metric type to be used to find the diversity among base learners
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleRegressionDiversityMeasure DiversityMetricType { get; set; } = new RegressionDisagreementDiversityMeasureEnsembleRegressionDiversityMeasure();

            /// <summary>
            /// The proportion of best base learners to be selected. The range is 0.0-1.0
            /// </summary>
            public float LearnersSelectionProportion { get; set; } = 0.5f;

            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "BestDiverseSelectorRegression";
        }

        public enum RegressionEvaluatorMetrics
        {
            L1 = 0,
            L2 = 1,
            Rms = 2,
            Loss = 3,
            RSquared = 4
        }



        public sealed class BestPerformanceRegressionSelectorEnsembleRegressionSubModelSelector : EnsembleRegressionSubModelSelector
        {
            /// <summary>
            /// The metric type to be used to find the best performance
            /// </summary>
            public RegressionEvaluatorMetrics MetricName { get; set; } = RegressionEvaluatorMetrics.L1;

            /// <summary>
            /// The proportion of best base learners to be selected. The range is 0.0-1.0
            /// </summary>
            public float LearnersSelectionProportion { get; set; } = 0.5f;

            /// <summary>
            /// The proportion of instances to be selected to test the individual base learner. If it is 0, it uses training set
            /// </summary>
            public float ValidationDatasetProportion { get; set; } = 0.3f;

            internal override string ComponentName => "BestPerformanceRegressionSelector";
        }

        public abstract class EnsembleSubsetSelector : ComponentKind {}



        public sealed class AllInstanceSelectorEnsembleSubsetSelector : EnsembleSubsetSelector
        {
            /// <summary>
            /// The Feature selector
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleFeatureSelector FeatureSelector { get; set; } = new AllFeatureSelectorEnsembleFeatureSelector();

            internal override string ComponentName => "AllInstanceSelector";
        }



        public sealed class BootstrapSelectorEnsembleSubsetSelector : EnsembleSubsetSelector
        {
            /// <summary>
            /// The Feature selector
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleFeatureSelector FeatureSelector { get; set; } = new AllFeatureSelectorEnsembleFeatureSelector();

            internal override string ComponentName => "BootstrapSelector";
        }



        public sealed class RandomPartitionSelectorEnsembleSubsetSelector : EnsembleSubsetSelector
        {
            /// <summary>
            /// The Feature selector
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EnsembleFeatureSelector FeatureSelector { get; set; } = new AllFeatureSelectorEnsembleFeatureSelector();

            internal override string ComponentName => "RandomPartitionSelector";
        }

        public abstract class FastTreeTrainer : ComponentKind {}



        /// <summary>
        /// Uses a logit-boost boosted tree learner to perform binary classification.
        /// </summary>
        public sealed class FastTreeBinaryClassificationFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Should we use derivatives optimized for unbalanced sets
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Legacy.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeBinaryClassification";
        }



        /// <summary>
        /// Trains gradient boosted decision trees to the LambdaRank quasi-gradient.
        /// </summary>
        public sealed class FastTreeRankingFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31";

            /// <summary>
            /// Train DCG instead of NDCG
            /// </summary>
            public bool TrainDcg { get; set; } = false;

            /// <summary>
            /// The sorting algorithm to use for DCG and LambdaMart calculations [DescendingStablePessimistic/DescendingStable/DescendingReverse/DescendingDotNet]
            /// </summary>
            public string SortingAlgorithm { get; set; } = "DescendingStablePessimistic";

            /// <summary>
            /// max-NDCG truncation to use in the Lambda Mart algorithm
            /// </summary>
            public int LambdaMartMaxTruncation { get; set; } = 100;

            /// <summary>
            /// Use shifted NDCG
            /// </summary>
            public bool ShiftedNdcg { get; set; } = false;

            /// <summary>
            /// Cost function parameter (w/c)
            /// </summary>
            public char CostFunctionParam { get; set; } = 'w';

            /// <summary>
            /// Distance weight 2 adjustment to cost
            /// </summary>
            public bool DistanceWeight2 { get; set; } = false;

            /// <summary>
            /// Normalize query lambdas
            /// </summary>
            public bool NormalizeQueryLambdas { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Legacy.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeRanking";
        }



        /// <summary>
        /// Trains gradient boosted decision trees to fit target values using least-squares.
        /// </summary>
        public sealed class FastTreeRegressionFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Legacy.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeRegression";
        }



        /// <summary>
        /// Trains gradient boosted decision trees to fit target values using a Tweedie loss function. This learner is a generalization of Poisson, compound Poisson, and gamma regression.
        /// </summary>
        public sealed class FastTreeTweedieRegressionFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Index parameter for the Tweedie distribution, in the range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate values are compound Poisson loss.
            /// </summary>
            public double Index { get; set; } = 1.5d;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Legacy.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Legacy.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Legacy.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Total number of decision trees to create in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Legacy.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Legacy.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Legacy.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Legacy.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeTweedieRegression";
        }

        public abstract class NgramExtractor : ComponentKind {}



        /// <summary>
        /// Extracts NGrams from text and convert them to vector using dictionary.
        /// </summary>
        public sealed class NGramNgramExtractor : NgramExtractor
        {
            /// <summary>
            /// Ngram length
            /// </summary>
            public int NgramLength { get; set; } = 1;

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int SkipLength { get; set; }

            /// <summary>
            /// Whether to include all ngram lengths up to NgramLength or only NgramLength
            /// </summary>
            public bool AllLengths { get; set; } = true;

            /// <summary>
            /// Maximum number of ngrams to store in the dictionary
            /// </summary>
            public int[] MaxNumTerms { get; set; } = { 10000000 };

            /// <summary>
            /// The weighting criteria
            /// </summary>
            public Microsoft.ML.Legacy.Transforms.NgramTransformWeightingCriteria Weighting { get; set; } = Microsoft.ML.Legacy.Transforms.NgramTransformWeightingCriteria.Tf;

            internal override string ComponentName => "NGram";
        }



        /// <summary>
        /// Extracts NGrams from text and convert them to vector using hashing trick.
        /// </summary>
        public sealed class NGramHashNgramExtractor : NgramExtractor
        {
            /// <summary>
            /// Ngram length
            /// </summary>
            public int NgramLength { get; set; } = 1;

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int SkipLength { get; set; }

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 30, inclusive.
            /// </summary>
            public int HashBits { get; set; } = 16;

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint Seed { get; set; } = 314489979;

            /// <summary>
            /// Whether the position of each source column should be included in the hash (when there are multiple source columns).
            /// </summary>
            public bool Ordered { get; set; } = true;

            /// <summary>
            /// Limit the number of keys used to generate the slot name to this many. 0 means no invert hashing, -1 means no limit.
            /// </summary>
            public int InvertHash { get; set; }

            /// <summary>
            /// Whether to include all ngram lengths up to ngramLength or only ngramLength
            /// </summary>
            public bool AllLengths { get; set; } = true;

            internal override string ComponentName => "NGramHash";
        }

        public abstract class ParallelLightGBM : ComponentKind {}



        /// <summary>
        /// Single node machine learning process.
        /// </summary>
        public sealed class SingleParallelLightGBM : ParallelLightGBM
        {
            internal override string ComponentName => "Single";
        }

        public abstract class ParallelTraining : ComponentKind {}



        /// <summary>
        /// Single node machine learning process.
        /// </summary>
        public sealed class SingleParallelTraining : ParallelTraining
        {
            internal override string ComponentName => "Single";
        }

        public abstract class PartitionedPathParser : ComponentKind {}



        /// <summary>
        /// Extract name/value pairs from Parquet formatted directory names. Example path: Year=2018/Month=12/data1.parquet
        /// </summary>
        public sealed class ParquetPathParserPartitionedPathParser : PartitionedPathParser
        {
            internal override string ComponentName => "ParquetPathParser";
        }


        public sealed partial class PartitionedFileLoaderColumn
        {
            /// <summary>
            /// Name of the column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Data type of the column.
            /// </summary>
            public Microsoft.ML.Legacy.Data.DataKind? Type { get; set; }

            /// <summary>
            /// Index of the directory representing this column.
            /// </summary>
            public int Source { get; set; }

        }


        /// <summary>
        /// A simple parser that extracts directory names as column values. Column names are defined as arguments.
        /// </summary>
        public sealed class SimplePathParserPartitionedPathParser : PartitionedPathParser
        {
            /// <summary>
            /// Column definitions used to override the Partitioned Path Parser. Expected with the format name:type:numeric-source, for example, col=MyFeature:R4:1
            /// </summary>
            public PartitionedFileLoaderColumn[] Columns { get; set; }

            /// <summary>
            /// Data type of each column.
            /// </summary>
            public Microsoft.ML.Legacy.Data.DataKind Type { get; set; } = Microsoft.ML.Legacy.Data.DataKind.TX;

            internal override string ComponentName => "SimplePathParser";
        }

        public abstract class RegressionLossFunction : ComponentKind {}



        /// <summary>
        /// Poisson loss.
        /// </summary>
        public sealed class PoissonLossRegressionLossFunction : RegressionLossFunction
        {
            internal override string ComponentName => "PoissonLoss";
        }



        /// <summary>
        /// Squared loss.
        /// </summary>
        public sealed class SquaredLossRegressionLossFunction : RegressionLossFunction
        {
            internal override string ComponentName => "SquaredLoss";
        }



        /// <summary>
        /// Tweedie loss.
        /// </summary>
        public sealed class TweedieLossRegressionLossFunction : RegressionLossFunction
        {
            /// <summary>
            /// Index parameter for the Tweedie distribution, in the range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate values are compound Poisson loss.
            /// </summary>
            public double Index { get; set; } = 1.5d;

            internal override string ComponentName => "TweedieLoss";
        }

        public abstract class SDCAClassificationLossFunction : ComponentKind {}



        /// <summary>
        /// Hinge loss.
        /// </summary>
        public sealed class HingeLossSDCAClassificationLossFunction : SDCAClassificationLossFunction
        {
            /// <summary>
            /// Margin value
            /// </summary>
            public float Margin { get; set; } = 1f;

            internal override string ComponentName => "HingeLoss";
        }



        /// <summary>
        /// Log loss.
        /// </summary>
        public sealed class LogLossSDCAClassificationLossFunction : SDCAClassificationLossFunction
        {
            internal override string ComponentName => "LogLoss";
        }



        /// <summary>
        /// Smoothed Hinge loss.
        /// </summary>
        public sealed class SmoothedHingeLossSDCAClassificationLossFunction : SDCAClassificationLossFunction
        {
            /// <summary>
            /// Smoothing constant
            /// </summary>
            public float SmoothingConst { get; set; } = 1f;

            internal override string ComponentName => "SmoothedHingeLoss";
        }

        public abstract class SDCARegressionLossFunction : ComponentKind {}



        /// <summary>
        /// Squared loss.
        /// </summary>
        public sealed class SquaredLossSDCARegressionLossFunction : SDCARegressionLossFunction
        {
            internal override string ComponentName => "SquaredLoss";
        }

        public abstract class SearchTerminator : ComponentKind {}



        /// <summary>
        /// Terminators a sweep based on total number of iterations.
        /// </summary>
        public sealed class IterationLimitedSearchTerminator : SearchTerminator
        {
            /// <summary>
            /// Total number of iterations.
            /// </summary>
            public int FinalHistoryLength { get; set; }

            internal override string ComponentName => "IterationLimited";
        }

        public abstract class StopWordsRemover : ComponentKind {}



        /// <summary>
        /// Remover with list of stopwords specified by the user.
        /// </summary>
        public sealed class CustomStopWordsRemover : StopWordsRemover
        {
            /// <summary>
            /// List of stopwords
            /// </summary>
            public string[] Stopword { get; set; }

            internal override string ComponentName => "Custom";
        }



        /// <summary>
        /// Remover with predefined list of stop words.
        /// </summary>
        public sealed class PredefinedStopWordsRemover : StopWordsRemover
        {
            internal override string ComponentName => "Predefined";
        }

    }
}
#pragma warning restore
