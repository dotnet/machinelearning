<?xml version="1.0" encoding="utf-8"?>
<docs>
  <members>

    <member name="CategoricalHashOneHotVectorizer">
      <summary>
        Encodes the categorical variable with hash-based encoding. 
      </summary>
      <remarks>
        CategoricalHashOneHotVectorizer converts a categorical value into an indicator array by hashing the
        value and using the hash as an index in the bag.
        If the input column is a vector, a single indicator bag is returned for it.
      </remarks>
      <example>
        <code>
          pipeline.Add(new CategoricalHashOneHotVectorizer(&quot;Text1&quot;) { HashBits = 10, Seed = 314489979, OutputKind = CategoricalTransformOutputKind.Bag });
        </code>
      </example>
    </member>

    <member name="CategoricalOneHotVectorizer">
      <summary>
        Converts the categorical value into an indicator array by building a dictionary of categories based on the data and using the id in the dictionary as the index in the array
      </summary>
      <remarks>
        <para>The CategoricalOneHotVectorizer transform passes through a data set, operating on text columns, to
        build a dictionary of categories.
        For each row, the entire text string appearing in the input column is defined as a category.
        The output of this transform is an indicator vector.
        Each slot in this vector corresponds to a category in the dictionary, so its length is the size of the built dictionary.
        The CategoricalOneHotVectorizer can be applied to one or more columns, in which case it builds and uses a separate dictionary
        for each column that it is applied to.</para>
        
        <para>The <see cref="Microsoft.ML.Runtime.Data.CategoricalTransform.OutputKind"/> produces integer values and <see cref="KeyType"/> columns.
        The Key value is the one-based index of the slot set in the Ind/Bag options.
        If the Key option is not found, it is assigned the value zero.
        In the <see cref="CategoricalTransform.OutputKind.Ind"/>, <see cref="CategoricalTransform.OutputKind.Bag"/> options are not found, they result in an all zero bit vector.
        <see cref="CategoricalTransform.OutputKind.Ind"/> and <see cref="CategoricalTransform.OutputKind.Bag"/> differ simply in how the bit-vectors generated from individual slots are aggregated:
        for Ind they are concatenated and for Bag they are added.
        When the source column is a singleton, the Ind and Bag options are identical.</para>
      </remarks>
      <example>
        An example of how to add the CategoricalOneHotVectorizer transform to a pipeline with two text column 
        features named &quot;Text1&quot; and &quot;Text2&quot;.
        <code>
          pipeline.Add(new CategoricalOneHotVectorizer(&quot;Text1&quot;, &quot;Text1&quot;));
        </code>
      </example>
    </member>

    <member name="CountFeatureSelection">
      <summary>
        Selects the slots for which the count of non-default values is greater than or equal to a threshold.
      </summary>
      <remarks>
        <para>
          This transform uses a set of aggregators to count the number of non-default values for each slot and
          instantiates a <see cref="Microsoft.ML.Runtime.Data.DropSlotsTramsform"/> to actually drop the slots.
          This transform is useful when applied together with a <see cref="Microsoft.ML.Transforms.CategoricalHashOneHotVectorizer"/>. 
          The count feature selection can remove those features generated by the hash transform that have no data in the examples.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new FeatureSelectorByCount() { Column = new[]{ &quot;Feature1&quot; }, Count = 2 });
        </code>
      </example>
    </member>

    <member name="MutualInformationFeatureSelection">
      <summary>
        Selects the top k slots across all specified columns ordered by their mutual information with the label column.
      </summary>
      <remarks>
        <para>
          The mutual information of two random variables X and Y is a measure of the mutual dependence between the variables.
          Formally, the mutual information can be written as:
        </para>
          <para>I(X;Y) = E[log(p(x,y)) - log(p(x)) - log(p(y))]</para>
        <para>where the expectation is taken over the joint distribution of X and Y. 
        Here p(x,y) is the joint probability density function of X and Y, p(x) and p(y) are the marginal probability density functions of X and Y respectively. 
        In general, a higher mutual information between the dependent variable (or label) and an independent variable (or feature) means 
        that the label has higher mutual dependence over that feature.
        The mutual information feature selection mode selects the features based on the mutual information. 
        It keeps the top SlotsInOutput features with the largest mutual information with the label.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new FeatureSelectorByMutualInformation() { Column = new[]{ &quot;Feature1&quot; }, SlotsInOutput = 6 });
        </code>
      </example>
    </member>

    <member name="MutualInformationFeatureSelection">
      <summary>
        Selects the top k slots across all specified columns ordered by their mutual information with the label column.
      </summary>
      <remarks>
        <para>
          The mutual information of two random variables X and Y is a measure of the mutual dependence between the variables.
          Formally, the mutual information can be written as:
        </para>
        <para>I(X;Y) = E[log(p(x,y)) - log(p(x)) - log(p(y))]</para>
        <para>
          where the expectation is taken over the joint distribution of X and Y.
          Here p(x,y) is the joint probability density function of X and Y, p(x) and p(y) are the marginal probability density functions of X and Y respectively.
          In general, a higher mutual information between the dependent variable (or label) and an independent variable (or feature) means
          that the label has higher mutual dependence over that feature.
          The mutual information feature selection mode selects the features based on the mutual information.
          It keeps the top SlotsInOutput features with the largest mutual information with the label.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new FeatureSelectorByMutualInformation() { Column = new[]{ &quot;Feature1&quot;}, SlotsInOutput = 6 });
        </code>
      </example>
    </member>

    <member name="OptionalColumnTransform">
      <summary>
        If the user wish to create additional columns with a particular type and default values, 
        or replicated the values from one column to another, changing their type, they can do so using this transform. 
        This transform can be used as a workaround to create a Label column after deserializing a model, for prediction. 
        Some transforms in the serialized model operate on the Label column, and would throw errors during prediction if such a column is not found. 
      </summary>
      <remarks>        
      </remarks>
      <example>
        <code>
          pipeline.Add(new OptionalColumnCreator() { Column = new[]{ &quot;OptColumn&quot;} });
        </code>
      </example>
    </member>

    <member name="HashJoin">
      <summary>
        Converts multiple column values into hashes. 
        This transform accepts both numeric and text inputs, both single and vector-valued columns. 
      </summary>
      <remarks>
        This transform can be helpful for ranking and cross-validation. In the case of ranking, where the GroupIdColumn column is required,
        and needs to be of a key type you can use the CategoricalHashOneHotVectorizer to hash the text value of a single GroupID column into a key value.
        If the GroupID is the combination of the values from multiple columns, you can use the HashConverter to hash multiple text columns into one key column. 
        Similarly with CrossValidator and the StratificationColumn. 
      </remarks>
      <example>
        <code>
          pipeline.Add(new HashConverter(&quot;Column1&quot;, &quot;Column2&quot;));
        </code>
      </example>
    </member>

    <member name="NADrop">
      <summary>
        Removes missing values from vector type columns.
      </summary>
      <seealso cref="Microsoft.ML.Runtime.Data.MetadataUtils.Kinds.HasMissingValues"></seealso>
      <example>
        <code>
          pipeline.Add(new MissingValuesDropper(&quot;Column1&quot;));
        </code>
      </example>
    </member>


    <member name="NAIndicator">
      <summary>
        This transform can transform either scalars or vectors (both fixed and variable size),
        creating output columns that indicate, through the true/false booleans whether the row has a missing value.
      </summary>
      <seealso cref=" Microsoft.ML.Runtime.Data.MetadataUtils.Kinds.HasMissingValues"></seealso>
      <example>
        <code>
          pipeline.Add(new MissingValueIndicator(&quot;Column1&quot;));
        </code>
      </example>
    </member>
  
  </members>
</docs>