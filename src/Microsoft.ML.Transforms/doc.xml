<?xml version="1.0" encoding="utf-8"?>
<doc>
  <members>

    <member name="CategoricalHashOneHotVectorizer">
      <summary>
        Encodes the categorical variable with hash-based encoding. 
      </summary>
      <remarks>
        CategoricalHashOneHotVectorizer converts a categorical value into an indicator array by hashing the
        value and using the hash as an index in the bag.
        If the input column is a vector, a single indicator bag is returned for it.
      </remarks>
      <example>
        <code>
          pipeline.Add(new CategoricalHashOneHotVectorizer(&quot;Text1&quot;) { HashBits = 10, Seed = 314489979, OutputKind = CategoricalTransformOutputKind.Bag });
        </code>
      </example>
    </member>

    <member name="CategoricalOneHotVectorizer">
      <summary>
        Converts the categorical value into an indicator array by building a dictionary of categories based on the data and using the id in the dictionary as the index in the array
      </summary>
      <remarks>
        <para>The CategoricalOneHotVectorizer transform passes through a data set, operating on text columns, to
        build a dictionary of categories.
        For each row, the entire text string appearing in the input column is defined as a category.
        The output of this transform is an indicator vector.
        Each slot in this vector corresponds to a category in the dictionary, so its length is the size of the built dictionary.
        The CategoricalOneHotVectorizer can be applied to one or more columns, in which case it builds and uses a separate dictionary
        for each column that it is applied to.</para>
        
        <para>The <see cref="Microsoft.ML.Runtime.Data.CategoricalTransform.OutputKind"/> produces integer values and <see cref="KeyType"/> columns.
        The Key value is the one-based index of the slot set in the Ind/Bag options.
        If the Key option is not found, it is assigned the value zero.
        In the <see cref="CategoricalTransform.OutputKind.Ind"/>, <see cref="CategoricalTransform.OutputKind.Bag"/> options are not found, they result in an all zero bit vector.
        <see cref="CategoricalTransform.OutputKind.Ind"/> and <see cref="CategoricalTransform.OutputKind.Bag"/> differ simply in how the bit-vectors generated from individual slots are aggregated:
        for Ind they are concatenated and for Bag they are added.
        When the source column is a singleton, the Ind and Bag options are identical.</para>
      </remarks>
      <example>
        An example of how to add the CategoricalOneHotVectorizer transform to a pipeline with two text column 
        features named &quot;Text1&quot; and &quot;Text2&quot;.
        <code>
          pipeline.Add(new CategoricalOneHotVectorizer(&quot;Text1&quot;, &quot;Text1&quot;));
        </code>
      </example>
    </member>

    <member name="CountFeatureSelection">
      <summary>
        Selects the slots for which the count of non-default values is greater than or equal to a threshold.
      </summary>
      <remarks>
        <para>
          This transform uses a set of aggregators to count the number of non-default values for each slot and
          instantiates a <see cref="Microsoft.ML.Runtime.Data.DropSlotsTransform"/> to actually drop the slots.
          This transform is useful when applied together with a CategoricalHashOneHotVectorizer. 
          The count feature selection can remove those features generated by the hash transform that have no data in the examples.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new FeatureSelectorByCount() { Column = new[]{ &quot;Feature1&quot; }, Count = 2 });
        </code>
      </example>
    </member>

    <member name="MutualInformationFeatureSelection">
      <summary>
        Selects the top k slots across all specified columns ordered by their mutual information with the label column.
      </summary>
      <remarks>
        <para>
          The mutual information of two random variables X and Y is a measure of the mutual dependence between the variables.
          Formally, the mutual information can be written as:
        </para>
          <para>I(X;Y) = E[log(p(x,y)) - log(p(x)) - log(p(y))]</para>
        <para>where the expectation is taken over the joint distribution of X and Y. 
        Here p(x,y) is the joint probability density function of X and Y, p(x) and p(y) are the marginal probability density functions of X and Y respectively. 
        In general, a higher mutual information between the dependent variable (or label) and an independent variable (or feature) means 
        that the label has higher mutual dependence over that feature.
        The mutual information feature selection mode selects the features based on the mutual information. 
        It keeps the top SlotsInOutput features with the largest mutual information with the label.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new FeatureSelectorByMutualInformation() { Column = new[]{ &quot;Feature1&quot; }, SlotsInOutput = 6 });
        </code>
      </example>
    </member>

    <member name="MutualInformationFeatureSelection">
      <summary>
        Selects the top k slots across all specified columns ordered by their mutual information with the label column.
      </summary>
      <remarks>
        <para>
          The mutual information of two random variables X and Y is a measure of the mutual dependence between the variables.
          Formally, the mutual information can be written as:
        </para>
        <para>I(X;Y) = E[log(p(x,y)) - log(p(x)) - log(p(y))]</para>
        <para>
          where the expectation is taken over the joint distribution of X and Y.
          Here p(x,y) is the joint probability density function of X and Y, p(x) and p(y) are the marginal probability density functions of X and Y respectively.
          In general, a higher mutual information between the dependent variable (or label) and an independent variable (or feature) means
          that the label has higher mutual dependence over that feature.
          The mutual information feature selection mode selects the features based on the mutual information.
          It keeps the top SlotsInOutput features with the largest mutual information with the label.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new FeatureSelectorByMutualInformation() { Column = new[]{ &quot;Feature1&quot;}, SlotsInOutput = 6 });
        </code>
      </example>
    </member>

    <member name="OptionalColumnTransform">
      <summary>
        If the user wish to create additional columns with a particular type and default values, 
        or replicated the values from one column to another, changing their type, they can do so using this transform. 
        This transform can be used as a workaround to create a Label column after deserializing a model, for prediction. 
        Some transforms in the serialized model operate on the Label column, and would throw errors during prediction if such a column is not found. 
      </summary>
      <remarks>        
      </remarks>
      <example>
        <code>
          pipeline.Add(new OptionalColumnCreator() { Column = new[]{ &quot;OptColumn&quot;} });
        </code>
      </example>
    </member>

    <member name="HashJoin">
      <summary>
        Converts multiple column values into hashes. 
        This transform accepts both numeric and text inputs, both single and vector-valued columns. 
      </summary>
      <remarks>
        This transform can be helpful for ranking and cross-validation. In the case of ranking, where the GroupIdColumn column is required,
        and needs to be of a key type you can use the CategoricalHashOneHotVectorizer to hash the text value of a single GroupID column into a key value.
        If the GroupID is the combination of the values from multiple columns, you can use the HashConverter to hash multiple text columns into one key column. 
        Similarly with CrossValidator and the StratificationColumn. 
      </remarks>
      <example>
        <code>
          pipeline.Add(new HashConverter(&quot;Column1&quot;, &quot;Column2&quot;));
        </code>
      </example>
    </member>

    <member name="NADrop">
      <summary>
        Removes missing values from vector type columns.
      </summary>
      <seealso cref="Microsoft.ML.Runtime.Data.MetadataUtils.Kinds.HasMissingValues"></seealso>
      <example>
        <code>
          pipeline.Add(new MissingValuesDropper(&quot;Column1&quot;));
        </code>
      </example>
    </member>

    <member name="NAIndicator">
      <summary>
        This transform can transform either scalars or vectors (both fixed and variable size),
        creating output columns that indicate, through the true/false booleans whether the row has a missing value.
      </summary>
      <seealso cref=" Microsoft.ML.Runtime.Data.MetadataUtils.Kinds.HasMissingValues"></seealso>
      <example>
        <code>
          pipeline.Add(new MissingValueIndicator(&quot;Column1&quot;));
        </code>
      </example>
    </member>
    
    <member name="NAReplace">
      <summary>
        Create an output column of the same type and size of the input column, 
        where missing values are replaced with either the default value or the mean/min/max value (for non-text columns only). 
      </summary>
      <remarks>
        This transform can transform either scalars or vectors (both fixed and variable size),
        creating output columns that are identical to the input columns except for replacing NA values
        with either the default value, user input, or imputed values (min/max/mean are currently supported).
        Imputation modes are supported for vectors both by slot and across all slots.
      </remarks>
      <seealso cref=" Microsoft.ML.Runtime.Data.MetadataUtils.Kinds.HasMissingValues"></seealso>
      <example>
        <code>
          pipeline.Add(new MissingValueSubstitutor(&quot;FeatureCol&quot;){ ReplacementKind = NAReplaceTransformReplacementKind.Mean });
        </code>
      </example>
    </member>
    
    <member name="LpNormalize">
      <summary>
         The LpNormalizer transforms, normalizes vectors (rows) individually by rescaling them to unit norm (L2, L1 or LInf). 
         <para>Performs the following operation on a vector X:</para> 
         <para>Y = (X - M) / D</para> 
         <para>where M is mean and D is either L2 norm, L1 norm or LInf norm.</para>
       </summary>
      <remarks>
        Scaling inputs to unit norms is a common operation for text classification or clustering.
        For more information see: <a href="http://www.cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf"></a>
      </remarks>
      <seealso cref=" Microsoft.ML.Transforms.GcNormalize"></seealso>
      <example>
        <code>
          pipeline.Add(new LpNormalizer("FeatureCol"){ NormKind = LpNormNormalizerTransformNormalizerKind.L1Norm});
        </code>
      </example>
    </member>
    
  <member name="GcNormalize">
      <summary>
        <para>Performs a global contrast normalization on input values:</para>
        <para>Y = (s * X - M) / D</para> 
        <para>where s is a scale, M is mean and D is either the L2 norm or standard deviation.</para>
       </summary>
      <remarks>
        Scaling inputs to unit norms is a common operation for text classification or clustering.
        For more information see: <a href="http://www.cs.stanford.edu/~acoates/papers/coatesleeng_aistats_2011.pdf"></a>
      </remarks>
      <seealso cref=" Microsoft.ML.Transforms.LpNormalizer"></seealso>
      <example>
        <code>
          pipeline.Add(new GlobalContrastNormalizer(&quot;FeatureCol&quot;){ SubMean= false });
        </code>
      </example>
    </member>
    
  <member name="Ungroup">
      <summary>
        Un-groups vector columns into sequences of rows, inverse of Group transform.
       </summary>
      <remarks>
        <para>This can be thought of as an inverse of the CombinerByContiguousGroupId. 
        For all specified vector columns ("pivot" columns), performs the "ungroup" (or "unroll") operation as outlined below.
        </para>
        <para>If the only pivot column is called P, and has size K, then for every row of the input we will produce 
         K rows, that are identical in all columns except P. The column P will become a scalar column, and this 
         column will hold all the original values of input's P, one value per row, in order. The order of columns 
         will remain the same.
        </para>
        <para>Variable-length pivot columns are supported (including zero, which will eliminate the row from the result).</para>
        <para>Multiple pivot columns are also supported:</para>
        <list type="bullet">
          <item>
            <description>A number of output rows is controlled by the 'mode' parameter. 
            <list type="bullet">
              <item>
                <description>outer: it is equal to the maximum length of pivot columns</description>
                <description>inner: it is equal to the minimum length of pivot columns</description>
                <description>first: it is equal to the length of the first pivot column</description>
              </item>
            </list>
            </description>
          </item>
          <item>
            <description>
              If a particular pivot column has size that is different than the number of output rows, the extra slots will
              be ignored, and the missing slots will be 'padded' with default values.
            </description>
          </item>
        </list>
        <para>All metadata is preserved for the retained columns. For 'unrolled' columns, all known metadata
        except slot names is preserved.
        </para>
      </remarks>
      <example>
        <code>
          pipeline.Add(new Segregator(){ Column = new[]{&quot;Column1&quot; }, Mode = UngroupTransformUngroupMode.First} );
        </code>
      </example>
    </member>
    
    <member name="TextToKey">
      <summary>
       Converts input values (words, numbers, etc.) to index in a dictionary.
      </summary>
      <remarks>
      The TextToKeyConverter transform builds up term vocabularies (dictionaries).
      The TextToKey Converter and the <see cref="Microsoft.ML.Transforms.HashConverter"/> are the two one primary mechanisms by which raw input is transformed into keys. 
      If multiple columns are used, each column builds/uses exactly one vocabulary (dictionary).
      The output columns are KeyType-valued.
      The Key value is the one-based index of the item in the dictionary.
      If the key is not found in the dictionary, it is assigned the missing value indicator.
      This dictionary mapping values to keys is most commonly learnt from the unique values in input data, 
      but can be defined through other means: either with the mapping defined directly on the command line, or as loaded from an external file.
      </remarks>
      <seealso cref="Microsoft.ML.Transforms.HashConverter"/>
      <seealso cref="Microsoft.ML.Transforms.KeyToTextConverter"/>
      <example>
        <code>
          pipeline.Add(new TextToKeyConverter((&quot;Column&quot;, &quot;OutColumn&quot;)){ Sort = TermTransformSortOrder.Occurrence });
        </code>
      </example>
    </member>
    
    <member name="KeyToText">
      <summary>
       The KeyToValueTransform utilizes KeyValues metadata to map key indices to the corresponding values in the 
       KeyValues metadata.
      </summary>
      <remarks>
        The KeyToTextConverter is the complement of the <see  cref="TextToKeyConverter"/> transform. 
        Since key values are an enumeration into the set of keys, most transforms that produce key valued outputs 
        corresponding to input values will often, wherever possible, associate a piece of KeyValue metadata with that dataset.
        Transforming values into a categorical variable would be of limited use, 
        if we couldn't somehow backtrack to figure out what those categories actually mean. 
        The KeyToTextConverter enables that functionality. 
      </remarks>
      <seealso cref="Microsoft.ML.Transforms.HashConverter"/>
      <seealso cref="Microsoft.ML.Transforms.TextToKeyConverter"/>
      <example>
        <code>
          pipeline.Add(new KeyToTextConverter((&quot;InColumn&quot;, &quot;OutColumn&quot; )));
        </code>
      </example>
    </member>
    
    <member name="Group">
      <summary>
       Groups values of a scalar column into a vector, by a contiguous group ID.
      </summary>
      <remarks>
       The CombinerByContiguousGroupId transform groups the consecutive rows that share the specified group key (or keys). 
       Both group keys and the aggregated values can be of arbitrary non-vector types. 
       The resulting data will have all the group key columns preserved, 
       and the aggregated columns will become variable-length vectors of the original types.
       <para>This transform essentially performs the following SQL-like operation:</para> 
       <para>GroupKey1, GroupKey2, ... GroupKeyK, LIST(Value1), LIST(Value2), ... LIST(ValueN)</para> 
       <para>FROM Data</para> 
       <para>GROUP BY GroupKey1, GroupKey2, ... GroupKeyK.</para> 
      </remarks>
       <seealso cref="Microsoft.ML.Transforms.Segregator"/>
      <example>
        <code>
          pipeline.Add(new CombinerByContiguousGroupId(){ GroupKey = new []{"Key1", "Key2" } } );
        </code>
      </example>
    </member>
    
  </members>
</doc>