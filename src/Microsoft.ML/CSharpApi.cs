//------------------------------------------------------------------------------
// <auto-generated>
//     This code was generated by a tool.
//
//     Changes to this file may cause incorrect behavior and will be lost if
//     the code is regenerated.
// </auto-generated>
//------------------------------------------------------------------------------
#pragma warning disable
using System.Collections.Generic;
using Microsoft.ML.Runtime;
using Microsoft.ML.Runtime.Data;
using Microsoft.ML.Runtime.EntryPoints;
using Newtonsoft.Json;
using System;
using System.Linq;
using Microsoft.ML.Runtime.CommandLine;

namespace Microsoft.ML
{
    namespace Runtime
    {
        public sealed partial class Experiment
        {
            public Microsoft.ML.Data.CustomTextLoader.Output Add(Microsoft.ML.Data.CustomTextLoader input)
            {
                var output = new Microsoft.ML.Data.CustomTextLoader.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Data.CustomTextLoader input, Microsoft.ML.Data.CustomTextLoader.Output output)
            {
                _jsonNodes.Add(Serialize("Data.CustomTextLoader", input, output));
            }

            public Microsoft.ML.Data.IDataViewArrayConverter.Output Add(Microsoft.ML.Data.IDataViewArrayConverter input)
            {
                var output = new Microsoft.ML.Data.IDataViewArrayConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Data.IDataViewArrayConverter input, Microsoft.ML.Data.IDataViewArrayConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Data.IDataViewArrayConverter", input, output));
            }

            public Microsoft.ML.Data.PredictorModelArrayConverter.Output Add(Microsoft.ML.Data.PredictorModelArrayConverter input)
            {
                var output = new Microsoft.ML.Data.PredictorModelArrayConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Data.PredictorModelArrayConverter input, Microsoft.ML.Data.PredictorModelArrayConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Data.PredictorModelArrayConverter", input, output));
            }

            public Microsoft.ML.Data.TextLoader.Output Add(Microsoft.ML.Data.TextLoader input)
            {
                var output = new Microsoft.ML.Data.TextLoader.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Data.TextLoader input, Microsoft.ML.Data.TextLoader.Output output)
            {
                _jsonNodes.Add(Serialize("Data.TextLoader", input, output));
            }

            public Microsoft.ML.Models.AnomalyDetectionEvaluator.Output Add(Microsoft.ML.Models.AnomalyDetectionEvaluator input)
            {
                var output = new Microsoft.ML.Models.AnomalyDetectionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.AnomalyDetectionEvaluator input, Microsoft.ML.Models.AnomalyDetectionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.AnomalyDetectionEvaluator", input, output));
            }

            public Microsoft.ML.Models.BinaryClassificationEvaluator.Output Add(Microsoft.ML.Models.BinaryClassificationEvaluator input)
            {
                var output = new Microsoft.ML.Models.BinaryClassificationEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.BinaryClassificationEvaluator input, Microsoft.ML.Models.BinaryClassificationEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.BinaryClassificationEvaluator", input, output));
            }

            public Microsoft.ML.Models.BinaryCrossValidator.Output Add(Microsoft.ML.Models.BinaryCrossValidator input)
            {
                var output = new Microsoft.ML.Models.BinaryCrossValidator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.BinaryCrossValidator input, Microsoft.ML.Models.BinaryCrossValidator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.BinaryCrossValidator", input, output));
            }

            public Microsoft.ML.Models.ClassificationEvaluator.Output Add(Microsoft.ML.Models.ClassificationEvaluator input)
            {
                var output = new Microsoft.ML.Models.ClassificationEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.ClassificationEvaluator input, Microsoft.ML.Models.ClassificationEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.ClassificationEvaluator", input, output));
            }

            public Microsoft.ML.Models.ClusterEvaluator.Output Add(Microsoft.ML.Models.ClusterEvaluator input)
            {
                var output = new Microsoft.ML.Models.ClusterEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.ClusterEvaluator input, Microsoft.ML.Models.ClusterEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.ClusterEvaluator", input, output));
            }

            public Microsoft.ML.Models.CrossValidator.Output Add(Microsoft.ML.Models.CrossValidator input)
            {
                var output = new Microsoft.ML.Models.CrossValidator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.CrossValidator input, Microsoft.ML.Models.CrossValidator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.CrossValidator", input, output));
            }

            public Microsoft.ML.Models.CrossValidatorDatasetSplitter.Output Add(Microsoft.ML.Models.CrossValidatorDatasetSplitter input)
            {
                var output = new Microsoft.ML.Models.CrossValidatorDatasetSplitter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.CrossValidatorDatasetSplitter input, Microsoft.ML.Models.CrossValidatorDatasetSplitter.Output output)
            {
                _jsonNodes.Add(Serialize("Models.CrossValidatorDatasetSplitter", input, output));
            }

            public Microsoft.ML.Models.DatasetTransformer.Output Add(Microsoft.ML.Models.DatasetTransformer input)
            {
                var output = new Microsoft.ML.Models.DatasetTransformer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.DatasetTransformer input, Microsoft.ML.Models.DatasetTransformer.Output output)
            {
                _jsonNodes.Add(Serialize("Models.DatasetTransformer", input, output));
            }

            public Microsoft.ML.Models.FixedPlattCalibrator.Output Add(Microsoft.ML.Models.FixedPlattCalibrator input)
            {
                var output = new Microsoft.ML.Models.FixedPlattCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.FixedPlattCalibrator input, Microsoft.ML.Models.FixedPlattCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.FixedPlattCalibrator", input, output));
            }

            public Microsoft.ML.Models.MultiOutputRegressionEvaluator.Output Add(Microsoft.ML.Models.MultiOutputRegressionEvaluator input)
            {
                var output = new Microsoft.ML.Models.MultiOutputRegressionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.MultiOutputRegressionEvaluator input, Microsoft.ML.Models.MultiOutputRegressionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.MultiOutputRegressionEvaluator", input, output));
            }

            public Microsoft.ML.Models.NaiveCalibrator.Output Add(Microsoft.ML.Models.NaiveCalibrator input)
            {
                var output = new Microsoft.ML.Models.NaiveCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.NaiveCalibrator input, Microsoft.ML.Models.NaiveCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.NaiveCalibrator", input, output));
            }

            public Microsoft.ML.Models.OneVersusAll.Output Add(Microsoft.ML.Models.OneVersusAll input)
            {
                var output = new Microsoft.ML.Models.OneVersusAll.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.OneVersusAll input, Microsoft.ML.Models.OneVersusAll.Output output)
            {
                _jsonNodes.Add(Serialize("Models.OneVersusAll", input, output));
            }

            public Microsoft.ML.Models.OvaModelCombiner.Output Add(Microsoft.ML.Models.OvaModelCombiner input)
            {
                var output = new Microsoft.ML.Models.OvaModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.OvaModelCombiner input, Microsoft.ML.Models.OvaModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Models.OvaModelCombiner", input, output));
            }

            public Microsoft.ML.Models.PAVCalibrator.Output Add(Microsoft.ML.Models.PAVCalibrator input)
            {
                var output = new Microsoft.ML.Models.PAVCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.PAVCalibrator input, Microsoft.ML.Models.PAVCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.PAVCalibrator", input, output));
            }

            public Microsoft.ML.Models.PlattCalibrator.Output Add(Microsoft.ML.Models.PlattCalibrator input)
            {
                var output = new Microsoft.ML.Models.PlattCalibrator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.PlattCalibrator input, Microsoft.ML.Models.PlattCalibrator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.PlattCalibrator", input, output));
            }

            public Microsoft.ML.Models.QuantileRegressionEvaluator.Output Add(Microsoft.ML.Models.QuantileRegressionEvaluator input)
            {
                var output = new Microsoft.ML.Models.QuantileRegressionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.QuantileRegressionEvaluator input, Microsoft.ML.Models.QuantileRegressionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.QuantileRegressionEvaluator", input, output));
            }

            public Microsoft.ML.Models.RankerEvaluator.Output Add(Microsoft.ML.Models.RankerEvaluator input)
            {
                var output = new Microsoft.ML.Models.RankerEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.RankerEvaluator input, Microsoft.ML.Models.RankerEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.RankerEvaluator", input, output));
            }

            public Microsoft.ML.Models.RegressionEvaluator.Output Add(Microsoft.ML.Models.RegressionEvaluator input)
            {
                var output = new Microsoft.ML.Models.RegressionEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.RegressionEvaluator input, Microsoft.ML.Models.RegressionEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.RegressionEvaluator", input, output));
            }

            public Microsoft.ML.Models.Summarizer.Output Add(Microsoft.ML.Models.Summarizer input)
            {
                var output = new Microsoft.ML.Models.Summarizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.Summarizer input, Microsoft.ML.Models.Summarizer.Output output)
            {
                _jsonNodes.Add(Serialize("Models.Summarizer", input, output));
            }

            public Microsoft.ML.Models.TrainTestBinaryEvaluator.Output Add(Microsoft.ML.Models.TrainTestBinaryEvaluator input)
            {
                var output = new Microsoft.ML.Models.TrainTestBinaryEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.TrainTestBinaryEvaluator input, Microsoft.ML.Models.TrainTestBinaryEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.TrainTestBinaryEvaluator", input, output));
            }

            public Microsoft.ML.Models.TrainTestEvaluator.Output Add(Microsoft.ML.Models.TrainTestEvaluator input)
            {
                var output = new Microsoft.ML.Models.TrainTestEvaluator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Models.TrainTestEvaluator input, Microsoft.ML.Models.TrainTestEvaluator.Output output)
            {
                _jsonNodes.Add(Serialize("Models.TrainTestEvaluator", input, output));
            }

            public Microsoft.ML.Trainers.AveragedPerceptronBinaryClassifier.Output Add(Microsoft.ML.Trainers.AveragedPerceptronBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.AveragedPerceptronBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.AveragedPerceptronBinaryClassifier input, Microsoft.ML.Trainers.AveragedPerceptronBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.AveragedPerceptronBinaryClassifier", input, output));
            }

            public Microsoft.ML.Trainers.BinaryLogisticRegressor.Output Add(Microsoft.ML.Trainers.BinaryLogisticRegressor input)
            {
                var output = new Microsoft.ML.Trainers.BinaryLogisticRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.BinaryLogisticRegressor input, Microsoft.ML.Trainers.BinaryLogisticRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.BinaryLogisticRegressor", input, output));
            }

            public Microsoft.ML.Trainers.FastForestBinaryClassifier.Output Add(Microsoft.ML.Trainers.FastForestBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.FastForestBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.FastForestBinaryClassifier input, Microsoft.ML.Trainers.FastForestBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastForestBinaryClassifier", input, output));
            }

            public Microsoft.ML.Trainers.FastForestRegressor.Output Add(Microsoft.ML.Trainers.FastForestRegressor input)
            {
                var output = new Microsoft.ML.Trainers.FastForestRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.FastForestRegressor input, Microsoft.ML.Trainers.FastForestRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastForestRegressor", input, output));
            }

            public Microsoft.ML.Trainers.FastTreeBinaryClassifier.Output Add(Microsoft.ML.Trainers.FastTreeBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.FastTreeBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.FastTreeBinaryClassifier input, Microsoft.ML.Trainers.FastTreeBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeBinaryClassifier", input, output));
            }

            public Microsoft.ML.Trainers.FastTreeRanker.Output Add(Microsoft.ML.Trainers.FastTreeRanker input)
            {
                var output = new Microsoft.ML.Trainers.FastTreeRanker.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.FastTreeRanker input, Microsoft.ML.Trainers.FastTreeRanker.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeRanker", input, output));
            }

            public Microsoft.ML.Trainers.FastTreeRegressor.Output Add(Microsoft.ML.Trainers.FastTreeRegressor input)
            {
                var output = new Microsoft.ML.Trainers.FastTreeRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.FastTreeRegressor input, Microsoft.ML.Trainers.FastTreeRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeRegressor", input, output));
            }

            public Microsoft.ML.Trainers.FastTreeTweedieRegressor.Output Add(Microsoft.ML.Trainers.FastTreeTweedieRegressor input)
            {
                var output = new Microsoft.ML.Trainers.FastTreeTweedieRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.FastTreeTweedieRegressor input, Microsoft.ML.Trainers.FastTreeTweedieRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.FastTreeTweedieRegressor", input, output));
            }

            public Microsoft.ML.Trainers.GeneralizedAdditiveModelBinaryClassifier.Output Add(Microsoft.ML.Trainers.GeneralizedAdditiveModelBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.GeneralizedAdditiveModelBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.GeneralizedAdditiveModelBinaryClassifier input, Microsoft.ML.Trainers.GeneralizedAdditiveModelBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.GeneralizedAdditiveModelBinaryClassifier", input, output));
            }

            public Microsoft.ML.Trainers.GeneralizedAdditiveModelRegressor.Output Add(Microsoft.ML.Trainers.GeneralizedAdditiveModelRegressor input)
            {
                var output = new Microsoft.ML.Trainers.GeneralizedAdditiveModelRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.GeneralizedAdditiveModelRegressor input, Microsoft.ML.Trainers.GeneralizedAdditiveModelRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.GeneralizedAdditiveModelRegressor", input, output));
            }

            public Microsoft.ML.Trainers.LinearSvmBinaryClassifier.Output Add(Microsoft.ML.Trainers.LinearSvmBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.LinearSvmBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.LinearSvmBinaryClassifier input, Microsoft.ML.Trainers.LinearSvmBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LinearSvmBinaryClassifier", input, output));
            }

            public Microsoft.ML.Trainers.LogisticRegressor.Output Add(Microsoft.ML.Trainers.LogisticRegressor input)
            {
                var output = new Microsoft.ML.Trainers.LogisticRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.LogisticRegressor input, Microsoft.ML.Trainers.LogisticRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.LogisticRegressor", input, output));
            }

            public Microsoft.ML.Trainers.NaiveBayesClassifier.Output Add(Microsoft.ML.Trainers.NaiveBayesClassifier input)
            {
                var output = new Microsoft.ML.Trainers.NaiveBayesClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.NaiveBayesClassifier input, Microsoft.ML.Trainers.NaiveBayesClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.NaiveBayesClassifier", input, output));
            }

            public Microsoft.ML.Trainers.OnlineGradientDescentRegressor.Output Add(Microsoft.ML.Trainers.OnlineGradientDescentRegressor input)
            {
                var output = new Microsoft.ML.Trainers.OnlineGradientDescentRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.OnlineGradientDescentRegressor input, Microsoft.ML.Trainers.OnlineGradientDescentRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.OnlineGradientDescentRegressor", input, output));
            }

            public Microsoft.ML.Trainers.OrdinaryLeastSquaresRegressor.Output Add(Microsoft.ML.Trainers.OrdinaryLeastSquaresRegressor input)
            {
                var output = new Microsoft.ML.Trainers.OrdinaryLeastSquaresRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.OrdinaryLeastSquaresRegressor input, Microsoft.ML.Trainers.OrdinaryLeastSquaresRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.OrdinaryLeastSquaresRegressor", input, output));
            }

            public Microsoft.ML.Trainers.PoissonRegressor.Output Add(Microsoft.ML.Trainers.PoissonRegressor input)
            {
                var output = new Microsoft.ML.Trainers.PoissonRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.PoissonRegressor input, Microsoft.ML.Trainers.PoissonRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.PoissonRegressor", input, output));
            }

            public Microsoft.ML.Trainers.StochasticDualCoordinateAscentBinaryClassifier.Output Add(Microsoft.ML.Trainers.StochasticDualCoordinateAscentBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.StochasticDualCoordinateAscentBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.StochasticDualCoordinateAscentBinaryClassifier input, Microsoft.ML.Trainers.StochasticDualCoordinateAscentBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticDualCoordinateAscentBinaryClassifier", input, output));
            }

            public Microsoft.ML.Trainers.StochasticDualCoordinateAscentClassifier.Output Add(Microsoft.ML.Trainers.StochasticDualCoordinateAscentClassifier input)
            {
                var output = new Microsoft.ML.Trainers.StochasticDualCoordinateAscentClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.StochasticDualCoordinateAscentClassifier input, Microsoft.ML.Trainers.StochasticDualCoordinateAscentClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticDualCoordinateAscentClassifier", input, output));
            }

            public Microsoft.ML.Trainers.StochasticDualCoordinateAscentRegressor.Output Add(Microsoft.ML.Trainers.StochasticDualCoordinateAscentRegressor input)
            {
                var output = new Microsoft.ML.Trainers.StochasticDualCoordinateAscentRegressor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.StochasticDualCoordinateAscentRegressor input, Microsoft.ML.Trainers.StochasticDualCoordinateAscentRegressor.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticDualCoordinateAscentRegressor", input, output));
            }

            public Microsoft.ML.Trainers.StochasticGradientDescentBinaryClassifier.Output Add(Microsoft.ML.Trainers.StochasticGradientDescentBinaryClassifier input)
            {
                var output = new Microsoft.ML.Trainers.StochasticGradientDescentBinaryClassifier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Trainers.StochasticGradientDescentBinaryClassifier input, Microsoft.ML.Trainers.StochasticGradientDescentBinaryClassifier.Output output)
            {
                _jsonNodes.Add(Serialize("Trainers.StochasticGradientDescentBinaryClassifier", input, output));
            }

            public Microsoft.ML.Transforms.ApproximateBootstrapSampler.Output Add(Microsoft.ML.Transforms.ApproximateBootstrapSampler input)
            {
                var output = new Microsoft.ML.Transforms.ApproximateBootstrapSampler.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ApproximateBootstrapSampler input, Microsoft.ML.Transforms.ApproximateBootstrapSampler.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ApproximateBootstrapSampler", input, output));
            }

            public Microsoft.ML.Transforms.BinaryPredictionScoreColumnsRenamer.Output Add(Microsoft.ML.Transforms.BinaryPredictionScoreColumnsRenamer input)
            {
                var output = new Microsoft.ML.Transforms.BinaryPredictionScoreColumnsRenamer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.BinaryPredictionScoreColumnsRenamer input, Microsoft.ML.Transforms.BinaryPredictionScoreColumnsRenamer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.BinaryPredictionScoreColumnsRenamer", input, output));
            }

            public Microsoft.ML.Transforms.BinNormalizer.Output Add(Microsoft.ML.Transforms.BinNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.BinNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.BinNormalizer input, Microsoft.ML.Transforms.BinNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.BinNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.CategoricalHashOneHotVectorizer.Output Add(Microsoft.ML.Transforms.CategoricalHashOneHotVectorizer input)
            {
                var output = new Microsoft.ML.Transforms.CategoricalHashOneHotVectorizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.CategoricalHashOneHotVectorizer input, Microsoft.ML.Transforms.CategoricalHashOneHotVectorizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CategoricalHashOneHotVectorizer", input, output));
            }

            public Microsoft.ML.Transforms.CategoricalOneHotVectorizer.Output Add(Microsoft.ML.Transforms.CategoricalOneHotVectorizer input)
            {
                var output = new Microsoft.ML.Transforms.CategoricalOneHotVectorizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.CategoricalOneHotVectorizer input, Microsoft.ML.Transforms.CategoricalOneHotVectorizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CategoricalOneHotVectorizer", input, output));
            }

            public Microsoft.ML.Transforms.CharacterTokenizer.Output Add(Microsoft.ML.Transforms.CharacterTokenizer input)
            {
                var output = new Microsoft.ML.Transforms.CharacterTokenizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.CharacterTokenizer input, Microsoft.ML.Transforms.CharacterTokenizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CharacterTokenizer", input, output));
            }

            public Microsoft.ML.Transforms.ColumnConcatenator.Output Add(Microsoft.ML.Transforms.ColumnConcatenator input)
            {
                var output = new Microsoft.ML.Transforms.ColumnConcatenator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ColumnConcatenator input, Microsoft.ML.Transforms.ColumnConcatenator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnConcatenator", input, output));
            }

            public Microsoft.ML.Transforms.ColumnCopier.Output Add(Microsoft.ML.Transforms.ColumnCopier input)
            {
                var output = new Microsoft.ML.Transforms.ColumnCopier.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ColumnCopier input, Microsoft.ML.Transforms.ColumnCopier.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnCopier", input, output));
            }

            public Microsoft.ML.Transforms.ColumnDropper.Output Add(Microsoft.ML.Transforms.ColumnDropper input)
            {
                var output = new Microsoft.ML.Transforms.ColumnDropper.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ColumnDropper input, Microsoft.ML.Transforms.ColumnDropper.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnDropper", input, output));
            }

            public Microsoft.ML.Transforms.ColumnSelector.Output Add(Microsoft.ML.Transforms.ColumnSelector input)
            {
                var output = new Microsoft.ML.Transforms.ColumnSelector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ColumnSelector input, Microsoft.ML.Transforms.ColumnSelector.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnSelector", input, output));
            }

            public Microsoft.ML.Transforms.ColumnTypeConverter.Output Add(Microsoft.ML.Transforms.ColumnTypeConverter input)
            {
                var output = new Microsoft.ML.Transforms.ColumnTypeConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ColumnTypeConverter input, Microsoft.ML.Transforms.ColumnTypeConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ColumnTypeConverter", input, output));
            }

            public Microsoft.ML.Transforms.CombinerByContiguousGroupId.Output Add(Microsoft.ML.Transforms.CombinerByContiguousGroupId input)
            {
                var output = new Microsoft.ML.Transforms.CombinerByContiguousGroupId.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.CombinerByContiguousGroupId input, Microsoft.ML.Transforms.CombinerByContiguousGroupId.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.CombinerByContiguousGroupId", input, output));
            }

            public Microsoft.ML.Transforms.ConditionalNormalizer.Output Add(Microsoft.ML.Transforms.ConditionalNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.ConditionalNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ConditionalNormalizer input, Microsoft.ML.Transforms.ConditionalNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ConditionalNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.DataCache.Output Add(Microsoft.ML.Transforms.DataCache input)
            {
                var output = new Microsoft.ML.Transforms.DataCache.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.DataCache input, Microsoft.ML.Transforms.DataCache.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.DataCache", input, output));
            }

            public Microsoft.ML.Transforms.DatasetScorer.Output Add(Microsoft.ML.Transforms.DatasetScorer input)
            {
                var output = new Microsoft.ML.Transforms.DatasetScorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.DatasetScorer input, Microsoft.ML.Transforms.DatasetScorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.DatasetScorer", input, output));
            }

            public Microsoft.ML.Transforms.DatasetTransformScorer.Output Add(Microsoft.ML.Transforms.DatasetTransformScorer input)
            {
                var output = new Microsoft.ML.Transforms.DatasetTransformScorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.DatasetTransformScorer input, Microsoft.ML.Transforms.DatasetTransformScorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.DatasetTransformScorer", input, output));
            }

            public Microsoft.ML.Transforms.Dictionarizer.Output Add(Microsoft.ML.Transforms.Dictionarizer input)
            {
                var output = new Microsoft.ML.Transforms.Dictionarizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.Dictionarizer input, Microsoft.ML.Transforms.Dictionarizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.Dictionarizer", input, output));
            }

            public Microsoft.ML.Transforms.FeatureCombiner.Output Add(Microsoft.ML.Transforms.FeatureCombiner input)
            {
                var output = new Microsoft.ML.Transforms.FeatureCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.FeatureCombiner input, Microsoft.ML.Transforms.FeatureCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.FeatureCombiner", input, output));
            }

            public Microsoft.ML.Transforms.FeatureSelectorByCount.Output Add(Microsoft.ML.Transforms.FeatureSelectorByCount input)
            {
                var output = new Microsoft.ML.Transforms.FeatureSelectorByCount.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.FeatureSelectorByCount input, Microsoft.ML.Transforms.FeatureSelectorByCount.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.FeatureSelectorByCount", input, output));
            }

            public Microsoft.ML.Transforms.FeatureSelectorByMutualInformation.Output Add(Microsoft.ML.Transforms.FeatureSelectorByMutualInformation input)
            {
                var output = new Microsoft.ML.Transforms.FeatureSelectorByMutualInformation.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.FeatureSelectorByMutualInformation input, Microsoft.ML.Transforms.FeatureSelectorByMutualInformation.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.FeatureSelectorByMutualInformation", input, output));
            }

            public Microsoft.ML.Transforms.GlobalContrastNormalizer.Output Add(Microsoft.ML.Transforms.GlobalContrastNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.GlobalContrastNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.GlobalContrastNormalizer input, Microsoft.ML.Transforms.GlobalContrastNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.GlobalContrastNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.HashConverter.Output Add(Microsoft.ML.Transforms.HashConverter input)
            {
                var output = new Microsoft.ML.Transforms.HashConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.HashConverter input, Microsoft.ML.Transforms.HashConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.HashConverter", input, output));
            }

            public Microsoft.ML.Transforms.KeyToTextConverter.Output Add(Microsoft.ML.Transforms.KeyToTextConverter input)
            {
                var output = new Microsoft.ML.Transforms.KeyToTextConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.KeyToTextConverter input, Microsoft.ML.Transforms.KeyToTextConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.KeyToTextConverter", input, output));
            }

            public Microsoft.ML.Transforms.LabelColumnKeyBooleanConverter.Output Add(Microsoft.ML.Transforms.LabelColumnKeyBooleanConverter input)
            {
                var output = new Microsoft.ML.Transforms.LabelColumnKeyBooleanConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.LabelColumnKeyBooleanConverter input, Microsoft.ML.Transforms.LabelColumnKeyBooleanConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LabelColumnKeyBooleanConverter", input, output));
            }

            public Microsoft.ML.Transforms.LabelIndicator.Output Add(Microsoft.ML.Transforms.LabelIndicator input)
            {
                var output = new Microsoft.ML.Transforms.LabelIndicator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.LabelIndicator input, Microsoft.ML.Transforms.LabelIndicator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LabelIndicator", input, output));
            }

            public Microsoft.ML.Transforms.LabelToFloatConverter.Output Add(Microsoft.ML.Transforms.LabelToFloatConverter input)
            {
                var output = new Microsoft.ML.Transforms.LabelToFloatConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.LabelToFloatConverter input, Microsoft.ML.Transforms.LabelToFloatConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LabelToFloatConverter", input, output));
            }

            public Microsoft.ML.Transforms.LogMeanVarianceNormalizer.Output Add(Microsoft.ML.Transforms.LogMeanVarianceNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.LogMeanVarianceNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.LogMeanVarianceNormalizer input, Microsoft.ML.Transforms.LogMeanVarianceNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LogMeanVarianceNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.LpNormalizer.Output Add(Microsoft.ML.Transforms.LpNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.LpNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.LpNormalizer input, Microsoft.ML.Transforms.LpNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.LpNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.ManyHeterogeneousModelCombiner.Output Add(Microsoft.ML.Transforms.ManyHeterogeneousModelCombiner input)
            {
                var output = new Microsoft.ML.Transforms.ManyHeterogeneousModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ManyHeterogeneousModelCombiner input, Microsoft.ML.Transforms.ManyHeterogeneousModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ManyHeterogeneousModelCombiner", input, output));
            }

            public Microsoft.ML.Transforms.MeanVarianceNormalizer.Output Add(Microsoft.ML.Transforms.MeanVarianceNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.MeanVarianceNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MeanVarianceNormalizer input, Microsoft.ML.Transforms.MeanVarianceNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MeanVarianceNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.MinMaxNormalizer.Output Add(Microsoft.ML.Transforms.MinMaxNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.MinMaxNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MinMaxNormalizer input, Microsoft.ML.Transforms.MinMaxNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MinMaxNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.MissingValueHandler.Output Add(Microsoft.ML.Transforms.MissingValueHandler input)
            {
                var output = new Microsoft.ML.Transforms.MissingValueHandler.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MissingValueHandler input, Microsoft.ML.Transforms.MissingValueHandler.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValueHandler", input, output));
            }

            public Microsoft.ML.Transforms.MissingValueIndicator.Output Add(Microsoft.ML.Transforms.MissingValueIndicator input)
            {
                var output = new Microsoft.ML.Transforms.MissingValueIndicator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MissingValueIndicator input, Microsoft.ML.Transforms.MissingValueIndicator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValueIndicator", input, output));
            }

            public Microsoft.ML.Transforms.MissingValuesDropper.Output Add(Microsoft.ML.Transforms.MissingValuesDropper input)
            {
                var output = new Microsoft.ML.Transforms.MissingValuesDropper.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MissingValuesDropper input, Microsoft.ML.Transforms.MissingValuesDropper.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValuesDropper", input, output));
            }

            public Microsoft.ML.Transforms.MissingValuesRowDropper.Output Add(Microsoft.ML.Transforms.MissingValuesRowDropper input)
            {
                var output = new Microsoft.ML.Transforms.MissingValuesRowDropper.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MissingValuesRowDropper input, Microsoft.ML.Transforms.MissingValuesRowDropper.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValuesRowDropper", input, output));
            }

            public Microsoft.ML.Transforms.MissingValueSubstitutor.Output Add(Microsoft.ML.Transforms.MissingValueSubstitutor input)
            {
                var output = new Microsoft.ML.Transforms.MissingValueSubstitutor.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.MissingValueSubstitutor input, Microsoft.ML.Transforms.MissingValueSubstitutor.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.MissingValueSubstitutor", input, output));
            }

            public Microsoft.ML.Transforms.ModelCombiner.Output Add(Microsoft.ML.Transforms.ModelCombiner input)
            {
                var output = new Microsoft.ML.Transforms.ModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ModelCombiner input, Microsoft.ML.Transforms.ModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ModelCombiner", input, output));
            }

            public Microsoft.ML.Transforms.NGramTranslator.Output Add(Microsoft.ML.Transforms.NGramTranslator input)
            {
                var output = new Microsoft.ML.Transforms.NGramTranslator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.NGramTranslator input, Microsoft.ML.Transforms.NGramTranslator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.NGramTranslator", input, output));
            }

            public Microsoft.ML.Transforms.NoOperation.Output Add(Microsoft.ML.Transforms.NoOperation input)
            {
                var output = new Microsoft.ML.Transforms.NoOperation.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.NoOperation input, Microsoft.ML.Transforms.NoOperation.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.NoOperation", input, output));
            }

            public Microsoft.ML.Transforms.OptionalColumnCreator.Output Add(Microsoft.ML.Transforms.OptionalColumnCreator input)
            {
                var output = new Microsoft.ML.Transforms.OptionalColumnCreator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.OptionalColumnCreator input, Microsoft.ML.Transforms.OptionalColumnCreator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.OptionalColumnCreator", input, output));
            }

            public Microsoft.ML.Transforms.PredictedLabelColumnOriginalValueConverter.Output Add(Microsoft.ML.Transforms.PredictedLabelColumnOriginalValueConverter input)
            {
                var output = new Microsoft.ML.Transforms.PredictedLabelColumnOriginalValueConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.PredictedLabelColumnOriginalValueConverter input, Microsoft.ML.Transforms.PredictedLabelColumnOriginalValueConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.PredictedLabelColumnOriginalValueConverter", input, output));
            }

            public Microsoft.ML.Transforms.RandomNumberGenerator.Output Add(Microsoft.ML.Transforms.RandomNumberGenerator input)
            {
                var output = new Microsoft.ML.Transforms.RandomNumberGenerator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.RandomNumberGenerator input, Microsoft.ML.Transforms.RandomNumberGenerator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RandomNumberGenerator", input, output));
            }

            public Microsoft.ML.Transforms.RowRangeFilter.Output Add(Microsoft.ML.Transforms.RowRangeFilter input)
            {
                var output = new Microsoft.ML.Transforms.RowRangeFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.RowRangeFilter input, Microsoft.ML.Transforms.RowRangeFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowRangeFilter", input, output));
            }

            public Microsoft.ML.Transforms.RowSkipAndTakeFilter.Output Add(Microsoft.ML.Transforms.RowSkipAndTakeFilter input)
            {
                var output = new Microsoft.ML.Transforms.RowSkipAndTakeFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.RowSkipAndTakeFilter input, Microsoft.ML.Transforms.RowSkipAndTakeFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowSkipAndTakeFilter", input, output));
            }

            public Microsoft.ML.Transforms.RowSkipFilter.Output Add(Microsoft.ML.Transforms.RowSkipFilter input)
            {
                var output = new Microsoft.ML.Transforms.RowSkipFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.RowSkipFilter input, Microsoft.ML.Transforms.RowSkipFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowSkipFilter", input, output));
            }

            public Microsoft.ML.Transforms.RowTakeFilter.Output Add(Microsoft.ML.Transforms.RowTakeFilter input)
            {
                var output = new Microsoft.ML.Transforms.RowTakeFilter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.RowTakeFilter input, Microsoft.ML.Transforms.RowTakeFilter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.RowTakeFilter", input, output));
            }

            public Microsoft.ML.Transforms.ScoreColumnSelector.Output Add(Microsoft.ML.Transforms.ScoreColumnSelector input)
            {
                var output = new Microsoft.ML.Transforms.ScoreColumnSelector.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.ScoreColumnSelector input, Microsoft.ML.Transforms.ScoreColumnSelector.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.ScoreColumnSelector", input, output));
            }

            public Microsoft.ML.Transforms.Scorer.Output Add(Microsoft.ML.Transforms.Scorer input)
            {
                var output = new Microsoft.ML.Transforms.Scorer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.Scorer input, Microsoft.ML.Transforms.Scorer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.Scorer", input, output));
            }

            public Microsoft.ML.Transforms.Segregator.Output Add(Microsoft.ML.Transforms.Segregator input)
            {
                var output = new Microsoft.ML.Transforms.Segregator.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.Segregator input, Microsoft.ML.Transforms.Segregator.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.Segregator", input, output));
            }

            public Microsoft.ML.Transforms.SentimentAnalyzer.Output Add(Microsoft.ML.Transforms.SentimentAnalyzer input)
            {
                var output = new Microsoft.ML.Transforms.SentimentAnalyzer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.SentimentAnalyzer input, Microsoft.ML.Transforms.SentimentAnalyzer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.SentimentAnalyzer", input, output));
            }

            public Microsoft.ML.Transforms.SupervisedBinNormalizer.Output Add(Microsoft.ML.Transforms.SupervisedBinNormalizer input)
            {
                var output = new Microsoft.ML.Transforms.SupervisedBinNormalizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.SupervisedBinNormalizer input, Microsoft.ML.Transforms.SupervisedBinNormalizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.SupervisedBinNormalizer", input, output));
            }

            public Microsoft.ML.Transforms.TextFeaturizer.Output Add(Microsoft.ML.Transforms.TextFeaturizer input)
            {
                var output = new Microsoft.ML.Transforms.TextFeaturizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.TextFeaturizer input, Microsoft.ML.Transforms.TextFeaturizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TextFeaturizer", input, output));
            }

            public Microsoft.ML.Transforms.TextToKeyConverter.Output Add(Microsoft.ML.Transforms.TextToKeyConverter input)
            {
                var output = new Microsoft.ML.Transforms.TextToKeyConverter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.TextToKeyConverter input, Microsoft.ML.Transforms.TextToKeyConverter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TextToKeyConverter", input, output));
            }

            public Microsoft.ML.Transforms.TrainTestDatasetSplitter.Output Add(Microsoft.ML.Transforms.TrainTestDatasetSplitter input)
            {
                var output = new Microsoft.ML.Transforms.TrainTestDatasetSplitter.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.TrainTestDatasetSplitter input, Microsoft.ML.Transforms.TrainTestDatasetSplitter.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TrainTestDatasetSplitter", input, output));
            }

            public Microsoft.ML.Transforms.TreeLeafFeaturizer.Output Add(Microsoft.ML.Transforms.TreeLeafFeaturizer input)
            {
                var output = new Microsoft.ML.Transforms.TreeLeafFeaturizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.TreeLeafFeaturizer input, Microsoft.ML.Transforms.TreeLeafFeaturizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TreeLeafFeaturizer", input, output));
            }

            public Microsoft.ML.Transforms.TwoHeterogeneousModelCombiner.Output Add(Microsoft.ML.Transforms.TwoHeterogeneousModelCombiner input)
            {
                var output = new Microsoft.ML.Transforms.TwoHeterogeneousModelCombiner.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.TwoHeterogeneousModelCombiner input, Microsoft.ML.Transforms.TwoHeterogeneousModelCombiner.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.TwoHeterogeneousModelCombiner", input, output));
            }

            public Microsoft.ML.Transforms.WordTokenizer.Output Add(Microsoft.ML.Transforms.WordTokenizer input)
            {
                var output = new Microsoft.ML.Transforms.WordTokenizer.Output();
                Add(input, output);
                return output;
            }

            public void Add(Microsoft.ML.Transforms.WordTokenizer input, Microsoft.ML.Transforms.WordTokenizer.Output output)
            {
                _jsonNodes.Add(Serialize("Transforms.WordTokenizer", input, output));
            }

        }
    }
    namespace Data
    {

        /// <summary>
        /// Import a dataset from a text file
        /// </summary>
        [Obsolete("Use TextLoader instead.")]
        public sealed partial class CustomTextLoader
        {


            /// <summary>
            /// Location of the input file
            /// </summary>
            public Var<Microsoft.ML.Runtime.IFileHandle> InputFile { get; set; } = new Var<Microsoft.ML.Runtime.IFileHandle>();

            /// <summary>
            /// Custom schema to use for parsing
            /// </summary>
            public string CustomSchema { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// The resulting data view
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Data
    {

        /// <summary>
        /// Create and array variable
        /// </summary>
        public sealed partial class IDataViewArrayConverter
        {


            /// <summary>
            /// The data sets
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// The data set array
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Data
    {

        /// <summary>
        /// Create and array variable
        /// </summary>
        public sealed partial class PredictorModelArrayConverter
        {


            /// <summary>
            /// The models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The model array
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> OutputModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Data
    {

        public sealed class TextLoaderArguments
        {
            /// <summary>
            /// Use separate parsing threads?
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// File containing a header with feature names. If specified, header defined in the data file (header+) is ignored.
            /// </summary>
            public string HeaderFile { get; set; }

            /// <summary>
            /// Maximum number of rows to produce
            /// </summary>
            public long? MaxRows { get; set; }

            /// <summary>
            /// Whether the input may include quoted values, which can contain separator characters, colons, and distinguish empty values from missing values. When true, consecutive separators denote a missing value and an empty value is denoted by "". When false, consecutive separators denote an empty value.
            /// </summary>
            public bool AllowQuoting { get; set; } = true;

            /// <summary>
            /// Whether the input may include sparse representations
            /// </summary>
            public bool AllowSparse { get; set; } = true;

            /// <summary>
            /// Number of source columns in the text data. Default is that sparse rows contain their size information.
            /// </summary>
            public int? InputSize { get; set; }

            /// <summary>
            /// Source column separator.
            /// </summary>
            public char[] Separator { get; set; } = { '	' };

            /// <summary>
            /// Column groups. Each group is specified as name:type:numeric-ranges, eg, col=Features:R4:1-17,26,35-40
            /// </summary>
            public TextLoaderColumn[] Column { get; set; }

            /// <summary>
            /// Remove trailing whitespace from lines
            /// </summary>
            public bool TrimWhitespace { get; set; } = false;

            /// <summary>
            /// Data file has header with feature names. Header is read only if options 'hs' and 'hf' are not specified.
            /// </summary>
            public bool HasHeader { get; set; } = false;

        }

        public sealed class TextLoaderColumn
        {
            /// <summary>
            /// Name of the column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Type of the items in the column
            /// </summary>
            public DataKind? Type { get; set; }

            /// <summary>
            /// Source index range(s) of the column
            /// </summary>
            public TextLoaderRange[] Source { get; set; }

            /// <summary>
            /// For a key column, this defines the range of values
            /// </summary>
            public KeyRange KeyRange { get; set; }

        }

        public sealed class TextLoaderRange
        {
            /// <summary>
            /// First index in the range
            /// </summary>
            public int Min { get; set; }

            /// <summary>
            /// Last index in the range
            /// </summary>
            public int? Max { get; set; }

            /// <summary>
            /// This range extends to the end of the line, but should be a fixed number of items
            /// </summary>
            public bool AutoEnd { get; set; } = false;

            /// <summary>
            /// This range extends to the end of the line, which can vary from line to line
            /// </summary>
            public bool VariableEnd { get; set; } = false;

            /// <summary>
            /// This range includes only other indices not specified
            /// </summary>
            public bool AllOther { get; set; } = false;

            /// <summary>
            /// Force scalar columns to be treated as vectors of length one
            /// </summary>
            public bool ForceVector { get; set; } = false;

        }

        public sealed class KeyRange
        {
            /// <summary>
            /// First index in the range
            /// </summary>
            public ulong Min { get; set; } = 0;

            /// <summary>
            /// Last index in the range
            /// </summary>
            public ulong? Max { get; set; }

            /// <summary>
            /// Whether the key is contiguous
            /// </summary>
            public bool Contiguous { get; set; } = true;

        }

        /// <summary>
        /// Import a dataset from a text file
        /// </summary>
        public partial class TextLoader : Microsoft.ML.ILearningPipelineLoader
        {

            [JsonIgnore]
            private string _inputFilePath = null;
            public TextLoader(string filePath)
            {
                _inputFilePath = filePath;
            }
            
            public void SetInput(IHostEnvironment env, Experiment experiment)
            {
                IFileHandle inputFile = new SimpleFileHandle(env, _inputFilePath, false, false);
                experiment.SetInput(InputFile, inputFile);
            }
            
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                Contracts.Assert(previousStep == null);
                
                return new TextLoaderPipelineStep(experiment.Add(this));
            }
            
            private class TextLoaderPipelineStep : ILearningPipelineDataStep
            {
                public TextLoaderPipelineStep (Output output)
                {
                    Data = output.Data;
                    Model = null;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }

            /// <summary>
            /// Location of the input file
            /// </summary>
            public Var<Microsoft.ML.Runtime.IFileHandle> InputFile { get; set; } = new Var<Microsoft.ML.Runtime.IFileHandle>();

            /// <summary>
            /// Arguments
            /// </summary>
            public Data.TextLoaderArguments Arguments { get; set; } = new Data.TextLoaderArguments();


            public sealed class Output
            {
                /// <summary>
                /// The resulting data view
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates an anomaly detection scored dataset.
        /// </summary>
        public sealed partial class AnomalyDetectionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Expected number of false positives
            /// </summary>
            public int K { get; set; } = 10;

            /// <summary>
            /// Expected false positive rate
            /// </summary>
            public double P { get; set; } = 0.01d;

            /// <summary>
            /// Number of top-scored predictions to display
            /// </summary>
            public int NumTopResults { get; set; } = 50;

            /// <summary>
            /// Whether to calculate metrics in one pass
            /// </summary>
            public bool Stream { get; set; } = true;

            /// <summary>
            /// The number of samples to use for AUC calculation. If 0, AUC is not computed. If -1, the whole dataset is used
            /// </summary>
            public int MaxAucExamples { get; set; } = -1;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a binary classification scored dataset.
        /// </summary>
        public sealed partial class BinaryClassificationEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Probability column name
            /// </summary>
            public string ProbabilityColumn { get; set; }

            /// <summary>
            /// Probability value for classification thresholding
            /// </summary>
            public float Threshold { get; set; }

            /// <summary>
            /// Use raw score value instead of probability for classification thresholding
            /// </summary>
            public bool UseRawScoreThreshold { get; set; } = true;

            /// <summary>
            /// The number of samples to use for p/r curve generation. Specify 0 for no p/r curve generation
            /// </summary>
            public int NumRocExamples { get; set; } = 100000;

            /// <summary>
            /// The number of samples to use for AUC calculation. If 0, AUC is not computed. If -1, the whole dataset is used
            /// </summary>
            public int MaxAucExamples { get; set; } = -1;

            /// <summary>
            /// The number of samples to use for AUPRC calculation. Specify 0 for no AUPRC calculation
            /// </summary>
            public int NumAuPrcExamples { get; set; } = 100000;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IClassificationEvaluatorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        public sealed class CrossValidationBinaryMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed class CrossValidationBinaryMacroSubGraphOutput
        {
            /// <summary>
            /// The model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// Cross validation for binary classification
        /// </summary>
        public sealed partial class BinaryCrossValidator
        {


            /// <summary>
            /// The data set
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public Models.CrossValidationBinaryMacroSubGraphInput Inputs { get; set; } = new Models.CrossValidationBinaryMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public Models.CrossValidationBinaryMacroSubGraphOutput Outputs { get; set; } = new Models.CrossValidationBinaryMacroSubGraphOutput();

            /// <summary>
            /// Column to use for stratification
            /// </summary>
            public string StratificationColumn { get; set; }

            /// <summary>
            /// Number of folds in k-fold cross-validation
            /// </summary>
            public int NumFolds { get; set; } = 2;


            public sealed class Output
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a multi class classification scored dataset.
        /// </summary>
        public sealed partial class ClassificationEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Output top-K accuracy.
            /// </summary>
            public int? OutputTopKAcc { get; set; }

            /// <summary>
            /// Output top-K classes.
            /// </summary>
            public int NumTopClassesToOutput { get; set; } = 3;

            /// <summary>
            /// Maximum number of classes in confusion matrix.
            /// </summary>
            public int NumClassesConfusionMatrix { get; set; } = 10;

            /// <summary>
            /// Output per class statistics and confusion matrix.
            /// </summary>
            public bool OutputPerClassStatistics { get; set; } = false;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IClassificationEvaluatorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a clustering scored dataset.
        /// </summary>
        public sealed partial class ClusterEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Features column name
            /// </summary>
            public string FeatureColumn { get; set; }

            /// <summary>
            /// Calculate DBI? (time-consuming unsupervised metric)
            /// </summary>
            public bool CalculateDbi { get; set; } = false;

            /// <summary>
            /// Output top K clusters
            /// </summary>
            public int NumTopClustersToOutput { get; set; } = 3;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {
        public enum MacroUtilsTrainerKinds
        {
            SignatureBinaryClassifierTrainer = 0,
            SignatureMultiClassClassifierTrainer = 1,
            SignatureRankerTrainer = 2,
            SignatureRegressorTrainer = 3,
            SignatureMultiOutputRegressorTrainer = 4,
            SignatureAnomalyDetectorTrainer = 5,
            SignatureClusteringTrainer = 6
        }


        public sealed class CrossValidationMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed class CrossValidationMacroSubGraphOutput
        {
            /// <summary>
            /// The model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// Cross validation for general learning
        /// </summary>
        public sealed partial class CrossValidator
        {


            /// <summary>
            /// The data set
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The transform model from the pipeline before this command. It gets included in the Output.PredictorModel.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public Models.CrossValidationMacroSubGraphInput Inputs { get; set; } = new Models.CrossValidationMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public Models.CrossValidationMacroSubGraphOutput Outputs { get; set; } = new Models.CrossValidationMacroSubGraphOutput();

            /// <summary>
            /// Column to use for stratification
            /// </summary>
            public string StratificationColumn { get; set; }

            /// <summary>
            /// Number of folds in k-fold cross-validation
            /// </summary>
            public int NumFolds { get; set; } = 2;

            /// <summary>
            /// Specifies the trainer kind, which determines the evaluator to be used.
            /// </summary>
            public Models.MacroUtilsTrainerKinds Kind { get; set; } = Models.MacroUtilsTrainerKinds.SignatureBinaryClassifierTrainer;


            public sealed class Output
            {
                /// <summary>
                /// The final model including the trained predictor model and the model from the transforms, provided as the Input.TransformModel.
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Split the dataset into the specified number of cross-validation folds (train and test sets)
        /// </summary>
        public sealed partial class CrossValidatorDatasetSplitter
        {


            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Number of folds to split into
            /// </summary>
            public int NumFolds { get; set; } = 2;

            /// <summary>
            /// Stratification column
            /// </summary>
            public string StratificationColumn { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// Training data (one dataset per fold)
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> TrainData { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Testing data (one dataset per fold)
                /// </summary>
                public ArrayVar<Microsoft.ML.Runtime.Data.IDataView> TestData { get; set; } = new ArrayVar<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Applies a TransformModel to a dataset.
        /// </summary>
        public sealed partial class DatasetTransformer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Transform model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(DatasetTransformer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new DatasetTransformerPipelineStep(output);
            }

            private class DatasetTransformerPipelineStep : ILearningPipelineDataStep
            {
                public DatasetTransformerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Apply a Platt calibrator with a fixed slope and offset to an input model
        /// </summary>
        public sealed partial class FixedPlattCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The slope parameter of the calibration function 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Slope { get; set; } = 1d;

            /// <summary>
            /// The offset parameter of the calibration function 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Offset { get; set; }

            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FixedPlattCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new FixedPlattCalibratorPipelineStep(output);
            }

            private class FixedPlattCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public FixedPlattCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a multi output regression scored dataset.
        /// </summary>
        public sealed partial class MultiOutputRegressionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Loss function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Supress labels and scores in per-instance outputs?
            /// </summary>
            public bool SupressScoresAndLabels { get; set; } = false;

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Apply a Naive calibrator to an input model
        /// </summary>
        public sealed partial class NaiveCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(NaiveCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new NaiveCalibratorPipelineStep(output);
            }

            private class NaiveCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public NaiveCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Models
    {
        public enum NormalizeOption
        {
            No = 0,
            Warn = 1,
            Auto = 2,
            Yes = 3
        }

        public enum CachingOptions
        {
            Auto = 0,
            Memory = 1,
            Disk = 2,
            None = 3
        }


        public sealed class OneVersusAllMacroSubGraphOutput
        {
            /// <summary>
            /// The predictor model for the subgraph exemplar.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// One-vs-All macro (OVA)
        /// </summary>
        public sealed partial class OneVersusAll : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The subgraph for the binary trainer used to construct the OVA learner. This should be a TrainBinary node.
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph output.
            /// </summary>
            public Models.OneVersusAllMacroSubGraphOutput OutputForSubGraph { get; set; } = new Models.OneVersusAllMacroSubGraphOutput();

            /// <summary>
            /// Use probabilities in OVA combiner
            /// </summary>
            public bool UseProbabilities { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output
            {
                /// <summary>
                /// The trained multiclass model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(OneVersusAll)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new OneVersusAllPipelineStep(output);
            }

            private class OneVersusAllPipelineStep : ILearningPipelinePredictorStep
            {
                public OneVersusAllPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Combines a sequence of PredictorModels into a single model
        /// </summary>
        public sealed partial class OvaModelCombiner : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Input models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> ModelArray { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Use probabilities from learners instead of raw values.
            /// </summary>
            public bool UseProbabilities { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output
            {
                /// <summary>
                /// Predictor model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(OvaModelCombiner)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new OvaModelCombinerPipelineStep(output);
            }

            private class OvaModelCombinerPipelineStep : ILearningPipelinePredictorStep
            {
                public OvaModelCombinerPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Apply a PAV calibrator to an input model
        /// </summary>
        public sealed partial class PAVCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(PAVCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new PAVCalibratorPipelineStep(output);
            }

            private class PAVCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public PAVCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Apply a Platt calibrator to an input model
        /// </summary>
        public sealed partial class PlattCalibrator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ICalibratorInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor to calibrate
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> UncalibratedPredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// The maximum number of examples to train the calibrator on
            /// </summary>
            [TlcModule.Range(Inf = 0, Max = 2147483647)]
            public int MaxRows { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ICalibratorOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(PlattCalibrator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new PlattCalibratorPipelineStep(output);
            }

            private class PlattCalibratorPipelineStep : ILearningPipelinePredictorStep
            {
                public PlattCalibratorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a quantile regression scored dataset.
        /// </summary>
        public sealed partial class QuantileRegressionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Loss function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Quantile index to select
            /// </summary>
            public int? Index { get; set; }

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a ranking scored dataset.
        /// </summary>
        public sealed partial class RankerEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Column to use for the group ID
            /// </summary>
            public string GroupIdColumn { get; set; }

            /// <summary>
            /// Maximum truncation level for computing (N)DCG
            /// </summary>
            public int DcgTruncationLevel { get; set; } = 3;

            /// <summary>
            /// Label relevance gains
            /// </summary>
            public string LabelGains { get; set; } = "0,3,7,15,31";

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Evaluates a regression scored dataset.
        /// </summary>
        public sealed partial class RegressionEvaluator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IEvaluatorInput
        {


            /// <summary>
            /// Loss function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Column to use for labels.
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Weight column name.
            /// </summary>
            public string WeightColumn { get; set; }

            /// <summary>
            /// Score column name.
            /// </summary>
            public string ScoreColumn { get; set; }

            /// <summary>
            /// Stratification column name.
            /// </summary>
            public string[] StratColumn { get; set; }

            /// <summary>
            /// The data to be used for evaluation.
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Name column name.
            /// </summary>
            public string NameColumn { get; set; } = "Name";


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IEvaluatorOutput
            {
                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        /// <summary>
        /// Summarize a linear regression predictor.
        /// </summary>
        public sealed partial class Summarizer
        {


            /// <summary>
            /// The predictor to summarize
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The summary of a predictor
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Summary { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The training set statistics. Note that this output can be null.
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Stats { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        public sealed class TrainTestBinaryMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed class TrainTestBinaryMacroSubGraphOutput
        {
            /// <summary>
            /// The model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// Train test for binary classification
        /// </summary>
        public sealed partial class TrainTestBinaryEvaluator
        {


            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The data to be used for testing
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TestingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public Models.TrainTestBinaryMacroSubGraphInput Inputs { get; set; } = new Models.TrainTestBinaryMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public Models.TrainTestBinaryMacroSubGraphOutput Outputs { get; set; } = new Models.TrainTestBinaryMacroSubGraphOutput();


            public sealed class Output
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Models
    {

        public sealed class TrainTestMacroSubGraphInput
        {
            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

        }

        public sealed class TrainTestMacroSubGraphOutput
        {
            /// <summary>
            /// The model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

        }

        /// <summary>
        /// General train test for any supported evaluator
        /// </summary>
        public sealed partial class TrainTestEvaluator
        {


            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The data to be used for testing
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TestingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The aggregated transform model from the pipeline before this command, to apply to the test data, and also include in the final model, together with the predictor model.
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// The training subgraph
            /// </summary>
            public Experiment Nodes { get; set; }

            /// <summary>
            /// The training subgraph inputs
            /// </summary>
            public Models.TrainTestMacroSubGraphInput Inputs { get; set; } = new Models.TrainTestMacroSubGraphInput();

            /// <summary>
            /// The training subgraph outputs
            /// </summary>
            public Models.TrainTestMacroSubGraphOutput Outputs { get; set; } = new Models.TrainTestMacroSubGraphOutput();

            /// <summary>
            /// Specifies the trainer kind, which determines the evaluator to be used.
            /// </summary>
            public Models.MacroUtilsTrainerKinds Kind { get; set; } = Models.MacroUtilsTrainerKinds.SignatureBinaryClassifierTrainer;

            /// <summary>
            /// Identifies which pipeline was run for this train test.
            /// </summary>
            public string PipelineId { get; set; }

            /// <summary>
            /// Indicates whether to include and output training dataset metrics.
            /// </summary>
            public bool IncludeTrainingMetrics { get; set; } = false;


            public sealed class Output
            {
                /// <summary>
                /// The final model including the trained predictor model and the model from the transforms, provided as the Input.TransformModel.
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

                /// <summary>
                /// Warning dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> Warnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> PerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Warning dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingWarnings { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Overall metrics dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingOverallMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Per instance metrics dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingPerInstanceMetrics { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Confusion matrix dataset for training
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingConfusionMatrix { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train a Average perceptron.
        /// </summary>
        public sealed partial class AveragedPerceptronBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ClassificationLossFunction LossFunction { get; set; } = new HingeLossClassificationLossFunction();

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("LearningRate", new object[]{0.01f, 0.1f, 0.5f, 1f})]
            public float LearningRate { get; set; } = 1f;

            /// <summary>
            /// Decrease learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DecreaseLearningRate", new object[]{false, true})]
            public bool DecreaseLearningRate { get; set; } = false;

            /// <summary>
            /// Number of examples after which weights will be reset to the current average
            /// </summary>
            public long? ResetWeightsAfterXExamples { get; set; }

            /// <summary>
            /// Instead of updating averaged weights on every example, only update when loss is nonzero
            /// </summary>
            public bool DoLazyUpdates { get; set; } = true;

            /// <summary>
            /// L2 Regularization Weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2RegularizerWeight", 0f, 0.5f)]
            public float L2RegularizerWeight { get; set; }

            /// <summary>
            /// Extra weight given to more recent updates
            /// </summary>
            public float RecencyGain { get; set; }

            /// <summary>
            /// Whether Recency Gain is multiplicative (vs. additive)
            /// </summary>
            public bool RecencyGainMulti { get; set; } = false;

            /// <summary>
            /// Do averaging?
            /// </summary>
            public bool Averaged { get; set; } = true;

            /// <summary>
            /// The inexactness tolerance for averaging
            /// </summary>
            public float AveragedTolerance { get; set; } = 0.01f;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumIterations", 1, 100, stepSize:10, isLogScale:true)]
            public int NumIterations { get; set; } = 1;

            /// <summary>
            /// Initial Weights and bias, comma-separated
            /// </summary>
            public string InitialWeights { get; set; }

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Size of cache when trained in Scope
            /// </summary>
            public int StreamingCacheSize { get; set; } = 1000000;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(AveragedPerceptronBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new AveragedPerceptronBinaryClassifierPipelineStep(output);
            }

            private class AveragedPerceptronBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public AveragedPerceptronBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train a logistic regression binary model
        /// </summary>
        public sealed partial class BinaryLogisticRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Show statistics of training examples.
            /// </summary>
            public bool ShowTrainingStats { get; set; } = false;

            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2Weight", 0f, 1f, numSteps:4)]
            public float L2Weight { get; set; } = 1f;

            /// <summary>
            /// L1 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L1Weight", 0f, 1f, numSteps:4)]
            public float L1Weight { get; set; } = 1f;

            /// <summary>
            /// Tolerance parameter for optimization convergence. Lower = slower, more accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("OptTol", new object[]{0.0001f, 1E-07f})]
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Memory size for L-BFGS. Lower=faster, less accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MemorySize", new object[]{5, 20, 50})]
            public int MemorySize { get; set; } = 20;

            /// <summary>
            /// Maximum iterations.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("MaxIterations", 1, 2147483647)]
            public int MaxIterations { get; set; } = 2147483647;

            /// <summary>
            /// Run SGD to initialize LR weights, converging to this tolerance
            /// </summary>
            public float SgdInitializationTolerance { get; set; }

            /// <summary>
            /// If set to true, produce no output during training.
            /// </summary>
            public bool Quiet { get; set; } = false;

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether or not to use threads. Default is true
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// Number of threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Force densification of the internal optimization vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DenseOptimizer", new object[]{false, true})]
            public bool DenseOptimizer { get; set; } = false;

            /// <summary>
            /// Enforce non-negative weights
            /// </summary>
            public bool EnforceNonNegativity { get; set; } = false;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(BinaryLogisticRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new BinaryLogisticRegressorPipelineStep(output);
            }

            private class BinaryLogisticRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public BinaryLogisticRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {
        public enum Bundle : byte
        {
            None = 0,
            AggregateLowPopulation = 1,
            Adjacent = 2
        }


        /// <summary>
        /// Uses a random forest learner to perform binary classification.
        /// </summary>
        public sealed partial class FastForestBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Number of labels to be sampled from each leaf to make the distribtuion
            /// </summary>
            public int QuantileSampleCount { get; set; } = 100;

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Trainers.Bundle Bundling { get; set; } = Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 0.7d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; } = 1;

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 0.7d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FastForestBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new FastForestBinaryClassifierPipelineStep(output);
            }

            private class FastForestBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public FastForestBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Trains a random forest to fit target values using least-squares.
        /// </summary>
        public sealed partial class FastForestRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Shuffle the labels on every iteration. Useful probably only if using this tree as a tree leaf featurizer for multiclass.
            /// </summary>
            public bool ShuffleLabels { get; set; } = false;

            /// <summary>
            /// Number of labels to be sampled from each leaf to make the distribtuion
            /// </summary>
            public int QuantileSampleCount { get; set; } = 100;

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Trainers.Bundle Bundling { get; set; } = Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 0.7d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; } = 1;

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 0.7d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FastForestRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new FastForestRegressorPipelineStep(output);
            }

            private class FastForestRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public FastForestRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {
        public enum BoostedTreeArgsOptimizationAlgorithmType
        {
            GradientDescent = 0,
            AcceleratedGradientDescent = 1,
            ConjugateGradientDescent = 2
        }


        /// <summary>
        /// Uses a logit-boost boosted tree learner to perform binary classification.
        /// </summary>
        public sealed partial class FastTreeBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Should we use derivatives optimized for unbalanced sets
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Trainers.Bundle Bundling { get; set; } = Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FastTreeBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new FastTreeBinaryClassifierPipelineStep(output);
            }

            private class FastTreeBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Trains gradient boosted decision trees to the LambdaRank quasi-gradient.
        /// </summary>
        public sealed partial class FastTreeRanker : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31";

            /// <summary>
            /// Train DCG instead of NDCG
            /// </summary>
            public bool TrainDcg { get; set; } = false;

            /// <summary>
            /// The sorting algorithm to use for DCG and LambdaMart calculations [DescendingStablePessimistic/DescendingStable/DescendingReverse/DescendingDotNet]
            /// </summary>
            public string SortingAlgorithm { get; set; } = "DescendingStablePessimistic";

            /// <summary>
            /// max-NDCG truncation to use in the Lambda Mart algorithm
            /// </summary>
            public int LambdaMartMaxTruncation { get; set; } = 100;

            /// <summary>
            /// Use shifted NDCG
            /// </summary>
            public bool ShiftedNdcg { get; set; } = false;

            /// <summary>
            /// Cost function parameter (w/c)
            /// </summary>
            public char CostFunctionParam { get; set; } = 'w';

            /// <summary>
            /// Distance weight 2 adjustment to cost
            /// </summary>
            public bool DistanceWeight2 { get; set; } = false;

            /// <summary>
            /// Normalize query lambdas
            /// </summary>
            public bool NormalizeQueryLambdas { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Trainers.Bundle Bundling { get; set; } = Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRankingOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FastTreeRanker)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new FastTreeRankerPipelineStep(output);
            }

            private class FastTreeRankerPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeRankerPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Trains gradient boosted decision trees to fit target values using least-squares.
        /// </summary>
        public sealed partial class FastTreeRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Trainers.Bundle Bundling { get; set; } = Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FastTreeRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new FastTreeRegressorPipelineStep(output);
            }

            private class FastTreeRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Trains gradient boosted decision trees to fit target values using a Tweedie loss function. This learner is a generalization of Poisson, compound Poisson, and gamma regression.
        /// </summary>
        public sealed partial class FastTreeTweedieRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithGroupId, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Index parameter for the Tweedie distribution, in the range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate values are compound Poisson loss.
            /// </summary>
            public double Index { get; set; } = 1.5d;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Trainers.Bundle Bundling { get; set; } = Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FastTreeTweedieRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new FastTreeTweedieRegressorPipelineStep(output);
            }

            private class FastTreeTweedieRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public FastTreeTweedieRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Trains a gradient boosted stump per feature, on all features simultaneously, to fit target values using least-squares. It mantains no interactions between features.
        /// </summary>
        public sealed partial class GeneralizedAdditiveModelBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Should we use derivatives optimized for unbalanced sets
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public int GainConfidenceLevel { get; set; }

            /// <summary>
            /// Total number of iterations over all features
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumIterations", new object[]{200, 1500, 9500})]
            public int NumIterations { get; set; } = 9500;

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.001f, 0.1f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.002d;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Upper bound on absolute value of single output
            /// </summary>
            public double MaxOutput { get; set; } = double.PositiveInfinity;

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// Minimum number of training instances required to form a partition
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocuments", new object[]{1, 10, 50})]
            public int MinDocuments { get; set; } = 10;

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(GeneralizedAdditiveModelBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new GeneralizedAdditiveModelBinaryClassifierPipelineStep(output);
            }

            private class GeneralizedAdditiveModelBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public GeneralizedAdditiveModelBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Trains a gradient boosted stump per feature, on all features simultaneously, to fit target values using least-squares. It mantains no interactions between features.
        /// </summary>
        public sealed partial class GeneralizedAdditiveModelRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public int GainConfidenceLevel { get; set; }

            /// <summary>
            /// Total number of iterations over all features
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumIterations", new object[]{200, 1500, 9500})]
            public int NumIterations { get; set; } = 9500;

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.001f, 0.1f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.002d;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Upper bound on absolute value of single output
            /// </summary>
            public double MaxOutput { get; set; } = double.PositiveInfinity;

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// Minimum number of training instances required to form a partition
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocuments", new object[]{1, 10, 50})]
            public int MinDocuments { get; set; } = 10;

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(GeneralizedAdditiveModelRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new GeneralizedAdditiveModelRegressorPipelineStep(output);
            }

            private class GeneralizedAdditiveModelRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public GeneralizedAdditiveModelRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train a linear SVM.
        /// </summary>
        public sealed partial class LinearSvmBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Regularizer constant
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Lambda", 1E-05f, 0.1f, stepSize:10, isLogScale:true)]
            public float Lambda { get; set; } = 0.001f;

            /// <summary>
            /// Batch size
            /// </summary>
            public int BatchSize { get; set; } = 1;

            /// <summary>
            /// Perform projection to unit-ball? Typically used with batch size > 1.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("PerformProjection", new object[]{false, true})]
            public bool PerformProjection { get; set; } = false;

            /// <summary>
            /// No bias
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NoBias", new object[]{false, true})]
            public bool NoBias { get; set; } = false;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumIterations", 1, 100, stepSize:10, isLogScale:true)]
            public int NumIterations { get; set; } = 1;

            /// <summary>
            /// Initial Weights and bias, comma-separated
            /// </summary>
            public string InitialWeights { get; set; }

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Size of cache when trained in Scope
            /// </summary>
            public int StreamingCacheSize { get; set; } = 1000000;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LinearSvmBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new LinearSvmBinaryClassifierPipelineStep(output);
            }

            private class LinearSvmBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public LinearSvmBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train a logistic regression multi class model
        /// </summary>
        public sealed partial class LogisticRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Show statistics of training examples.
            /// </summary>
            public bool ShowTrainingStats { get; set; } = false;

            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2Weight", 0f, 1f, numSteps:4)]
            public float L2Weight { get; set; } = 1f;

            /// <summary>
            /// L1 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L1Weight", 0f, 1f, numSteps:4)]
            public float L1Weight { get; set; } = 1f;

            /// <summary>
            /// Tolerance parameter for optimization convergence. Lower = slower, more accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("OptTol", new object[]{0.0001f, 1E-07f})]
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Memory size for L-BFGS. Lower=faster, less accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MemorySize", new object[]{5, 20, 50})]
            public int MemorySize { get; set; } = 20;

            /// <summary>
            /// Maximum iterations.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("MaxIterations", 1, 2147483647)]
            public int MaxIterations { get; set; } = 2147483647;

            /// <summary>
            /// Run SGD to initialize LR weights, converging to this tolerance
            /// </summary>
            public float SgdInitializationTolerance { get; set; }

            /// <summary>
            /// If set to true, produce no output during training.
            /// </summary>
            public bool Quiet { get; set; } = false;

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether or not to use threads. Default is true
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// Number of threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Force densification of the internal optimization vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DenseOptimizer", new object[]{false, true})]
            public bool DenseOptimizer { get; set; } = false;

            /// <summary>
            /// Enforce non-negative weights
            /// </summary>
            public bool EnforceNonNegativity { get; set; } = false;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LogisticRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new LogisticRegressorPipelineStep(output);
            }

            private class LogisticRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public LogisticRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train a MultiClassNaiveBayesTrainer.
        /// </summary>
        public sealed partial class NaiveBayesClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(NaiveBayesClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new NaiveBayesClassifierPipelineStep(output);
            }

            private class NaiveBayesClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public NaiveBayesClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train a Online gradient descent perceptron.
        /// </summary>
        public sealed partial class OnlineGradientDescentRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public RegressionLossFunction LossFunction { get; set; } = new SquaredLossRegressionLossFunction();

            /// <summary>
            /// Learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("LearningRate", new object[]{0.01f, 0.1f, 0.5f, 1f})]
            public float LearningRate { get; set; } = 0.1f;

            /// <summary>
            /// Decrease learning rate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DecreaseLearningRate", new object[]{false, true})]
            public bool DecreaseLearningRate { get; set; } = true;

            /// <summary>
            /// Number of examples after which weights will be reset to the current average
            /// </summary>
            public long? ResetWeightsAfterXExamples { get; set; }

            /// <summary>
            /// Instead of updating averaged weights on every example, only update when loss is nonzero
            /// </summary>
            public bool DoLazyUpdates { get; set; } = true;

            /// <summary>
            /// L2 Regularization Weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2RegularizerWeight", 0f, 0.5f)]
            public float L2RegularizerWeight { get; set; }

            /// <summary>
            /// Extra weight given to more recent updates
            /// </summary>
            public float RecencyGain { get; set; }

            /// <summary>
            /// Whether Recency Gain is multiplicative (vs. additive)
            /// </summary>
            public bool RecencyGainMulti { get; set; } = false;

            /// <summary>
            /// Do averaging?
            /// </summary>
            public bool Averaged { get; set; } = true;

            /// <summary>
            /// The inexactness tolerance for averaging
            /// </summary>
            public float AveragedTolerance { get; set; } = 0.01f;

            /// <summary>
            /// Number of iterations
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumIterations", 1, 100, stepSize:10, isLogScale:true)]
            public int NumIterations { get; set; } = 1;

            /// <summary>
            /// Initial Weights and bias, comma-separated
            /// </summary>
            public string InitialWeights { get; set; }

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether to shuffle for each training iteration
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Size of cache when trained in Scope
            /// </summary>
            public int StreamingCacheSize { get; set; } = 1000000;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(OnlineGradientDescentRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new OnlineGradientDescentRegressorPipelineStep(output);
            }

            private class OnlineGradientDescentRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public OnlineGradientDescentRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train an OLS regression model.
        /// </summary>
        public sealed partial class OrdinaryLeastSquaresRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Weight", new object[]{1E-06f, 0.1f, 1f})]
            public float L2Weight { get; set; } = 1E-06f;

            /// <summary>
            /// Whether to calculate per parameter significance statistics
            /// </summary>
            public bool PerParameterSignificance { get; set; } = true;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(OrdinaryLeastSquaresRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new OrdinaryLeastSquaresRegressorPipelineStep(output);
            }

            private class OrdinaryLeastSquaresRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public OrdinaryLeastSquaresRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train an Poisson regression model.
        /// </summary>
        public sealed partial class PoissonRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// L2 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L2Weight", 0f, 1f, numSteps:4)]
            public float L2Weight { get; set; } = 1f;

            /// <summary>
            /// L1 regularization weight
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("L1Weight", 0f, 1f, numSteps:4)]
            public float L1Weight { get; set; } = 1f;

            /// <summary>
            /// Tolerance parameter for optimization convergence. Lower = slower, more accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("OptTol", new object[]{0.0001f, 1E-07f})]
            public float OptTol { get; set; } = 1E-07f;

            /// <summary>
            /// Memory size for L-BFGS. Lower=faster, less accurate
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MemorySize", new object[]{5, 20, 50})]
            public int MemorySize { get; set; } = 20;

            /// <summary>
            /// Maximum iterations.
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("MaxIterations", 1, 2147483647)]
            public int MaxIterations { get; set; } = 2147483647;

            /// <summary>
            /// Run SGD to initialize LR weights, converging to this tolerance
            /// </summary>
            public float SgdInitializationTolerance { get; set; }

            /// <summary>
            /// If set to true, produce no output during training.
            /// </summary>
            public bool Quiet { get; set; } = false;

            /// <summary>
            /// Init weights diameter
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("InitWtsDiameter", 0f, 1f, numSteps:5)]
            public float InitWtsDiameter { get; set; }

            /// <summary>
            /// Whether or not to use threads. Default is true
            /// </summary>
            public bool UseThreads { get; set; } = true;

            /// <summary>
            /// Number of threads
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Force densification of the internal optimization vectors
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DenseOptimizer", new object[]{false, true})]
            public bool DenseOptimizer { get; set; } = false;

            /// <summary>
            /// Enforce non-negative weights
            /// </summary>
            public bool EnforceNonNegativity { get; set; } = false;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(PoissonRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new PoissonRegressorPipelineStep(output);
            }

            private class PoissonRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public PoissonRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train an SDCA binary model.
        /// </summary>
        public sealed partial class StochasticDualCoordinateAscentBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SDCAClassificationLossFunction LossFunction { get; set; } = new LogLossSDCAClassificationLossFunction();

            /// <summary>
            /// Apply weight to the positive class, for imbalanced data
            /// </summary>
            public float PositiveInstanceWeight { get; set; } = 1f;

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// L2 regularizer constant. By default the l2 constant is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{"<Auto>", 1E-07f, 1E-06f, 1E-05f, 0.0001f, 0.001f, 0.01f})]
            public float? L2Const { get; set; }

            /// <summary>
            /// L1 soft threshold (L1/L2). Note that it is easier to control and sweep using the threshold parameter than the raw L1-regularizer constant. By default the l1 threshold is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L1Threshold", new object[]{"<Auto>", 0f, 0.25f, 0.5f, 0.75f, 1f})]
            public float? L1Threshold { get; set; }

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The tolerance for the ratio between duality gap and primal loss for convergence checking.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.001f, 0.01f, 0.1f, 0.2f})]
            public float ConvergenceTolerance { get; set; } = 0.1f;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning. Defaults to automatic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{"<Auto>", 10, 20, 100})]
            public int? MaxIterations { get; set; }

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Set as negative or zero for not checking at all. If left blank, it defaults to check after every 'numThreads' iterations.
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The learning rate for adjusting bias from being regularized.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("BiasLearningRate", new object[]{0f, 0.01f, 0.1f, 1f})]
            public float BiasLearningRate { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(StochasticDualCoordinateAscentBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new StochasticDualCoordinateAscentBinaryClassifierPipelineStep(output);
            }

            private class StochasticDualCoordinateAscentBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticDualCoordinateAscentBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train an SDCA multi class model
        /// </summary>
        public sealed partial class StochasticDualCoordinateAscentClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SDCAClassificationLossFunction LossFunction { get; set; } = new LogLossSDCAClassificationLossFunction();

            /// <summary>
            /// L2 regularizer constant. By default the l2 constant is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{"<Auto>", 1E-07f, 1E-06f, 1E-05f, 0.0001f, 0.001f, 0.01f})]
            public float? L2Const { get; set; }

            /// <summary>
            /// L1 soft threshold (L1/L2). Note that it is easier to control and sweep using the threshold parameter than the raw L1-regularizer constant. By default the l1 threshold is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L1Threshold", new object[]{"<Auto>", 0f, 0.25f, 0.5f, 0.75f, 1f})]
            public float? L1Threshold { get; set; }

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The tolerance for the ratio between duality gap and primal loss for convergence checking.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.001f, 0.01f, 0.1f, 0.2f})]
            public float ConvergenceTolerance { get; set; } = 0.1f;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning. Defaults to automatic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{"<Auto>", 10, 20, 100})]
            public int? MaxIterations { get; set; }

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Set as negative or zero for not checking at all. If left blank, it defaults to check after every 'numThreads' iterations.
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The learning rate for adjusting bias from being regularized.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("BiasLearningRate", new object[]{0f, 0.01f, 0.1f, 1f})]
            public float BiasLearningRate { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IMulticlassClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(StochasticDualCoordinateAscentClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new StochasticDualCoordinateAscentClassifierPipelineStep(output);
            }

            private class StochasticDualCoordinateAscentClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticDualCoordinateAscentClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train an SDCA regression model
        /// </summary>
        public sealed partial class StochasticDualCoordinateAscentRegressor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public SDCARegressionLossFunction LossFunction { get; set; } = new SquaredLossSDCARegressionLossFunction();

            /// <summary>
            /// L2 regularizer constant. By default the l2 constant is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{"<Auto>", 1E-07f, 1E-06f, 1E-05f, 0.0001f, 0.001f, 0.01f})]
            public float? L2Const { get; set; }

            /// <summary>
            /// L1 soft threshold (L1/L2). Note that it is easier to control and sweep using the threshold parameter than the raw L1-regularizer constant. By default the l1 threshold is automatically inferred based on data set.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L1Threshold", new object[]{"<Auto>", 0f, 0.25f, 0.5f, 0.75f, 1f})]
            public float? L1Threshold { get; set; }

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The tolerance for the ratio between duality gap and primal loss for convergence checking.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.001f, 0.01f, 0.1f, 0.2f})]
            public float ConvergenceTolerance { get; set; } = 0.01f;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning. Defaults to automatic.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{"<Auto>", 10, 20, 100})]
            public int? MaxIterations { get; set; }

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Set as negative or zero for not checking at all. If left blank, it defaults to check after every 'numThreads' iterations.
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The learning rate for adjusting bias from being regularized.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("BiasLearningRate", new object[]{0f, 0.01f, 0.1f, 1f})]
            public float BiasLearningRate { get; set; } = 1f;

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IRegressionOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(StochasticDualCoordinateAscentRegressor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new StochasticDualCoordinateAscentRegressorPipelineStep(output);
            }

            private class StochasticDualCoordinateAscentRegressorPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticDualCoordinateAscentRegressorPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Trainers
    {

        /// <summary>
        /// Train an Hogwild SGD binary model.
        /// </summary>
        public sealed partial class StochasticGradientDescentBinaryClassifier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithWeight, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInputWithLabel, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITrainerInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Loss Function
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ClassificationLossFunction LossFunction { get; set; } = new LogLossClassificationLossFunction();

            /// <summary>
            /// L2 regularizer constant
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("L2Const", new object[]{1E-07f, 5E-07f, 1E-06f, 5E-06f, 1E-05f})]
            public float L2Const { get; set; } = 1E-06f;

            /// <summary>
            /// Degree of lock-free parallelism. Defaults to automatic depending on data sparseness. Determinism not guaranteed.
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// Exponential moving averaged improvement tolerance for convergence
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("ConvergenceTolerance", new object[]{0.01f, 0.001f, 0.0001f, 1E-05f})]
            public double ConvergenceTolerance { get; set; } = 0.0001d;

            /// <summary>
            /// Maximum number of iterations; set to 1 to simulate online learning.
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MaxIterations", new object[]{1, 5, 10, 20})]
            public int MaxIterations { get; set; } = 20;

            /// <summary>
            /// Initial learning rate (only used by SGD)
            /// </summary>
            public double InitLearningRate { get; set; } = 0.01d;

            /// <summary>
            /// Shuffle data every epoch?
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("Shuffle", new object[]{false, true})]
            public bool Shuffle { get; set; } = true;

            /// <summary>
            /// Apply weight to the positive class, for imbalanced data
            /// </summary>
            public float PositiveInstanceWeight { get; set; } = 1f;

            /// <summary>
            /// Convergence check frequency (in terms of number of iterations). Default equals number of threads
            /// </summary>
            public int? CheckFrequency { get; set; }

            /// <summary>
            /// The calibrator kind to apply to the predictor. Specify null for no calibration
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public CalibratorTrainer Calibrator { get; set; } = new PlattCalibratorCalibratorTrainer();

            /// <summary>
            /// The maximum number of examples to use when training the calibrator
            /// </summary>
            public int MaxCalibrationExamples { get; set; } = 1000000;

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Models.NormalizeOption NormalizeFeatures { get; set; } = Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Models.CachingOptions Caching { get; set; } = Models.CachingOptions.Auto;


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.IBinaryClassificationOutput, Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITrainerOutput
            {
                /// <summary>
                /// The trained model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(StochasticGradientDescentBinaryClassifier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                TrainingData = dataStep.Data;
                Output output = experiment.Add(this);
                return new StochasticGradientDescentBinaryClassifierPipelineStep(output);
            }

            private class StochasticGradientDescentBinaryClassifierPipelineStep : ILearningPipelinePredictorStep
            {
                public StochasticGradientDescentBinaryClassifierPipelineStep(Output output)
                {
                    Model = output.PredictorModel;
                }

                public Var<IPredictorModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Approximate bootstrap sampling.
        /// </summary>
        public sealed partial class ApproximateBootstrapSampler : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Whether this is the out-of-bag sample, that is, all those rows that are not selected by the transform.
            /// </summary>
            public bool Complement { get; set; } = false;

            /// <summary>
            /// The random seed. If unspecified random state will be instead derived from the environment.
            /// </summary>
            public uint? Seed { get; set; }

            /// <summary>
            /// Whether we should attempt to shuffle the source data. By default on, but can be turned off for efficiency.
            /// </summary>
            public bool ShuffleInput { get; set; } = true;

            /// <summary>
            /// When shuffling the output, the number of output rows to keep in that pool. Note that shuffling of output is completely distinct from shuffling of input.
            /// </summary>
            public int PoolSize { get; set; } = 1000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ApproximateBootstrapSampler)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ApproximateBootstrapSamplerPipelineStep(output);
            }

            private class ApproximateBootstrapSamplerPipelineStep : ILearningPipelineDataStep
            {
                public ApproximateBootstrapSamplerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// For binary prediction, it renames the PredictedLabel and Score columns to include the name of the positive class.
        /// </summary>
        public sealed partial class BinaryPredictionScoreColumnsRenamer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The predictor model used in scoring
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(BinaryPredictionScoreColumnsRenamer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new BinaryPredictionScoreColumnsRenamerPipelineStep(output);
            }

            private class BinaryPredictionScoreColumnsRenamerPipelineStep : ILearningPipelineDataStep
            {
                public BinaryPredictionScoreColumnsRenamerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class NormalizeTransformBinColumn : OneToOneColumn<NormalizeTransformBinColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Max number of bins, power of 2 recommended
            /// </summary>
            public int? NumBins { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool? FixZero { get; set; }

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long? MaxTrainingExamples { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// The values are assigned into equidensity bins and a value is mapped to its bin_number/number_of_bins.
        /// </summary>
        public sealed partial class BinNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public BinNormalizer()
            {
            }
            
            public BinNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public BinNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformBinColumn>() : new List<Transforms.NormalizeTransformBinColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformBinColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformBinColumn>() : new List<Transforms.NormalizeTransformBinColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformBinColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NormalizeTransformBinColumn[] Column { get; set; }

            /// <summary>
            /// Max number of bins, power of 2 recommended
            /// </summary>
            public int NumBins { get; set; } = 1024;

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(BinNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new BinNormalizerPipelineStep(output);
            }

            private class BinNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public BinNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum CategoricalTransformOutputKind : byte
        {
            Bag = 1,
            Ind = 2,
            Key = 3,
            Bin = 4
        }


        public sealed class CategoricalHashTransformColumn : OneToOneColumn<CategoricalHashTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The number of bits to hash into. Must be between 1 and 30, inclusive.
            /// </summary>
            public int? HashBits { get; set; }

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint? Seed { get; set; }

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool? Ordered { get; set; }

            /// <summary>
            /// Limit the number of keys used to generate the slot name to this many. 0 means no invert hashing, -1 means no limit.
            /// </summary>
            public int? InvertHash { get; set; }

            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), or Key (index)
            /// </summary>
            public Transforms.CategoricalTransformOutputKind? OutputKind { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Encodes the categorical variable with hash-based encoding
        /// </summary>
        public sealed partial class CategoricalHashOneHotVectorizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public CategoricalHashOneHotVectorizer()
            {
            }
            
            public CategoricalHashOneHotVectorizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public CategoricalHashOneHotVectorizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.CategoricalHashTransformColumn>() : new List<Transforms.CategoricalHashTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CategoricalHashTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.CategoricalHashTransformColumn>() : new List<Transforms.CategoricalHashTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CategoricalHashTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:hashBits:src)
            /// </summary>
            public Transforms.CategoricalHashTransformColumn[] Column { get; set; }

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 30, inclusive.
            /// </summary>
            public int HashBits { get; set; } = 16;

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint Seed { get; set; } = 314489979;

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool Ordered { get; set; } = true;

            /// <summary>
            /// Limit the number of keys used to generate the slot name to this many. 0 means no invert hashing, -1 means no limit.
            /// </summary>
            public int InvertHash { get; set; }

            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), or Key (index)
            /// </summary>
            public Transforms.CategoricalTransformOutputKind OutputKind { get; set; } = Transforms.CategoricalTransformOutputKind.Bag;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(CategoricalHashOneHotVectorizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new CategoricalHashOneHotVectorizerPipelineStep(output);
            }

            private class CategoricalHashOneHotVectorizerPipelineStep : ILearningPipelineDataStep
            {
                public CategoricalHashOneHotVectorizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum TermTransformSortOrder : byte
        {
            Occurrence = 0,
            Value = 1
        }


        public sealed class CategoricalTransformColumn : OneToOneColumn<CategoricalTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), Key (index), or Binary encoded indicator vector
            /// </summary>
            public Transforms.CategoricalTransformOutputKind? OutputKind { get; set; }

            /// <summary>
            /// Maximum number of terms to keep when auto-training
            /// </summary>
            public int? MaxNumTerms { get; set; }

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, e.g., text sorting will be case sensitive (e.g., 'A' then 'Z' then 'a').
            /// </summary>
            public Transforms.TermTransformSortOrder? Sort { get; set; }

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool? TextKeyValues { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Encodes the categorical variable with one-hot encoding based on term dictionary
        /// </summary>
        public sealed partial class CategoricalOneHotVectorizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public CategoricalOneHotVectorizer()
            {
            }
            
            public CategoricalOneHotVectorizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public CategoricalOneHotVectorizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.CategoricalTransformColumn>() : new List<Transforms.CategoricalTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CategoricalTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.CategoricalTransformColumn>() : new List<Transforms.CategoricalTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CategoricalTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.CategoricalTransformColumn[] Column { get; set; }

            /// <summary>
            /// Output kind: Bag (multi-set vector), Ind (indicator vector), or Key (index)
            /// </summary>
            public Transforms.CategoricalTransformOutputKind OutputKind { get; set; } = Transforms.CategoricalTransformOutputKind.Ind;

            /// <summary>
            /// Maximum number of terms to keep per column when auto-training
            /// </summary>
            public int MaxNumTerms { get; set; } = 1000000;

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, e.g., text sorting will be case sensitive (e.g., 'A' then 'Z' then 'a').
            /// </summary>
            public Transforms.TermTransformSortOrder Sort { get; set; } = Transforms.TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool TextKeyValues { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(CategoricalOneHotVectorizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new CategoricalOneHotVectorizerPipelineStep(output);
            }

            private class CategoricalOneHotVectorizerPipelineStep : ILearningPipelineDataStep
            {
                public CategoricalOneHotVectorizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class CharTokenizeTransformColumn : OneToOneColumn<CharTokenizeTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Character-oriented tokenizer where text is considered a sequence of characters.
        /// </summary>
        public sealed partial class CharacterTokenizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public CharacterTokenizer()
            {
            }
            
            public CharacterTokenizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public CharacterTokenizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.CharTokenizeTransformColumn>() : new List<Transforms.CharTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CharTokenizeTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.CharTokenizeTransformColumn>() : new List<Transforms.CharTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CharTokenizeTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.CharTokenizeTransformColumn[] Column { get; set; }

            /// <summary>
            /// Whether to mark the beginning/end of each row/slot with start of text character (0x02)/end of text character (0x03)
            /// </summary>
            public bool UseMarkerChars { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(CharacterTokenizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new CharacterTokenizerPipelineStep(output);
            }

            private class CharacterTokenizerPipelineStep : ILearningPipelineDataStep
            {
                public CharacterTokenizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class ConcatTransformColumn : ManyToOneColumn<ConcatTransformColumn>, IManyToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string[] Source { get; set; }

        }

        /// <summary>
        /// Concatenates two columns of the same item type.
        /// </summary>
        public sealed partial class ColumnConcatenator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public ColumnConcatenator()
            {
            }
            
            public ColumnConcatenator(string outputColumn, params string[] inputColumns)
            {
                AddColumn(outputColumn, inputColumns);
            }
            
            public void AddColumn(string name, params string[] source)
            {
                var list = Column == null ? new List<Transforms.ConcatTransformColumn>() : new List<Transforms.ConcatTransformColumn>(Column);
                list.Add(ManyToOneColumn<Transforms.ConcatTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:srcs)
            /// </summary>
            public Transforms.ConcatTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ColumnConcatenator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ColumnConcatenatorPipelineStep(output);
            }

            private class ColumnConcatenatorPipelineStep : ILearningPipelineDataStep
            {
                public ColumnConcatenatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class CopyColumnsTransformColumn : OneToOneColumn<CopyColumnsTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Duplicates columns from the dataset
        /// </summary>
        public sealed partial class ColumnCopier : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public ColumnCopier()
            {
            }
            
            public ColumnCopier(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ColumnCopier(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.CopyColumnsTransformColumn>() : new List<Transforms.CopyColumnsTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CopyColumnsTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.CopyColumnsTransformColumn>() : new List<Transforms.CopyColumnsTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.CopyColumnsTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.CopyColumnsTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ColumnCopier)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ColumnCopierPipelineStep(output);
            }

            private class ColumnCopierPipelineStep : ILearningPipelineDataStep
            {
                public ColumnCopierPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Drops columns from the dataset
        /// </summary>
        public sealed partial class ColumnDropper : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Column name to drop
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ColumnDropper)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ColumnDropperPipelineStep(output);
            }

            private class ColumnDropperPipelineStep : ILearningPipelineDataStep
            {
                public ColumnDropperPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Selects a set of columns, dropping all others
        /// </summary>
        public sealed partial class ColumnSelector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Column name to keep
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ColumnSelector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ColumnSelectorPipelineStep(output);
            }

            private class ColumnSelectorPipelineStep : ILearningPipelineDataStep
            {
                public ColumnSelectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum DataKind : byte
        {
            I1 = 1,
            U1 = 2,
            I2 = 3,
            U2 = 4,
            I4 = 5,
            U4 = 6,
            I8 = 7,
            U8 = 8,
            R4 = 9,
            Num = 9,
            R8 = 10,
            TX = 11,
            Text = 11,
            TXT = 11,
            BL = 12,
            Bool = 12,
            TimeSpan = 13,
            TS = 13,
            DT = 14,
            DateTime = 14,
            DZ = 15,
            DateTimeZone = 15,
            UG = 16,
            U16 = 16
        }


        public sealed class ConvertTransformColumn : OneToOneColumn<ConvertTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The result type
            /// </summary>
            public Transforms.DataKind? ResultType { get; set; }

            /// <summary>
            /// For a key column, this defines the range of values
            /// </summary>
            public string Range { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Converts a column to a different type, using standard conversions.
        /// </summary>
        public sealed partial class ColumnTypeConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public ColumnTypeConverter()
            {
            }
            
            public ColumnTypeConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ColumnTypeConverter(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.ConvertTransformColumn>() : new List<Transforms.ConvertTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.ConvertTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.ConvertTransformColumn>() : new List<Transforms.ConvertTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.ConvertTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:type:src)
            /// </summary>
            public Transforms.ConvertTransformColumn[] Column { get; set; }

            /// <summary>
            /// The result type
            /// </summary>
            public Transforms.DataKind? ResultType { get; set; }

            /// <summary>
            /// For a key column, this defines the range of values
            /// </summary>
            public string Range { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ColumnTypeConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ColumnTypeConverterPipelineStep(output);
            }

            private class ColumnTypeConverterPipelineStep : ILearningPipelineDataStep
            {
                public ColumnTypeConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Groups values of a scalar column into a vector, by a contiguous group ID
        /// </summary>
        public sealed partial class CombinerByContiguousGroupId : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to group by
            /// </summary>
            public string[] GroupKey { get; set; }

            /// <summary>
            /// Columns to group together
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(CombinerByContiguousGroupId)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new CombinerByContiguousGroupIdPipelineStep(output);
            }

            private class CombinerByContiguousGroupIdPipelineStep : ILearningPipelineDataStep
            {
                public CombinerByContiguousGroupIdPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class NormalizeTransformAffineColumn : OneToOneColumn<NormalizeTransformAffineColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool? FixZero { get; set; }

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long? MaxTrainingExamples { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Normalize the columns only if needed
        /// </summary>
        public sealed partial class ConditionalNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public ConditionalNormalizer()
            {
            }
            
            public ConditionalNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public ConditionalNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformAffineColumn>() : new List<Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformAffineColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformAffineColumn>() : new List<Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformAffineColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NormalizeTransformAffineColumn[] Column { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ConditionalNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ConditionalNormalizerPipelineStep(output);
            }

            private class ConditionalNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public ConditionalNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum CacheCachingType
        {
            Memory = 0,
            Disk = 1
        }


        /// <summary>
        /// Caches using the specified cache option.
        /// </summary>
        public sealed partial class DataCache : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Caching strategy
            /// </summary>
            public Transforms.CacheCachingType Caching { get; set; } = Transforms.CacheCachingType.Memory;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output
            {
                /// <summary>
                /// Dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(DataCache)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new DataCachePipelineStep(output);
            }

            private class DataCachePipelineStep : ILearningPipelineDataStep
            {
                public DataCachePipelineStep(Output output)
                {
                    Data = output.OutputData;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Score a dataset with a predictor model
        /// </summary>
        public sealed partial class DatasetScorer
        {


            /// <summary>
            /// The dataset to be scored
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The predictor model to apply to data
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Suffix to append to the score columns
            /// </summary>
            public string Suffix { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// The scored dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ScoredData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The scoring transform
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> ScoringTransform { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Score a dataset with a transform model
        /// </summary>
        public sealed partial class DatasetTransformScorer
        {


            /// <summary>
            /// The dataset to be scored
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// The transform model to apply to data
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();


            public sealed class Output
            {
                /// <summary>
                /// The scored dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ScoredData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The scoring transform
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> ScoringTransform { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Transforms
    {

        public sealed class TermTransformColumn : OneToOneColumn<TermTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Maximum number of terms to keep when auto-training
            /// </summary>
            public int? MaxNumTerms { get; set; }

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, e.g., text sorting will be case sensitive (e.g., 'A' then 'Z' then 'a').
            /// </summary>
            public Transforms.TermTransformSortOrder? Sort { get; set; }

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool? TextKeyValues { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Converts input values (words, numbers, etc.) to index in a dictionary.
        /// </summary>
        public sealed partial class Dictionarizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public Dictionarizer()
            {
            }
            
            public Dictionarizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public Dictionarizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.TermTransformColumn>() : new List<Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.TermTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.TermTransformColumn>() : new List<Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.TermTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.TermTransformColumn[] Column { get; set; }

            /// <summary>
            /// Maximum number of terms to keep per column when auto-training
            /// </summary>
            public int MaxNumTerms { get; set; } = 1000000;

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, e.g., text sorting will be case sensitive (e.g., 'A' then 'Z' then 'a').
            /// </summary>
            public Transforms.TermTransformSortOrder Sort { get; set; } = Transforms.TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool TextKeyValues { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(Dictionarizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new DictionarizerPipelineStep(output);
            }

            private class DictionarizerPipelineStep : ILearningPipelineDataStep
            {
                public DictionarizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Combines all the features into one feature column.
        /// </summary>
        public sealed partial class FeatureCombiner : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Features
            /// </summary>
            public string[] Features { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FeatureCombiner)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new FeatureCombinerPipelineStep(output);
            }

            private class FeatureCombinerPipelineStep : ILearningPipelineDataStep
            {
                public FeatureCombinerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Selects the slots for which the count of non-default values is greater than or equal to a threshold.
        /// </summary>
        public sealed partial class FeatureSelectorByCount : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to use for feature selection
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// If the count of non-default values for a slot is greater than or equal to this threshold, the slot is preserved
            /// </summary>
            public long Count { get; set; } = 1;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FeatureSelectorByCount)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new FeatureSelectorByCountPipelineStep(output);
            }

            private class FeatureSelectorByCountPipelineStep : ILearningPipelineDataStep
            {
                public FeatureSelectorByCountPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Selects the top k slots across all specified columns ordered by their mutual information with the label column.
        /// </summary>
        public sealed partial class FeatureSelectorByMutualInformation : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to use for feature selection
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The maximum number of slots to preserve in output
            /// </summary>
            public int SlotsInOutput { get; set; } = 1000;

            /// <summary>
            /// Max number of bins for R4/R8 columns, power of 2 recommended
            /// </summary>
            public int NumBins { get; set; } = 256;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(FeatureSelectorByMutualInformation)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new FeatureSelectorByMutualInformationPipelineStep(output);
            }

            private class FeatureSelectorByMutualInformationPipelineStep : ILearningPipelineDataStep
            {
                public FeatureSelectorByMutualInformationPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class LpNormNormalizerTransformGcnColumn : OneToOneColumn<LpNormNormalizerTransformGcnColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Normalize by standard deviation rather than L2 norm
            /// </summary>
            public bool? UseStdDev { get; set; }

            /// <summary>
            /// Scale features by this value
            /// </summary>
            public float? Scale { get; set; }

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool? SubMean { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Performs a global contrast normalization on input values: Y = (s * X - M) / D, where s is a scale, M is mean and D is either L2 norm or standard deviation.
        /// </summary>
        public sealed partial class GlobalContrastNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public GlobalContrastNormalizer()
            {
            }
            
            public GlobalContrastNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public GlobalContrastNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.LpNormNormalizerTransformGcnColumn>() : new List<Transforms.LpNormNormalizerTransformGcnColumn>(Column);
                list.Add(OneToOneColumn<Transforms.LpNormNormalizerTransformGcnColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.LpNormNormalizerTransformGcnColumn>() : new List<Transforms.LpNormNormalizerTransformGcnColumn>(Column);
                list.Add(OneToOneColumn<Transforms.LpNormNormalizerTransformGcnColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.LpNormNormalizerTransformGcnColumn[] Column { get; set; }

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool SubMean { get; set; } = true;

            /// <summary>
            /// Normalize by standard deviation rather than L2 norm
            /// </summary>
            public bool UseStdDev { get; set; } = false;

            /// <summary>
            /// Scale features by this value
            /// </summary>
            public float Scale { get; set; } = 1f;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(GlobalContrastNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new GlobalContrastNormalizerPipelineStep(output);
            }

            private class GlobalContrastNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public GlobalContrastNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class HashJoinTransformColumn : OneToOneColumn<HashJoinTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Whether the values need to be combined for a single hash
            /// </summary>
            public bool? Join { get; set; }

            /// <summary>
            /// Which slots should be combined together. Example: 0,3,5;0,1;3;2,1,0. Overrides 'join'.
            /// </summary>
            public string CustomSlotMap { get; set; }

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 31, inclusive.
            /// </summary>
            public int? HashBits { get; set; }

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint? Seed { get; set; }

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool? Ordered { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Converts column values into hashes. This transform accepts both numeric and text inputs, both single and vector-valued columns. This is a part of the Dracula transform.
        /// </summary>
        public sealed partial class HashConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public HashConverter()
            {
            }
            
            public HashConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public HashConverter(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.HashJoinTransformColumn>() : new List<Transforms.HashJoinTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.HashJoinTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.HashJoinTransformColumn>() : new List<Transforms.HashJoinTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.HashJoinTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.HashJoinTransformColumn[] Column { get; set; }

            /// <summary>
            /// Whether the values need to be combined for a single hash
            /// </summary>
            public bool Join { get; set; } = true;

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 31, inclusive.
            /// </summary>
            public int HashBits { get; set; } = 31;

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint Seed { get; set; } = 314489979;

            /// <summary>
            /// Whether the position of each term should be included in the hash
            /// </summary>
            public bool Ordered { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(HashConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new HashConverterPipelineStep(output);
            }

            private class HashConverterPipelineStep : ILearningPipelineDataStep
            {
                public HashConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class KeyToValueTransformColumn : OneToOneColumn<KeyToValueTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// KeyToValueTransform utilizes KeyValues metadata to map key indices to the corresponding values in the KeyValues metadata.
        /// </summary>
        public sealed partial class KeyToTextConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public KeyToTextConverter()
            {
            }
            
            public KeyToTextConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public KeyToTextConverter(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.KeyToValueTransformColumn>() : new List<Transforms.KeyToValueTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.KeyToValueTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.KeyToValueTransformColumn>() : new List<Transforms.KeyToValueTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.KeyToValueTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.KeyToValueTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(KeyToTextConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new KeyToTextConverterPipelineStep(output);
            }

            private class KeyToTextConverterPipelineStep : ILearningPipelineDataStep
            {
                public KeyToTextConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Transforms the label to either key or bool (if needed) to make it suitable for classification.
        /// </summary>
        public sealed partial class LabelColumnKeyBooleanConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Convert the key values to text
            /// </summary>
            public bool TextKeyValues { get; set; } = true;

            /// <summary>
            /// The label column
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LabelColumnKeyBooleanConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new LabelColumnKeyBooleanConverterPipelineStep(output);
            }

            private class LabelColumnKeyBooleanConverterPipelineStep : ILearningPipelineDataStep
            {
                public LabelColumnKeyBooleanConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class LabelIndicatorTransformColumn : OneToOneColumn<LabelIndicatorTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The positive example class for binary classification.
            /// </summary>
            public int? ClassIndex { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Label remapper used by OVA
        /// </summary>
        public sealed partial class LabelIndicator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public LabelIndicator()
            {
            }
            
            public LabelIndicator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LabelIndicator(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.LabelIndicatorTransformColumn>() : new List<Transforms.LabelIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.LabelIndicatorTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.LabelIndicatorTransformColumn>() : new List<Transforms.LabelIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.LabelIndicatorTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.LabelIndicatorTransformColumn[] Column { get; set; }

            /// <summary>
            /// Label of the positive class.
            /// </summary>
            public int ClassIndex { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LabelIndicator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new LabelIndicatorPipelineStep(output);
            }

            private class LabelIndicatorPipelineStep : ILearningPipelineDataStep
            {
                public LabelIndicatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Transforms the label to float to make it suitable for regression.
        /// </summary>
        public sealed partial class LabelToFloatConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The label column
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LabelToFloatConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new LabelToFloatConverterPipelineStep(output);
            }

            private class LabelToFloatConverterPipelineStep : ILearningPipelineDataStep
            {
                public LabelToFloatConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class NormalizeTransformLogNormalColumn : OneToOneColumn<NormalizeTransformLogNormalColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long? MaxTrainingExamples { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Normalizes the data based on the computed mean and variance of the logarithm of the data.
        /// </summary>
        public sealed partial class LogMeanVarianceNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public LogMeanVarianceNormalizer()
            {
            }
            
            public LogMeanVarianceNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LogMeanVarianceNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformLogNormalColumn>() : new List<Transforms.NormalizeTransformLogNormalColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformLogNormalColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformLogNormalColumn>() : new List<Transforms.NormalizeTransformLogNormalColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformLogNormalColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// Whether to use CDF as the output
            /// </summary>
            public bool UseCdf { get; set; } = true;

            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NormalizeTransformLogNormalColumn[] Column { get; set; }

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LogMeanVarianceNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new LogMeanVarianceNormalizerPipelineStep(output);
            }

            private class LogMeanVarianceNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public LogMeanVarianceNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum LpNormNormalizerTransformNormalizerKind : byte
        {
            L2Norm = 0,
            StdDev = 1,
            L1Norm = 2,
            LInf = 3
        }


        public sealed class LpNormNormalizerTransformColumn : OneToOneColumn<LpNormNormalizerTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The norm to use to normalize each sample
            /// </summary>
            public Transforms.LpNormNormalizerTransformNormalizerKind? NormKind { get; set; }

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool? SubMean { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Normalize vectors (rows) individually by rescaling them to unit norm (L2, L1 or LInf). Performs the following operation on a vector X: Y = (X - M) / D, where M is mean and D is either L2 norm, L1 norm or LInf norm.
        /// </summary>
        public sealed partial class LpNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public LpNormalizer()
            {
            }
            
            public LpNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public LpNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.LpNormNormalizerTransformColumn>() : new List<Transforms.LpNormNormalizerTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.LpNormNormalizerTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.LpNormNormalizerTransformColumn>() : new List<Transforms.LpNormNormalizerTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.LpNormNormalizerTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.LpNormNormalizerTransformColumn[] Column { get; set; }

            /// <summary>
            /// The norm to use to normalize each sample
            /// </summary>
            public Transforms.LpNormNormalizerTransformNormalizerKind NormKind { get; set; } = Transforms.LpNormNormalizerTransformNormalizerKind.L2Norm;

            /// <summary>
            /// Subtract mean from each value before normalizing
            /// </summary>
            public bool SubMean { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(LpNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new LpNormalizerPipelineStep(output);
            }

            private class LpNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public LpNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Combines a sequence of TransformModels and a PredictorModel into a single PredictorModel.
        /// </summary>
        public sealed partial class ManyHeterogeneousModelCombiner
        {


            /// <summary>
            /// Transform model
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModels { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// Predictor model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// Predictor model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Normalizes the data based on the computed mean and variance of the data.
        /// </summary>
        public sealed partial class MeanVarianceNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public MeanVarianceNormalizer()
            {
            }
            
            public MeanVarianceNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MeanVarianceNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformAffineColumn>() : new List<Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformAffineColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformAffineColumn>() : new List<Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformAffineColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// Whether to use CDF as the output
            /// </summary>
            public bool UseCdf { get; set; } = false;

            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NormalizeTransformAffineColumn[] Column { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MeanVarianceNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MeanVarianceNormalizerPipelineStep(output);
            }

            private class MeanVarianceNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public MeanVarianceNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Normalizes the data based on the observed minimum and maximum values of the data.
        /// </summary>
        public sealed partial class MinMaxNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public MinMaxNormalizer()
            {
            }
            
            public MinMaxNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MinMaxNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformAffineColumn>() : new List<Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformAffineColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformAffineColumn>() : new List<Transforms.NormalizeTransformAffineColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformAffineColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NormalizeTransformAffineColumn[] Column { get; set; }

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MinMaxNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MinMaxNormalizerPipelineStep(output);
            }

            private class MinMaxNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public MinMaxNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum NAHandleTransformReplacementKind
        {
            Default = 0,
            Def = 0,
            DefaultValue = 0,
            Mean = 1,
            Minimum = 2,
            Min = 2,
            Maximum = 3,
            Max = 3
        }


        public sealed class NAHandleTransformColumn : OneToOneColumn<NAHandleTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public Transforms.NAHandleTransformReplacementKind? Kind { get; set; }

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool? ImputeBySlot { get; set; }

            /// <summary>
            /// Whether or not to concatenate an indicator vector column to the value column
            /// </summary>
            public bool? ConcatIndicator { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Handle missing values by replacing them with either the default value or the mean/min/max value (for non-text columns only). An indicator column can optionally be concatenated, if theinput column type is numeric.
        /// </summary>
        public sealed partial class MissingValueHandler : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public MissingValueHandler()
            {
            }
            
            public MissingValueHandler(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValueHandler(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NAHandleTransformColumn>() : new List<Transforms.NAHandleTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NAHandleTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NAHandleTransformColumn>() : new List<Transforms.NAHandleTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NAHandleTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:rep:src)
            /// </summary>
            public Transforms.NAHandleTransformColumn[] Column { get; set; }

            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public Transforms.NAHandleTransformReplacementKind ReplaceWith { get; set; } = Transforms.NAHandleTransformReplacementKind.Def;

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool ImputeBySlot { get; set; } = true;

            /// <summary>
            /// Whether or not to concatenate an indicator vector column to the value column
            /// </summary>
            public bool Concat { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MissingValueHandler)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MissingValueHandlerPipelineStep(output);
            }

            private class MissingValueHandlerPipelineStep : ILearningPipelineDataStep
            {
                public MissingValueHandlerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class NAIndicatorTransformColumn : OneToOneColumn<NAIndicatorTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Create a boolean output column with the same number of slots as the input column, where the output value is true if the value in the input column is missing.
        /// </summary>
        public sealed partial class MissingValueIndicator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public MissingValueIndicator()
            {
            }
            
            public MissingValueIndicator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValueIndicator(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NAIndicatorTransformColumn>() : new List<Transforms.NAIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NAIndicatorTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NAIndicatorTransformColumn>() : new List<Transforms.NAIndicatorTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NAIndicatorTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NAIndicatorTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MissingValueIndicator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MissingValueIndicatorPipelineStep(output);
            }

            private class MissingValueIndicatorPipelineStep : ILearningPipelineDataStep
            {
                public MissingValueIndicatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class NADropTransformColumn : OneToOneColumn<NADropTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Removes NAs from vector columns.
        /// </summary>
        public sealed partial class MissingValuesDropper : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public MissingValuesDropper()
            {
            }
            
            public MissingValuesDropper(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValuesDropper(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NADropTransformColumn>() : new List<Transforms.NADropTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NADropTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NADropTransformColumn>() : new List<Transforms.NADropTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NADropTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// Columns to drop the NAs for
            /// </summary>
            public Transforms.NADropTransformColumn[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MissingValuesDropper)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MissingValuesDropperPipelineStep(output);
            }

            private class MissingValuesDropperPipelineStep : ILearningPipelineDataStep
            {
                public MissingValuesDropperPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Filters out rows that contain missing values.
        /// </summary>
        public sealed partial class MissingValuesRowDropper : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Column
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// If true, keep only rows that contain NA values, and filter the rest.
            /// </summary>
            public bool Complement { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MissingValuesRowDropper)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MissingValuesRowDropperPipelineStep(output);
            }

            private class MissingValuesRowDropperPipelineStep : ILearningPipelineDataStep
            {
                public MissingValuesRowDropperPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum NAReplaceTransformReplacementKind
        {
            Default = 0,
            DefaultValue = 0,
            Def = 0,
            Mean = 1,
            Min = 2,
            Minimum = 2,
            Max = 3,
            Maximum = 3,
            SpecifiedValue = 4,
            Val = 4,
            Value = 4
        }


        public sealed class NAReplaceTransformColumn : OneToOneColumn<NAReplaceTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Replacement value for NAs (uses default value if not given)
            /// </summary>
            public string ReplacementString { get; set; }

            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public Transforms.NAReplaceTransformReplacementKind? Kind { get; set; }

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool? Slot { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Create an output column of the same type and size of the input column, where missing values are replaced with either the default value or the mean/min/max value (for non-text columns only).
        /// </summary>
        public sealed partial class MissingValueSubstitutor : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public MissingValueSubstitutor()
            {
            }
            
            public MissingValueSubstitutor(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public MissingValueSubstitutor(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NAReplaceTransformColumn>() : new List<Transforms.NAReplaceTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NAReplaceTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NAReplaceTransformColumn>() : new List<Transforms.NAReplaceTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NAReplaceTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:rep:src)
            /// </summary>
            public Transforms.NAReplaceTransformColumn[] Column { get; set; }

            /// <summary>
            /// The replacement method to utilize
            /// </summary>
            public Transforms.NAReplaceTransformReplacementKind ReplacementKind { get; set; } = Transforms.NAReplaceTransformReplacementKind.Def;

            /// <summary>
            /// Whether to impute values by slot
            /// </summary>
            public bool ImputeBySlot { get; set; } = true;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(MissingValueSubstitutor)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new MissingValueSubstitutorPipelineStep(output);
            }

            private class MissingValueSubstitutorPipelineStep : ILearningPipelineDataStep
            {
                public MissingValueSubstitutorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Combines a sequence of TransformModels into a single model
        /// </summary>
        public sealed partial class ModelCombiner
        {


            /// <summary>
            /// Input models
            /// </summary>
            public ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Models { get; set; } = new ArrayVar<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();


            public sealed class Output
            {
                /// <summary>
                /// Combined model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> OutputModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Transforms
    {
        public enum NgramTransformWeightingCriteria
        {
            Tf = 0,
            Idf = 1,
            TfIdf = 2
        }


        public sealed class NgramTransformColumn : OneToOneColumn<NgramTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Maximum ngram length
            /// </summary>
            public int? NgramLength { get; set; }

            /// <summary>
            /// Whether to include all ngram lengths up to NgramLength or only NgramLength
            /// </summary>
            public bool? AllLengths { get; set; }

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int? SkipLength { get; set; }

            /// <summary>
            /// Maximum number of ngrams to store in the dictionary
            /// </summary>
            public int[] MaxNumTerms { get; set; }

            /// <summary>
            /// Statistical measure used to evaluate how important a word is to a document in a corpus
            /// </summary>
            public Transforms.NgramTransformWeightingCriteria? Weighting { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// Produces a bag of counts of ngrams (sequences of consecutive values of length 1-n) in a given vector of keys. It does so by building a dictionary of ngrams and using the id in the dictionary as the index in the bag.
        /// </summary>
        public sealed partial class NGramTranslator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public NGramTranslator()
            {
            }
            
            public NGramTranslator(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public NGramTranslator(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NgramTransformColumn>() : new List<Transforms.NgramTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NgramTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NgramTransformColumn>() : new List<Transforms.NgramTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NgramTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NgramTransformColumn[] Column { get; set; }

            /// <summary>
            /// Maximum ngram length
            /// </summary>
            public int NgramLength { get; set; } = 2;

            /// <summary>
            /// Whether to store all ngram lengths up to ngramLength, or only ngramLength
            /// </summary>
            public bool AllLengths { get; set; } = true;

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int SkipLength { get; set; }

            /// <summary>
            /// Maximum number of ngrams to store in the dictionary
            /// </summary>
            public int[] MaxNumTerms { get; set; } = { 10000000 };

            /// <summary>
            /// The weighting criteria
            /// </summary>
            public Transforms.NgramTransformWeightingCriteria Weighting { get; set; } = Transforms.NgramTransformWeightingCriteria.Tf;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(NGramTranslator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new NGramTranslatorPipelineStep(output);
            }

            private class NGramTranslatorPipelineStep : ILearningPipelineDataStep
            {
                public NGramTranslatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Does nothing.
        /// </summary>
        public sealed partial class NoOperation : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(NoOperation)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new NoOperationPipelineStep(output);
            }

            private class NoOperationPipelineStep : ILearningPipelineDataStep
            {
                public NoOperationPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// If the source column does not exist after deserialization, create a column with the right type and default values.
        /// </summary>
        public sealed partial class OptionalColumnCreator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// New column definition(s)
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(OptionalColumnCreator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new OptionalColumnCreatorPipelineStep(output);
            }

            private class OptionalColumnCreatorPipelineStep : ILearningPipelineDataStep
            {
                public OptionalColumnCreatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Transforms a predicted label column to its original values, unless it is of type bool.
        /// </summary>
        public sealed partial class PredictedLabelColumnOriginalValueConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// The predicted label column
            /// </summary>
            public string PredictedLabelColumn { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(PredictedLabelColumnOriginalValueConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new PredictedLabelColumnOriginalValueConverterPipelineStep(output);
            }

            private class PredictedLabelColumnOriginalValueConverterPipelineStep : ILearningPipelineDataStep
            {
                public PredictedLabelColumnOriginalValueConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        public sealed class GenerateNumberTransformColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Use an auto-incremented integer starting at zero instead of a random number
            /// </summary>
            public bool? UseCounter { get; set; }

            /// <summary>
            /// The random seed
            /// </summary>
            public uint? Seed { get; set; }

        }

        /// <summary>
        /// Adds a column with a generated number sequence.
        /// </summary>
        public sealed partial class RandomNumberGenerator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// New column definition(s) (optional form: name:seed)
            /// </summary>
            public Transforms.GenerateNumberTransformColumn[] Column { get; set; }

            /// <summary>
            /// Use an auto-incremented integer starting at zero instead of a random number
            /// </summary>
            public bool UseCounter { get; set; } = false;

            /// <summary>
            /// The random seed
            /// </summary>
            public uint Seed { get; set; } = 42;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(RandomNumberGenerator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new RandomNumberGeneratorPipelineStep(output);
            }

            private class RandomNumberGeneratorPipelineStep : ILearningPipelineDataStep
            {
                public RandomNumberGeneratorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Filters a dataview on a column of type Single, Double or Key (contiguous). Keeps the values that are in the specified min/max range. NaNs are always filtered out. If the input is a Key type, the min/max are considered percentages of the number of values.
        /// </summary>
        public sealed partial class RowRangeFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Column
            /// </summary>
            public string Column { get; set; }

            /// <summary>
            /// Minimum value (0 to 1 for key types)
            /// </summary>
            public double? Min { get; set; }

            /// <summary>
            /// Maximum value (0 to 1 for key types)
            /// </summary>
            public double? Max { get; set; }

            /// <summary>
            /// If true, keep the values that fall outside the range.
            /// </summary>
            public bool Complement { get; set; } = false;

            /// <summary>
            /// If true, include in the range the values that are equal to min.
            /// </summary>
            public bool IncludeMin { get; set; } = true;

            /// <summary>
            /// If true, include in the range the values that are equal to max.
            /// </summary>
            public bool? IncludeMax { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(RowRangeFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new RowRangeFilterPipelineStep(output);
            }

            private class RowRangeFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowRangeFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Allows limiting input to a subset of rows at an optional offset.  Can be used to implement data paging.
        /// </summary>
        public sealed partial class RowSkipAndTakeFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Number of items to skip
            /// </summary>
            public long? Skip { get; set; }

            /// <summary>
            /// Number of items to take
            /// </summary>
            public long? Take { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(RowSkipAndTakeFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new RowSkipAndTakeFilterPipelineStep(output);
            }

            private class RowSkipAndTakeFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowSkipAndTakeFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Allows limiting input to a subset of rows by skipping a number of rows.
        /// </summary>
        public sealed partial class RowSkipFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Number of items to skip
            /// </summary>
            public long Count { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(RowSkipFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new RowSkipFilterPipelineStep(output);
            }

            private class RowSkipFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowSkipFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Allows limiting input to a subset of rows by taking N first rows.
        /// </summary>
        public sealed partial class RowTakeFilter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Number of items to take
            /// </summary>
            public long Count { get; set; } = 9223372036854775807;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(RowTakeFilter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new RowTakeFilterPipelineStep(output);
            }

            private class RowTakeFilterPipelineStep : ILearningPipelineDataStep
            {
                public RowTakeFilterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Selects only the last score columns and the extra columns specified in the arguments.
        /// </summary>
        public sealed partial class ScoreColumnSelector : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Extra columns to write
            /// </summary>
            public string[] ExtraColumns { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(ScoreColumnSelector)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new ScoreColumnSelectorPipelineStep(output);
            }

            private class ScoreColumnSelectorPipelineStep : ILearningPipelineDataStep
            {
                public ScoreColumnSelectorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Turn the predictor model into a transform model
        /// </summary>
        public sealed partial class Scorer
        {


            /// <summary>
            /// The predictor model to turn into a transform
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// The scored dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> ScoredData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// The scoring transform
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> ScoringTransform { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
        }
    }

    namespace Transforms
    {
        public enum UngroupTransformUngroupMode
        {
            Inner = 0,
            Outer = 1,
            First = 2
        }


        /// <summary>
        /// Un-groups vector columns into sequences of rows, inverse of Group transform
        /// </summary>
        public sealed partial class Segregator : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Columns to unroll, or 'pivot'
            /// </summary>
            public string[] Column { get; set; }

            /// <summary>
            /// Specifies how to unroll multiple pivot columns of different size.
            /// </summary>
            public Transforms.UngroupTransformUngroupMode Mode { get; set; } = Transforms.UngroupTransformUngroupMode.Inner;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(Segregator)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new SegregatorPipelineStep(output);
            }

            private class SegregatorPipelineStep : ILearningPipelineDataStep
            {
                public SegregatorPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Uses a pretrained sentiment model to score input strings
        /// </summary>
        public sealed partial class SentimentAnalyzer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Name of the source column.
            /// </summary>
            public string Source { get; set; }

            /// <summary>
            /// Name of the new column.
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(SentimentAnalyzer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new SentimentAnalyzerPipelineStep(output);
            }

            private class SentimentAnalyzerPipelineStep : ILearningPipelineDataStep
            {
                public SentimentAnalyzerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Similar to BinNormalizer, but calculates bins based on correlation with the label column, not equi-density. The new value is bin_number / number_of_bins.
        /// </summary>
        public sealed partial class SupervisedBinNormalizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public SupervisedBinNormalizer()
            {
            }
            
            public SupervisedBinNormalizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public SupervisedBinNormalizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformBinColumn>() : new List<Transforms.NormalizeTransformBinColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformBinColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.NormalizeTransformBinColumn>() : new List<Transforms.NormalizeTransformBinColumn>(Column);
                list.Add(OneToOneColumn<Transforms.NormalizeTransformBinColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// Label column for supervised binning
            /// </summary>
            public string LabelColumn { get; set; }

            /// <summary>
            /// Minimum number of examples per bin
            /// </summary>
            public int MinBinSize { get; set; } = 10;

            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.NormalizeTransformBinColumn[] Column { get; set; }

            /// <summary>
            /// Max number of bins, power of 2 recommended
            /// </summary>
            public int NumBins { get; set; } = 1024;

            /// <summary>
            /// Whether to map zero to zero, preserving sparsity
            /// </summary>
            public bool FixZero { get; set; } = true;

            /// <summary>
            /// Max number of examples used to train the normalizer
            /// </summary>
            public long MaxTrainingExamples { get; set; } = 1000000000;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(SupervisedBinNormalizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new SupervisedBinNormalizerPipelineStep(output);
            }

            private class SupervisedBinNormalizerPipelineStep : ILearningPipelineDataStep
            {
                public SupervisedBinNormalizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {
        public enum TextTransformLanguage
        {
            English = 1,
            French = 2,
            German = 3,
            Dutch = 4,
            Italian = 5,
            Spanish = 6,
            Japanese = 7
        }

        public enum TextNormalizerTransformCaseNormalizationMode
        {
            Lower = 0,
            Upper = 1,
            None = 2
        }

        public enum TextTransformTextNormKind
        {
            None = 0,
            L1 = 1,
            L2 = 2,
            LInf = 3
        }


        public sealed class TextTransformColumn : ManyToOneColumn<TextTransformColumn>, IManyToOneColumn
        {
            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string[] Source { get; set; }

        }

        public sealed class TermLoaderArguments
        {
            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, e.g., text sorting will be case sensitive (e.g., 'A' then 'Z' then 'a').
            /// </summary>
            public Transforms.TermTransformSortOrder Sort { get; set; } = Transforms.TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Drop unknown terms instead of mapping them to NA term.
            /// </summary>
            public bool DropUnknowns { get; set; } = false;

        }

        /// <summary>
        /// A transform that turns a collection of text documents into numerical feature vectors. The feature vectors are normalized counts of (word and/or character) ngrams in a given tokenized text.
        /// </summary>
        public sealed partial class TextFeaturizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public TextFeaturizer()
            {
            }
            
            public TextFeaturizer(string outputColumn, params string[] inputColumns)
            {
                AddColumn(outputColumn, inputColumns);
            }
            
            public void AddColumn(string name, params string[] source)
            {
                Column = ManyToOneColumn<Transforms.TextTransformColumn>.Create(name, source);
            }


            /// <summary>
            /// New column definition (optional form: name:srcs).
            /// </summary>
            public Transforms.TextTransformColumn Column { get; set; }

            /// <summary>
            /// Dataset language or 'AutoDetect' to detect language per row.
            /// </summary>
            public Transforms.TextTransformLanguage Language { get; set; } = Transforms.TextTransformLanguage.English;

            /// <summary>
            /// Stopwords remover.
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public StopWordsRemover StopWordsRemover { get; set; }

            /// <summary>
            /// Casing text using the rules of the invariant culture.
            /// </summary>
            public Transforms.TextNormalizerTransformCaseNormalizationMode TextCase { get; set; } = Transforms.TextNormalizerTransformCaseNormalizationMode.Lower;

            /// <summary>
            /// Whether to keep diacritical marks or remove them.
            /// </summary>
            public bool KeepDiacritics { get; set; } = false;

            /// <summary>
            /// Whether to keep punctuation marks or remove them.
            /// </summary>
            public bool KeepPunctuations { get; set; } = true;

            /// <summary>
            /// Whether to keep numbers or remove them.
            /// </summary>
            public bool KeepNumbers { get; set; } = true;

            /// <summary>
            /// Whether to output the transformed text tokens as an additional column.
            /// </summary>
            public bool OutputTokens { get; set; } = false;

            /// <summary>
            /// A dictionary of whitelisted terms.
            /// </summary>
            public Transforms.TermLoaderArguments Dictionary { get; set; }

            /// <summary>
            /// Ngram feature extractor to use for words (WordBag/WordHashBag).
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public NgramExtractor WordFeatureExtractor { get; set; } = new NGramNgramExtractor();

            /// <summary>
            /// Ngram feature extractor to use for characters (WordBag/WordHashBag).
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public NgramExtractor CharFeatureExtractor { get; set; } = new NGramNgramExtractor() { NgramLength = 3, AllLengths = false };

            /// <summary>
            /// Normalize vectors (rows) individually by rescaling them to unit norm.
            /// </summary>
            public Transforms.TextTransformTextNormKind VectorNormalizer { get; set; } = Transforms.TextTransformTextNormKind.L2;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(TextFeaturizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new TextFeaturizerPipelineStep(output);
            }

            private class TextFeaturizerPipelineStep : ILearningPipelineDataStep
            {
                public TextFeaturizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Converts input values (words, numbers, etc.) to index in a dictionary.
        /// </summary>
        public sealed partial class TextToKeyConverter : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public TextToKeyConverter()
            {
            }
            
            public TextToKeyConverter(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public TextToKeyConverter(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.TermTransformColumn>() : new List<Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.TermTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.TermTransformColumn>() : new List<Transforms.TermTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.TermTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s) (optional form: name:src)
            /// </summary>
            public Transforms.TermTransformColumn[] Column { get; set; }

            /// <summary>
            /// Maximum number of terms to keep per column when auto-training
            /// </summary>
            public int MaxNumTerms { get; set; } = 1000000;

            /// <summary>
            /// List of terms
            /// </summary>
            public string[] Term { get; set; }

            /// <summary>
            /// How items should be ordered when vectorized. By default, they will be in the order encountered. If by value items are sorted according to their default comparison, e.g., text sorting will be case sensitive (e.g., 'A' then 'Z' then 'a').
            /// </summary>
            public Transforms.TermTransformSortOrder Sort { get; set; } = Transforms.TermTransformSortOrder.Occurrence;

            /// <summary>
            /// Whether key value metadata should be text, regardless of the actual input type
            /// </summary>
            public bool TextKeyValues { get; set; } = false;

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(TextToKeyConverter)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new TextToKeyConverterPipelineStep(output);
            }

            private class TextToKeyConverterPipelineStep : ILearningPipelineDataStep
            {
                public TextToKeyConverterPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Split the dataset into train and test sets
        /// </summary>
        public sealed partial class TrainTestDatasetSplitter
        {


            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Fraction of training data
            /// </summary>
            public float Fraction { get; set; } = 0.8f;

            /// <summary>
            /// Stratification column
            /// </summary>
            public string StratificationColumn { get; set; }


            public sealed class Output
            {
                /// <summary>
                /// Training data
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TrainData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Testing data
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> TestData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Trains a tree ensemble, or loads it from a file, then maps a numeric feature vector to three outputs: 1. A vector containing the individual tree outputs of the tree ensemble. 2. A vector indicating the leaves that the feature vector falls on in the tree ensemble. 3. A vector indicating the paths that the feature vector falls on in the tree ensemble. If a both a model file and a trainer are specified - will use the model file. If neither are specified, will train a default FastTree model. This can handle key labels by training a regression model towards their optionally permuted indices.
        /// </summary>
        public sealed partial class TreeLeafFeaturizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.IFeaturizerInput, Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {


            /// <summary>
            /// Output column: The suffix to append to the default column names
            /// </summary>
            public string Suffix { get; set; }

            /// <summary>
            /// If specified, determines the permutation seed for applying this featurizer to a multiclass problem.
            /// </summary>
            public int LabelPermutationSeed { get; set; }

            /// <summary>
            /// Trainer to use
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(TreeLeafFeaturizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new TreeLeafFeaturizerPipelineStep(output);
            }

            private class TreeLeafFeaturizerPipelineStep : ILearningPipelineDataStep
            {
                public TreeLeafFeaturizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Transforms
    {

        /// <summary>
        /// Combines a TransformModel and a PredictorModel into a single PredictorModel.
        /// </summary>
        public sealed partial class TwoHeterogeneousModelCombiner
        {


            /// <summary>
            /// Transform model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> TransformModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            /// <summary>
            /// Predictor model
            /// </summary>
            public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();


            public sealed class Output
            {
                /// <summary>
                /// Predictor model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel> PredictorModel { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.IPredictorModel>();

            }
        }
    }

    namespace Transforms
    {

        public sealed class DelimitedTokenizeTransformColumn : OneToOneColumn<DelimitedTokenizeTransformColumn>, IOneToOneColumn
        {
            /// <summary>
            /// Comma separated set of term separator(s). Commonly: 'space', 'comma', 'semicolon' or other single character.
            /// </summary>
            public string TermSeparators { get; set; }

            /// <summary>
            /// Name of the new column
            /// </summary>
            public string Name { get; set; }

            /// <summary>
            /// Name of the source column
            /// </summary>
            public string Source { get; set; }

        }

        /// <summary>
        /// The input to this transform is text, and the output is a vector of text containing the words (tokens) in the original text. The separator is space, but can be specified as any other character (or multiple characters) if needed.
        /// </summary>
        public sealed partial class WordTokenizer : Microsoft.ML.Runtime.EntryPoints.CommonInputs.ITransformInput, Microsoft.ML.ILearningPipelineItem
        {

            public WordTokenizer()
            {
            }
            
            public WordTokenizer(params string[] inputColumns)
            {
                if (inputColumns != null)
                {
                    foreach (string input in inputColumns)
                    {
                        AddColumn(input);
                    }
                }
            }
            
            public WordTokenizer(params ValueTuple<string, string>[] inputOutputColumns)
            {
                if (inputOutputColumns != null)
                {
                    foreach (ValueTuple<string, string> inputOutput in inputOutputColumns)
                    {
                        AddColumn(inputOutput.Item2, inputOutput.Item1);
                    }
                }
            }
            
            public void AddColumn(string source)
            {
                var list = Column == null ? new List<Transforms.DelimitedTokenizeTransformColumn>() : new List<Transforms.DelimitedTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.DelimitedTokenizeTransformColumn>.Create(source));
                Column = list.ToArray();
            }

            public void AddColumn(string name, string source)
            {
                var list = Column == null ? new List<Transforms.DelimitedTokenizeTransformColumn>() : new List<Transforms.DelimitedTokenizeTransformColumn>(Column);
                list.Add(OneToOneColumn<Transforms.DelimitedTokenizeTransformColumn>.Create(name, source));
                Column = list.ToArray();
            }


            /// <summary>
            /// New column definition(s)
            /// </summary>
            public Transforms.DelimitedTokenizeTransformColumn[] Column { get; set; }

            /// <summary>
            /// Comma separated set of term separator(s). Commonly: 'space', 'comma', 'semicolon' or other single character.
            /// </summary>
            public string TermSeparators { get; set; } = "space";

            /// <summary>
            /// Input dataset
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> Data { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();


            public sealed class Output : Microsoft.ML.Runtime.EntryPoints.CommonOutputs.ITransformOutput
            {
                /// <summary>
                /// Transformed dataset
                /// </summary>
                public Var<Microsoft.ML.Runtime.Data.IDataView> OutputData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

                /// <summary>
                /// Transform model
                /// </summary>
                public Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel> Model { get; set; } = new Var<Microsoft.ML.Runtime.EntryPoints.ITransformModel>();

            }
            public ILearningPipelineStep ApplyStep(ILearningPipelineStep previousStep, Experiment experiment)
            {
                if (!(previousStep is ILearningPipelineDataStep dataStep))
                {
                    throw new InvalidOperationException($"{ nameof(WordTokenizer)} only supports an { nameof(ILearningPipelineDataStep)} as an input.");
                }

                Data = dataStep.Data;
                Output output = experiment.Add(this);
                return new WordTokenizerPipelineStep(output);
            }

            private class WordTokenizerPipelineStep : ILearningPipelineDataStep
            {
                public WordTokenizerPipelineStep(Output output)
                {
                    Data = output.OutputData;
                    Model = output.Model;
                }

                public Var<IDataView> Data { get; }
                public Var<ITransformModel> Model { get; }
            }
        }
    }

    namespace Runtime
    {
        public abstract class CalibratorTrainer : ComponentKind {}



        /// <summary>
        /// 
        /// </summary>
        public sealed class FixedPlattCalibratorCalibratorTrainer : CalibratorTrainer
        {
            /// <summary>
            /// The slope parameter of f(x) = 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Slope { get; set; } = 1d;

            /// <summary>
            /// The offset parameter of f(x) = 1 / (1 + exp(-slope * x + offset)
            /// </summary>
            public double Offset { get; set; }

            internal override string ComponentName => "FixedPlattCalibrator";
        }



        /// <summary>
        /// 
        /// </summary>
        public sealed class NaiveCalibratorCalibratorTrainer : CalibratorTrainer
        {
            internal override string ComponentName => "NaiveCalibrator";
        }



        /// <summary>
        /// 
        /// </summary>
        public sealed class PavCalibratorCalibratorTrainer : CalibratorTrainer
        {
            internal override string ComponentName => "PavCalibrator";
        }



        /// <summary>
        /// Platt calibration.
        /// </summary>
        public sealed class PlattCalibratorCalibratorTrainer : CalibratorTrainer
        {
            internal override string ComponentName => "PlattCalibrator";
        }

        public abstract class ClassificationLossFunction : ComponentKind {}



        /// <summary>
        /// Exponential loss.
        /// </summary>
        public sealed class ExpLossClassificationLossFunction : ClassificationLossFunction
        {
            /// <summary>
            /// Beta (dilation)
            /// </summary>
            public float Beta { get; set; } = 1f;

            internal override string ComponentName => "ExpLoss";
        }



        /// <summary>
        /// Hinge loss.
        /// </summary>
        public sealed class HingeLossClassificationLossFunction : ClassificationLossFunction
        {
            /// <summary>
            /// Margin value
            /// </summary>
            public float Margin { get; set; } = 1f;

            internal override string ComponentName => "HingeLoss";
        }



        /// <summary>
        /// Log loss.
        /// </summary>
        public sealed class LogLossClassificationLossFunction : ClassificationLossFunction
        {
            internal override string ComponentName => "LogLoss";
        }



        /// <summary>
        /// Smoothed Hinge loss.
        /// </summary>
        public sealed class SmoothedHingeLossClassificationLossFunction : ClassificationLossFunction
        {
            /// <summary>
            /// Smoothing constant
            /// </summary>
            public float SmoothingConst { get; set; } = 1f;

            internal override string ComponentName => "SmoothedHingeLoss";
        }

        public abstract class EarlyStoppingCriterion : ComponentKind {}



        /// <summary>
        /// Stop in case of loss of generality.
        /// </summary>
        public sealed class GLEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Threshold in range [0,1].
            /// </summary>
            [TlcModule.Range(Min = 0f, Max = 1f)]
            public float Threshold { get; set; } = 0.01f;

            internal override string ComponentName => "GL";
        }



        /// <summary>
        /// Stops in case of low progress.
        /// </summary>
        public sealed class LPEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Threshold in range [0,1].
            /// </summary>
            [TlcModule.Range(Min = 0f, Max = 1f)]
            public float Threshold { get; set; } = 0.01f;

            /// <summary>
            /// The window size.
            /// </summary>
            [TlcModule.Range(Inf = 0)]
            public int WindowSize { get; set; } = 5;

            internal override string ComponentName => "LP";
        }



        /// <summary>
        /// Stops in case of generality to progress ration exceeds threshold.
        /// </summary>
        public sealed class PQEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Threshold in range [0,1].
            /// </summary>
            [TlcModule.Range(Min = 0f, Max = 1f)]
            public float Threshold { get; set; } = 0.01f;

            /// <summary>
            /// The window size.
            /// </summary>
            [TlcModule.Range(Inf = 0)]
            public int WindowSize { get; set; } = 5;

            internal override string ComponentName => "PQ";
        }



        /// <summary>
        /// Stop if validation score exceeds threshold value.
        /// </summary>
        public sealed class TREarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// Tolerance threshold. (Non negative value)
            /// </summary>
            [TlcModule.Range(Min = 0f)]
            public float Threshold { get; set; } = 0.01f;

            internal override string ComponentName => "TR";
        }



        /// <summary>
        /// Stops in case of consecutive loss in generality.
        /// </summary>
        public sealed class UPEarlyStoppingCriterion : EarlyStoppingCriterion
        {
            /// <summary>
            /// The window size.
            /// </summary>
            [TlcModule.Range(Inf = 0)]
            public int WindowSize { get; set; } = 5;

            internal override string ComponentName => "UP";
        }

        public abstract class FastTreeTrainer : ComponentKind {}



        /// <summary>
        /// Uses a logit-boost boosted tree learner to perform binary classification.
        /// </summary>
        public sealed class FastTreeBinaryClassificationFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Should we use derivatives optimized for unbalanced sets
            /// </summary>
            public bool UnbalancedSets { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeBinaryClassification";
        }



        /// <summary>
        /// Trains gradient boosted decision trees to the LambdaRank quasi-gradient.
        /// </summary>
        public sealed class FastTreeRankingFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Comma seperated list of gains associated to each relevance label.
            /// </summary>
            public string CustomGains { get; set; } = "0,3,7,15,31";

            /// <summary>
            /// Train DCG instead of NDCG
            /// </summary>
            public bool TrainDcg { get; set; } = false;

            /// <summary>
            /// The sorting algorithm to use for DCG and LambdaMart calculations [DescendingStablePessimistic/DescendingStable/DescendingReverse/DescendingDotNet]
            /// </summary>
            public string SortingAlgorithm { get; set; } = "DescendingStablePessimistic";

            /// <summary>
            /// max-NDCG truncation to use in the Lambda Mart algorithm
            /// </summary>
            public int LambdaMartMaxTruncation { get; set; } = 100;

            /// <summary>
            /// Use shifted NDCG
            /// </summary>
            public bool ShiftedNdcg { get; set; } = false;

            /// <summary>
            /// Cost function parameter (w/c)
            /// </summary>
            public char CostFunctionParam { get; set; } = 'w';

            /// <summary>
            /// Distance weight 2 adjustment to cost
            /// </summary>
            public bool DistanceWeight2 { get; set; } = false;

            /// <summary>
            /// Normalize query lambdas
            /// </summary>
            public bool NormalizeQueryLambdas { get; set; } = false;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeRanking";
        }



        /// <summary>
        /// Trains gradient boosted decision trees to fit target values using least-squares.
        /// </summary>
        public sealed class FastTreeRegressionFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; } = 1;

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeRegression";
        }



        /// <summary>
        /// Trains gradient boosted decision trees to fit target values using a Tweedie loss function. This learner is a generalization of Poisson, compound Poisson, and gamma regression.
        /// </summary>
        public sealed class FastTreeTweedieRegressionFastTreeTrainer : FastTreeTrainer
        {
            /// <summary>
            /// Index parameter for the Tweedie distribution, in the range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate values are compound Poisson loss.
            /// </summary>
            public double Index { get; set; } = 1.5d;

            /// <summary>
            /// Use best regression step trees?
            /// </summary>
            public bool BestStepRankingRegressionTrees { get; set; } = false;

            /// <summary>
            /// Should we use line search for a step size
            /// </summary>
            public bool UseLineSearch { get; set; } = false;

            /// <summary>
            /// Number of post-bracket line search steps
            /// </summary>
            public int NumPostBracketSteps { get; set; }

            /// <summary>
            /// Minimum line search step size
            /// </summary>
            public double MinStepSize { get; set; }

            /// <summary>
            /// Optimization algorithm to be used (GradientDescent, AcceleratedGradientDescent)
            /// </summary>
            public Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType OptimizationAlgorithm { get; set; } = Microsoft.ML.Trainers.BoostedTreeArgsOptimizationAlgorithmType.GradientDescent;

            /// <summary>
            /// Early stopping rule. (Validation set (/valid) is required.)
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public EarlyStoppingCriterion EarlyStoppingRule { get; set; }

            /// <summary>
            /// Early stopping metrics. (For regression, 1: L1, 2:L2; for ranking, 1:NDCG@1, 3:NDCG@3)
            /// </summary>
            public int EarlyStoppingMetrics { get; set; }

            /// <summary>
            /// Enable post-training pruning to avoid overfitting. (a validation set is required)
            /// </summary>
            public bool EnablePruning { get; set; } = false;

            /// <summary>
            /// Use window and tolerance for pruning
            /// </summary>
            public bool UseTolerantPruning { get; set; } = false;

            /// <summary>
            /// The tolerance threshold for pruning
            /// </summary>
            public double PruningThreshold { get; set; } = 0.004d;

            /// <summary>
            /// The moving window size for pruning
            /// </summary>
            public int PruningWindowSize { get; set; } = 5;

            /// <summary>
            /// The learning rate
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("LearningRates", 0.025f, 0.4f, isLogScale:true)]
            public double LearningRates { get; set; } = 0.2d;

            /// <summary>
            /// Shrinkage
            /// </summary>
            [TlcModule.SweepableFloatParamAttribute("Shrinkage", 0.025f, 4f, isLogScale:true)]
            public double Shrinkage { get; set; } = 1d;

            /// <summary>
            /// Dropout rate for tree regularization
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("DropoutRate", new object[]{0f, 1E-09f, 0.05f, 0.1f, 0.2f})]
            public double DropoutRate { get; set; }

            /// <summary>
            /// Sample each query 1 in k times in the GetDerivatives function
            /// </summary>
            public int GetDerivativesSampleRate { get; set; } = 1;

            /// <summary>
            /// Write the last ensemble instead of the one determined by early stopping
            /// </summary>
            public bool WriteLastEnsemble { get; set; } = false;

            /// <summary>
            /// Upper bound on absolute value of single tree output
            /// </summary>
            public double MaxTreeOutput { get; set; } = 100d;

            /// <summary>
            /// Training starts from random ordering (determined by /r1)
            /// </summary>
            public bool RandomStart { get; set; } = false;

            /// <summary>
            /// Filter zero lambdas during training
            /// </summary>
            public bool FilterZeroLambdas { get; set; } = false;

            /// <summary>
            /// Freeform defining the scores that should be used as the baseline ranker
            /// </summary>
            public string BaselineScoresFormula { get; set; }

            /// <summary>
            /// Baseline alpha for tradeoffs of risk (0 is normal training)
            /// </summary>
            public string BaselineAlphaRisk { get; set; }

            /// <summary>
            /// The discount freeform which specifies the per position discounts of documents in a query (uses a single variable P for position where P=0 is first position)
            /// </summary>
            public string PositionDiscountFreeform { get; set; }

            /// <summary>
            /// Allows to choose Parallel FastTree Learning Algorithm
            /// </summary>
            [JsonConverter(typeof(ComponentSerializer))]
            public ParallelTraining ParallelTrainer { get; set; } = new SingleParallelTraining();

            /// <summary>
            /// The number of threads to use
            /// </summary>
            public int? NumThreads { get; set; }

            /// <summary>
            /// The seed of the random number generator
            /// </summary>
            public int RngSeed { get; set; } = 123;

            /// <summary>
            /// The seed of the active feature selection
            /// </summary>
            public int FeatureSelectSeed { get; set; } = 123;

            /// <summary>
            /// The entropy (regularization) coefficient between 0 and 1
            /// </summary>
            public double EntropyCoefficient { get; set; }

            /// <summary>
            /// The number of histograms in the pool (between 2 and numLeaves)
            /// </summary>
            public int HistogramPoolSize { get; set; } = -1;

            /// <summary>
            /// Whether to utilize the disk or the data's native transposition facilities (where applicable) when performing the transpose
            /// </summary>
            public bool? DiskTranspose { get; set; }

            /// <summary>
            /// Whether to collectivize features during dataset preparation to speed up training
            /// </summary>
            public bool FeatureFlocks { get; set; } = true;

            /// <summary>
            /// Whether to do split based on multiple categorical feature values.
            /// </summary>
            public bool CategoricalSplit { get; set; } = false;

            /// <summary>
            /// Maximum categorical split groups to consider when splitting on a categorical feature. Split groups are a collection of split points. This is used to reduce overfitting when there many categorical features.
            /// </summary>
            public int MaxCategoricalGroupsPerNode { get; set; } = 64;

            /// <summary>
            /// Maximum categorical split points to consider when splitting on a categorical feature.
            /// </summary>
            public int MaxCategoricalSplitPoints { get; set; } = 64;

            /// <summary>
            /// Minimum categorical docs percentage in a bin to consider for a split.
            /// </summary>
            public double MinDocsPercentageForCategoricalSplit { get; set; } = 0.001d;

            /// <summary>
            /// Minimum categorical doc count in a bin to consider for a split.
            /// </summary>
            public int MinDocsForCategoricalSplit { get; set; } = 100;

            /// <summary>
            /// Bias for calculating gradient for each feature bin for a categorical feature.
            /// </summary>
            public double Bias { get; set; }

            /// <summary>
            /// Bundle low population bins. Bundle.None(0): no bundling, Bundle.AggregateLowPopulation(1): Bundle low population, Bundle.Adjacent(2): Neighbor low population bundle.
            /// </summary>
            public Microsoft.ML.Trainers.Bundle Bundling { get; set; } = Microsoft.ML.Trainers.Bundle.None;

            /// <summary>
            /// Maximum number of distinct values (bins) per feature
            /// </summary>
            public int MaxBins { get; set; } = 255;

            /// <summary>
            /// Sparsity level needed to use sparse feature representation
            /// </summary>
            public double SparsifyThreshold { get; set; } = 0.7d;

            /// <summary>
            /// The feature first use penalty coefficient
            /// </summary>
            public double FeatureFirstUsePenalty { get; set; }

            /// <summary>
            /// The feature re-use penalty (regularization) coefficient
            /// </summary>
            public double FeatureReusePenalty { get; set; }

            /// <summary>
            /// Tree fitting gain confidence requirement (should be in the range [0,1) ).
            /// </summary>
            public double GainConfidenceLevel { get; set; }

            /// <summary>
            /// The temperature of the randomized softmax distribution for choosing the feature
            /// </summary>
            public double SoftmaxTemperature { get; set; }

            /// <summary>
            /// Print execution time breakdown to stdout
            /// </summary>
            public bool ExecutionTimes { get; set; } = false;

            /// <summary>
            /// The max number of leaves in each regression tree
            /// </summary>
            [TlcModule.SweepableLongParamAttribute("NumLeaves", 2, 128, stepSize:4, isLogScale:true)]
            public int NumLeaves { get; set; } = 20;

            /// <summary>
            /// The minimal number of documents allowed in a leaf of a regression tree, out of the subsampled data
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("MinDocumentsInLeafs", new object[]{1, 10, 50})]
            public int MinDocumentsInLeafs { get; set; } = 10;

            /// <summary>
            /// Number of weak hypotheses in the ensemble
            /// </summary>
            [TlcModule.SweepableDiscreteParamAttribute("NumTrees", new object[]{20, 100, 500})]
            public int NumTrees { get; set; } = 100;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each iteration
            /// </summary>
            public double FeatureFraction { get; set; } = 1d;

            /// <summary>
            /// Number of trees in each bag (0 for disabling bagging)
            /// </summary>
            public int BaggingSize { get; set; }

            /// <summary>
            /// Percentage of training examples used in each bag
            /// </summary>
            public double BaggingTrainFraction { get; set; } = 0.7d;

            /// <summary>
            /// The fraction of features (chosen randomly) to use on each split
            /// </summary>
            public double SplitFraction { get; set; } = 1d;

            /// <summary>
            /// Smoothing paramter for tree regularization
            /// </summary>
            public double Smoothing { get; set; }

            /// <summary>
            /// When a root split is impossible, allow training to proceed
            /// </summary>
            public bool AllowEmptyTrees { get; set; } = true;

            /// <summary>
            /// The level of feature compression to use
            /// </summary>
            public int FeatureCompressionLevel { get; set; } = 1;

            /// <summary>
            /// Compress the tree Ensemble
            /// </summary>
            public bool CompressEnsemble { get; set; } = false;

            /// <summary>
            /// Maximum Number of trees after compression
            /// </summary>
            public int MaxTreesAfterCompression { get; set; } = -1;

            /// <summary>
            /// Print metrics graph for the first test set
            /// </summary>
            public bool PrintTestGraph { get; set; } = false;

            /// <summary>
            /// Print Train and Validation metrics in graph
            /// </summary>
            public bool PrintTrainValidGraph { get; set; } = false;

            /// <summary>
            /// Calculate metric values for train/valid/test every k rounds
            /// </summary>
            public int TestFrequency { get; set; } = 2147483647;

            /// <summary>
            /// Column to use for example groupId
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> GroupIdColumn { get; set; }

            /// <summary>
            /// Column to use for example weight
            /// </summary>
            public Microsoft.ML.Runtime.EntryPoints.Optional<string> WeightColumn { get; set; }

            /// <summary>
            /// Column to use for labels
            /// </summary>
            public string LabelColumn { get; set; } = "Label";

            /// <summary>
            /// The data to be used for training
            /// </summary>
            public Var<Microsoft.ML.Runtime.Data.IDataView> TrainingData { get; set; } = new Var<Microsoft.ML.Runtime.Data.IDataView>();

            /// <summary>
            /// Column to use for features
            /// </summary>
            public string FeatureColumn { get; set; } = "Features";

            /// <summary>
            /// Normalize option for the feature column
            /// </summary>
            public Microsoft.ML.Models.NormalizeOption NormalizeFeatures { get; set; } = Microsoft.ML.Models.NormalizeOption.Auto;

            /// <summary>
            /// Whether learner should cache input training data
            /// </summary>
            public Microsoft.ML.Models.CachingOptions Caching { get; set; } = Microsoft.ML.Models.CachingOptions.Auto;

            internal override string ComponentName => "FastTreeTweedieRegression";
        }

        public abstract class NgramExtractor : ComponentKind {}



        /// <summary>
        /// Extracts NGrams from text and convert them to vector using dictionary.
        /// </summary>
        public sealed class NGramNgramExtractor : NgramExtractor
        {
            /// <summary>
            /// Ngram length
            /// </summary>
            public int NgramLength { get; set; } = 1;

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int SkipLength { get; set; }

            /// <summary>
            /// Whether to include all ngram lengths up to NgramLength or only NgramLength
            /// </summary>
            public bool AllLengths { get; set; } = true;

            /// <summary>
            /// Maximum number of ngrams to store in the dictionary
            /// </summary>
            public int[] MaxNumTerms { get; set; } = { 10000000 };

            /// <summary>
            /// The weighting criteria
            /// </summary>
            public Microsoft.ML.Transforms.NgramTransformWeightingCriteria Weighting { get; set; } = Microsoft.ML.Transforms.NgramTransformWeightingCriteria.Tf;

            internal override string ComponentName => "NGram";
        }



        /// <summary>
        /// Extracts NGrams from text and convert them to vector using hashing trick.
        /// </summary>
        public sealed class NGramHashNgramExtractor : NgramExtractor
        {
            /// <summary>
            /// Ngram length
            /// </summary>
            public int NgramLength { get; set; } = 1;

            /// <summary>
            /// Maximum number of tokens to skip when constructing an ngram
            /// </summary>
            public int SkipLength { get; set; }

            /// <summary>
            /// Number of bits to hash into. Must be between 1 and 30, inclusive.
            /// </summary>
            public int HashBits { get; set; } = 16;

            /// <summary>
            /// Hashing seed
            /// </summary>
            public uint Seed { get; set; } = 314489979;

            /// <summary>
            /// Whether the position of each source column should be included in the hash (when there are multiple source columns).
            /// </summary>
            public bool Ordered { get; set; } = true;

            /// <summary>
            /// Limit the number of keys used to generate the slot name to this many. 0 means no invert hashing, -1 means no limit.
            /// </summary>
            public int InvertHash { get; set; }

            /// <summary>
            /// Whether to include all ngram lengths up to ngramLength or only ngramLength
            /// </summary>
            public bool AllLengths { get; set; } = true;

            internal override string ComponentName => "NGramHash";
        }

        public abstract class ParallelTraining : ComponentKind {}



        /// <summary>
        /// Single node machine learning process.
        /// </summary>
        public sealed class SingleParallelTraining : ParallelTraining
        {
            internal override string ComponentName => "Single";
        }

        public abstract class RegressionLossFunction : ComponentKind {}



        /// <summary>
        /// Poisson loss.
        /// </summary>
        public sealed class PoissonLossRegressionLossFunction : RegressionLossFunction
        {
            internal override string ComponentName => "PoissonLoss";
        }



        /// <summary>
        /// Squared loss.
        /// </summary>
        public sealed class SquaredLossRegressionLossFunction : RegressionLossFunction
        {
            internal override string ComponentName => "SquaredLoss";
        }



        /// <summary>
        /// Tweedie loss.
        /// </summary>
        public sealed class TweedieLossRegressionLossFunction : RegressionLossFunction
        {
            /// <summary>
            /// Index parameter for the Tweedie distribution, in the range [1, 2]. 1 is Poisson loss, 2 is gamma loss, and intermediate values are compound Poisson loss.
            /// </summary>
            public double Index { get; set; } = 1.5d;

            internal override string ComponentName => "TweedieLoss";
        }

        public abstract class SDCAClassificationLossFunction : ComponentKind {}



        /// <summary>
        /// Hinge loss.
        /// </summary>
        public sealed class HingeLossSDCAClassificationLossFunction : SDCAClassificationLossFunction
        {
            /// <summary>
            /// Margin value
            /// </summary>
            public float Margin { get; set; } = 1f;

            internal override string ComponentName => "HingeLoss";
        }



        /// <summary>
        /// Log loss.
        /// </summary>
        public sealed class LogLossSDCAClassificationLossFunction : SDCAClassificationLossFunction
        {
            internal override string ComponentName => "LogLoss";
        }



        /// <summary>
        /// Smoothed Hinge loss.
        /// </summary>
        public sealed class SmoothedHingeLossSDCAClassificationLossFunction : SDCAClassificationLossFunction
        {
            /// <summary>
            /// Smoothing constant
            /// </summary>
            public float SmoothingConst { get; set; } = 1f;

            internal override string ComponentName => "SmoothedHingeLoss";
        }

        public abstract class SDCARegressionLossFunction : ComponentKind {}



        /// <summary>
        /// Squared loss.
        /// </summary>
        public sealed class SquaredLossSDCARegressionLossFunction : SDCARegressionLossFunction
        {
            internal override string ComponentName => "SquaredLoss";
        }

        public abstract class StopWordsRemover : ComponentKind {}



        /// <summary>
        /// Remover with list of stopwords specified by the user.
        /// </summary>
        public sealed class CustomStopWordsRemover : StopWordsRemover
        {
            /// <summary>
            /// List of stopwords
            /// </summary>
            public string[] Stopword { get; set; }

            internal override string ComponentName => "Custom";
        }



        /// <summary>
        /// Remover with predefined list of stop words.
        /// </summary>
        public sealed class PredefinedStopWordsRemover : StopWordsRemover
        {
            internal override string ComponentName => "Predefined";
        }

    }
}
#pragma warning restore
