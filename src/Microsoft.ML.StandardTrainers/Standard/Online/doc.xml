<?xml version="1.0" encoding="utf-8"?>
<doc>
  <members>
    
    <member name="OGD">
      <summary>
        Stochastic gradient descent is an optimization method used to train a wide range of models in machine learning. 
        In the ML.Net the implementation of OGD, is for linear regression. 
      </summary>
      <remarks>
        Stochastic gradient descent uses a simple yet efficient iterative technique to fit model coefficients using error gradients for convex loss functions.
        The OnlineGradientDescentRegressor implements the standard (non-batch) SGD, with a choice of loss functions,
        and an option to update the weight vector using the average of the vectors seen over time (averaged argument is set to True by default).
      </remarks>
    </member>
    <example name="OGD">
      <example>
        <code language="csharp">
          new OnlineGradientDescentRegressor
          {
            NumIterations = 10,
            L2RegularizerWeight = 0.6f,
            LossFunction = new PoissonLossRegressionLossFunction()
          }
        </code>
      </example>
    </example>
  </members>
</doc>
