<Project Sdk="Microsoft.NET.Sdk">

  <PropertyGroup>
    <TargetFrameworks>netstandard2.0;net8.0</TargetFrameworks>
    <Nullable>enable</Nullable>
    <IsPackable>true</IsPackable>
    <PackageDescription>Microsoft.ML.Tokenizers contains the implmentation of the tokenization used in the NLP transforms.</PackageDescription>
    <AllowUnsafeBlocks>true</AllowUnsafeBlocks>
  </PropertyGroup>

  <ItemGroup Condition="'$(TargetFramework)' == 'netstandard2.0'">
    <Compile Remove="Utils/Helpers.netcoreapp.cs" />
  </ItemGroup>

  <ItemGroup Condition="'$(TargetFramework)' != 'netstandard2.0'">
    <Compile Remove="Utils/Helpers.netstandard.cs" />
  </ItemGroup>

  <ItemGroup>
    <PackageReference Include="Google.Protobuf" Version="$(GoogleProtobufVersion)" />
    <PackageReference Include="System.Text.Json" Version="$(SystemTextJsonVersion)" />
  </ItemGroup>

  <ItemGroup Condition="'$(TargetFramework)' == 'netstandard2.0'">
    <PackageReference Include="Microsoft.Bcl.HashCode" Version="$(MicrosoftBclHashCodeVersion)" />
  </ItemGroup>

  <UsingTask TaskName="CompressFile"
    TaskFactory="RoslynCodeTaskFactory"
    AssemblyFile="$(MSBuildToolsPath)\Microsoft.Build.Tasks.Core.dll" >
    <ParameterGroup>
      <Files ParameterType="Microsoft.Build.Framework.ITaskItem[]" Required="true" />
    </ParameterGroup>
    <Task>
      <Using Namespace="System.IO" />
      <Using Namespace="System.IO.Compression" />
      <Code Type="Fragment" Language="cs">
			<![CDATA[
        foreach(var file in Files)
        {
            using var sourceStream = File.OpenRead(file.GetMetadata("FullPath"));
            using var reader = new StreamReader(sourceStream);
            using var destStream = new DeflateStream(File.Create(file.GetMetadata("Destination")), CompressionLevel.Optimal);
            using var streamWriter = new StreamWriter(destStream);

            string line;
            int destLineNumber = 0;

            while ((line = reader.ReadLine()) != null)
            {
                if (line.Length == 0) { continue; }
                int index = line.IndexOf(' ');

                if (index <= 0 || index == line.Length - 1 || !int.TryParse(line.Substring(index + 1), out int id) || id < destLineNumber)
                {
                    Log.LogError($"Invalid format in the file {file.GetMetadata("FullPath")} line {line}");
                    break;
                }

                while (destLineNumber < id)
                {
                    // ensure id always aligns with the line number
                    streamWriter.WriteLine();
                    destLineNumber++;
                }

                streamWriter.WriteLine(line.Substring(0, index));
                destLineNumber++;
            }
        }
      ]]>
      </Code>
    </Task>
  </UsingTask>

  <ItemGroup>
    <!--
      The following files are compressed using the DeflateStream and embedded as resources in the assembly.
      The files are downloaded from the following sources and compressed to the Destination.
        1. cl100k_base.tiktoken: https://openaipublic.blob.core.windows.net/encodings/cl100k_base.tiktoken
        2. gpt2.tiktoken:        https://fossies.org/linux/misc/whisper-20231117.tar.gz/whisper-20231117/whisper/assets/gpt2.tiktoken?m=b
        3. p50k_base.tiktoken:   https://openaipublic.blob.core.windows.net/encodings/p50k_base.tiktoken
        4. r50k_base.tiktoken:   https://openaipublic.blob.core.windows.net/encodings/r50k_base.tiktoken
        5. o200k_base.tiktoken   https://openaipublic.blob.core.windows.net/encodings/o200k_base.tiktoken

      These files under MIT copyright license https://github.com/openai/tiktoken/blob/main/LICENSE

      In the CompressFile task above we modify the file's content to elimenate the ranks, thus reducing the file size,
      since the rank corresponds to the line number in the file. For the file p50k_base.tiktoken,
      we introduce empty lines to replace any missing ranks, ensuring that the rank consistently aligns with the line number.
      After we eleminate the ranks from the file, we compress the file using the DeflateStream and embed it as a resource in the assembly.
    -->
    <FilesToCompress Include="Data\cl100k_base.tiktoken" Destination="$(IntermediateOutputPath)%(FileName).deflate" />
    <FilesToCompress Include="Data\gpt2.tiktoken" Destination="$(IntermediateOutputPath)%(FileName).deflate" />
    <FilesToCompress Include="Data\p50k_base.tiktoken" Destination="$(IntermediateOutputPath)%(FileName).deflate" />
    <FilesToCompress Include="Data\r50k_base.tiktoken" Destination="$(IntermediateOutputPath)%(FileName).deflate" />
    <FilesToCompress Include="Data\o200k_base.tiktoken" Destination="$(IntermediateOutputPath)%(FileName).deflate" />
  </ItemGroup>

  <Target Name="TestCompress"
          BeforeTargets="AssignTargetPaths"
          Inputs="@(FilesToCompress)"
          Outputs="@(FilesToCompress->'%(Destination)')">

    <CompressFile Files="@(FilesToCompress)" />
    <ItemGroup>
      <EmbeddedResource Include="@(FilesToCompress->'%(Destination)')" LogicalName="%(FileName)%(Extension).deflate" />
    </ItemGroup>
  </Target>
</Project>
